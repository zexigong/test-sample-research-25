{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_address\\test_address.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nAddress objects for network connections.\n\"\"\"\n\n\nimport os\nfrom typing import Optional, Union\nfrom warnings import warn\n\nfrom zope.interface import implementer\n\nimport attr\nfrom typing_extensions import Literal\n\nfrom twisted.internet.interfaces import IAddress\nfrom twisted.python.filepath import _asFilesystemBytes, _coerceToFilesystemEncoding\nfrom twisted.python.runtime import platform\n\n\n@implementer(IAddress)\n@attr.s(unsafe_hash=True, auto_attribs=True)\nclass IPv4Address:\n    \"\"\"\n    An L{IPv4Address} represents the address of an IPv4 socket endpoint.\n\n    @ivar type: A string describing the type of transport, either 'TCP' or\n        'UDP'.\n\n    @ivar host: A string containing a dotted-quad IPv4 address; for example,\n        \"127.0.0.1\".\n    @type host: C{str}\n\n    @ivar port: An integer representing the port number.\n    @type port: C{int}\n    \"\"\"\n\n    type: Union[Literal[\"TCP\"], Literal[\"UDP\"]] = attr.ib(\n        validator=attr.validators.in_([\"TCP\", \"UDP\"])\n    )\n    host: str\n    port: int\n\n\n@implementer(IAddress)\n@attr.s(unsafe_hash=True, auto_attribs=True)\nclass IPv6Address:\n    \"\"\"\n    An L{IPv6Address} represents the address of an IPv6 socket endpoint.\n\n    @ivar type: A string describing the type of transport, either 'TCP' or\n        'UDP'.\n\n    @ivar host: A string containing a colon-separated, hexadecimal formatted\n        IPv6 address; for example, \"::1\".\n    @type host: C{str}\n\n    @ivar port: An integer representing the port number.\n    @type port: C{int}\n\n    @ivar flowInfo: the IPv6 flow label.  This can be used by QoS routers to\n        identify flows of traffic; you may generally safely ignore it.\n    @type flowInfo: L{int}\n\n    @ivar scopeID: the IPv6 scope identifier - roughly analagous to what\n        interface traffic destined for this address must be transmitted over.\n    @type scopeID: L{int} or L{str}\n    \"\"\"\n\n    type: Union[Literal[\"TCP\"], Literal[\"UDP\"]] = attr.ib(\n        validator=attr.validators.in_([\"TCP\", \"UDP\"])\n    )\n    host: str\n    port: int\n    flowInfo: int = 0\n    scopeID: Union[str, int] = 0\n\n\n@implementer(IAddress)\nclass _ProcessAddress:\n    \"\"\"\n    An L{interfaces.IAddress} provider for process transports.\n    \"\"\"\n\n\n@attr.s(unsafe_hash=True, auto_attribs=True)\n@implementer(IAddress)\nclass HostnameAddress:\n    \"\"\"\n    A L{HostnameAddress} represents the address of a L{HostnameEndpoint}.\n\n    @ivar hostname: A hostname byte string; for example, b\"example.com\".\n    @type hostname: L{bytes}\n\n    @ivar port: An integer representing the port number.\n    @type port: L{int}\n    \"\"\"\n\n    hostname: bytes\n    port: int\n\n\n@attr.s(unsafe_hash=False, repr=False, eq=False, auto_attribs=True)\n@implementer(IAddress)\nclass UNIXAddress:\n    \"\"\"\n    Object representing a UNIX socket endpoint.\n\n    @ivar name: The filename associated with this socket.\n    @type name: C{bytes}\n    \"\"\"\n\n    name: Optional[bytes] = attr.ib(\n        converter=attr.converters.optional(_asFilesystemBytes)\n    )\n\n    if getattr(os.path, \"samefile\", None) is not None:\n\n        def __eq__(self, other: object) -> bool:\n            \"\"\"\n            Overriding C{attrs} to ensure the os level samefile\n            check is done if the name attributes do not match.\n            \"\"\"\n            if not isinstance(other, self.__class__):\n                return NotImplemented\n            res = self.name == other.name\n            if not res and self.name and other.name:\n                try:\n                    return os.path.samefile(self.name, other.name)\n                except OSError:\n                    pass\n                except (TypeError, ValueError) as e:\n                    # On Linux, abstract namespace UNIX sockets start with a\n                    # \\0, which os.path doesn't like.\n                    if not platform.isLinux():\n                        raise e\n            return res\n\n    else:\n\n        def __eq__(self, other: object) -> bool:\n            if isinstance(other, self.__class__):\n                return self.name == other.name\n            return NotImplemented\n\n    def __repr__(self) -> str:\n        name = self.name\n        show = _coerceToFilesystemEncoding(\"\", name) if name is not None else None\n        return f\"UNIXAddress({show!r})\"\n\n    def __hash__(self):\n        if self.name is None:\n            return hash((self.__class__, None))\n        try:\n            s1 = os.stat(self.name)\n            return hash((s1.st_ino, s1.st_dev))\n        except OSError:\n            return hash(self.name)\n\n\n# These are for buildFactory backwards compatibility due to\n# stupidity-induced inconsistency.\n\n\nclass _ServerFactoryIPv4Address(IPv4Address):\n    \"\"\"Backwards compatibility hack. Just like IPv4Address in practice.\"\"\"\n\n    def __eq__(self, other: object) -> bool:\n        if isinstance(other, tuple):\n            warn(\n                \"IPv4Address.__getitem__ is deprecated.  \" \"Use attributes instead.\",\n                category=DeprecationWarning,\n                stacklevel=2,\n            )\n            return (self.host, self.port) == other\n        elif isinstance(other, IPv4Address):\n            a = (self.type, self.host, self.port)\n            b = (other.type, other.host, other.port)\n            return a == b\n        return NotImplemented\n\n### Source File Dependency Files Content\n### Dependency File: filepath.py\n# -*- test-case-name: twisted.test.test_paths -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nObject-oriented filesystem path representation.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport base64\nimport errno\nimport os\nimport sys\nfrom os import listdir, stat, utime\nfrom os.path import (\n    abspath,\n    basename,\n    dirname,\n    exists,\n    isabs,\n    islink,\n    join as joinpath,\n    normpath,\n    splitext,\n)\nfrom stat import (\n    S_IMODE,\n    S_IRGRP,\n    S_IROTH,\n    S_IRUSR,\n    S_ISBLK,\n    S_ISDIR,\n    S_ISREG,\n    S_ISSOCK,\n    S_IWGRP,\n    S_IWOTH,\n    S_IWUSR,\n    S_IXGRP,\n    S_IXOTH,\n    S_IXUSR,\n)\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    AnyStr,\n    Callable,\n    Dict,\n    Generic,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n    cast,\n    overload,\n)\n\nfrom zope.interface import Attribute, Interface, implementer\n\nfrom typing_extensions import Literal\n\nfrom twisted.python.compat import cmp, comparable\nfrom twisted.python.runtime import platform\nfrom twisted.python.util import FancyEqMixin\nfrom twisted.python.win32 import (\n    ERROR_DIRECTORY,\n    ERROR_FILE_NOT_FOUND,\n    ERROR_INVALID_NAME,\n    ERROR_PATH_NOT_FOUND,\n    O_BINARY,\n)\n\n# Please keep this as light as possible on other Twisted imports; many, many\n# things import this module, and it would be good if it could easily be\n# modified for inclusion in the standard library.  --glyph\n\n\n_CREATE_FLAGS = os.O_EXCL | os.O_CREAT | os.O_RDWR | O_BINARY\n_Self = TypeVar(\"_Self\", bound=\"AbstractFilePath[Any]\")\n\n\nrandomBytes = os.urandom\narmor = base64.urlsafe_b64encode\n\n\nclass IFilePath(Interface):\n    \"\"\"\n    File path object.\n\n    A file path represents a location for a file-like-object and can be\n    organized into a hierarchy; a file path can can children which are\n    themselves file paths.\n\n    A file path has a name which unique identifies it in the context of its\n    parent (if it has one); a file path can not have two children with the same\n    name.  This name is referred to as the file path's \"base name\".\n\n    A series of such names can be used to locate nested children of a file\n    path; such a series is referred to as the child's \"path\", relative to the\n    parent.  In this case, each name in the path is referred to as a \"path\n    segment\"; the child's base name is the segment in the path.\n\n    When representing a file path as a string, a \"path separator\" is used to\n    delimit the path segments within the string.  For a file system path, that\n    would be C{os.sep}.\n\n    Note that the values of child names may be restricted.  For example, a file\n    system path will not allow the use of the path separator in a name, and\n    certain names (e.g. C{\".\"} and C{\"..\"}) may be reserved or have special\n    meanings.\n\n    @since: 12.1\n    \"\"\"\n\n    sep = Attribute(\"The path separator to use in string representations\")\n\n    def child(name: AnyStr) -> IFilePath:\n        \"\"\"\n        Obtain a direct child of this file path.  The child may or may not\n        exist.\n\n        @param name: the name of a child of this path. C{name} must be a direct\n            child of this path and may not contain a path separator.\n        @return: the child of this path with the given C{name}.\n        @raise InsecurePath: if C{name} describes a file path that is not a\n            direct child of this file path.\n        \"\"\"\n\n    def open(mode: FileMode = \"r\") -> IO[bytes]:\n        \"\"\"\n        Opens this file path with the given mode.\n\n        @return: a file-like object.\n        @raise Exception: if this file path cannot be opened.\n        \"\"\"\n\n    def changed() -> None:\n        \"\"\"\n        Clear any cached information about the state of this path on disk.\n        \"\"\"\n\n    def getsize() -> int:\n        \"\"\"\n        Retrieve the size of this file in bytes.\n\n        @return: the size of the file at this file path in bytes.\n        @raise Exception: if the size cannot be obtained.\n        \"\"\"\n\n    def getModificationTime() -> float:\n        \"\"\"\n        Retrieve the time of last access from this file.\n\n        @return: a number of seconds from the epoch.\n        @rtype: L{float}\n        \"\"\"\n\n    def getStatusChangeTime() -> float:\n        \"\"\"\n        Retrieve the time of the last status change for this file.\n\n        @return: a number of seconds from the epoch.\n        @rtype: L{float}\n        \"\"\"\n\n    def getAccessTime() -> float:\n        \"\"\"\n        Retrieve the time that this file was last accessed.\n\n        @return: a number of seconds from the epoch.\n        @rtype: L{float}\n        \"\"\"\n\n    def exists() -> bool:\n        \"\"\"\n        Check if this file path exists.\n\n        @return: C{True} if the file at this file path exists, C{False}\n            otherwise.\n        @rtype: L{bool}\n        \"\"\"\n\n    def isdir() -> bool:\n        \"\"\"\n        Check if this file path refers to a directory.\n\n        @return: C{True} if the file at this file path is a directory, C{False}\n            otherwise.\n        \"\"\"\n\n    def isfile() -> bool:\n        \"\"\"\n        Check if this file path refers to a regular file.\n\n        @return: C{True} if the file at this file path is a regular file,\n            C{False} otherwise.\n        \"\"\"\n\n    def children() -> Iterable[IFilePath]:\n        \"\"\"\n        List the children of this path object.\n\n        @return: a sequence of the children of the directory at this file path.\n        @raise Exception: if the file at this file path is not a directory.\n        \"\"\"\n\n    def basename() -> Union[str, bytes]:\n        \"\"\"\n        Retrieve the final component of the file path's path (everything after\n        the final path separator).\n\n        @note: In implementors, the return type should be generic, i.e.\n            C{AbstractFilePath[str].basename()} is a C{str}.  However,\n            L{Interface} objects cannot be generic as of this writing.\n\n        @return: the base name of this file path.\n        \"\"\"\n\n    def parent() -> IFilePath:\n        \"\"\"\n        A file path for the directory containing the file at this file path.\n        \"\"\"\n\n    def sibling(name: AnyStr) -> IFilePath:\n        \"\"\"\n        A file path for the directory containing the file at this file path.\n\n        @param name: the name of a sibling of this path.  C{name} must be a\n            direct sibling of this path and may not contain a path separator.\n\n        @return: a sibling file path of this one.\n        \"\"\"\n\n\nclass InsecurePath(Exception):\n    \"\"\"\n    Error that is raised when the path provided to L{FilePath} is invalid.\n    \"\"\"\n\n\nclass LinkError(Exception):\n    \"\"\"\n    An error with symlinks - either that there are cyclical symlinks or that\n    symlink are not supported on this platform.\n    \"\"\"\n\n\nclass UnlistableError(OSError):\n    \"\"\"\n    An exception which is used to distinguish between errors which mean 'this\n    is not a directory you can list' and other, more catastrophic errors.\n\n    This error will try to look as much like the original error as possible,\n    while still being catchable as an independent type.\n\n    @ivar originalException: the actual original exception instance.\n    \"\"\"\n\n    def __init__(self, originalException: OSError):\n        \"\"\"\n        Create an UnlistableError exception.\n\n        @param originalException: an instance of OSError.\n        \"\"\"\n        self.__dict__.update(originalException.__dict__)\n        self.originalException = originalException\n\n\ndef _secureEnoughString(path: AnyStr) -> AnyStr:\n    \"\"\"\n    Compute a string usable as a new, temporary filename.\n\n    @param path: The path that the new temporary filename should be able to be\n        concatenated with.\n\n    @return: A pseudorandom, 16 byte string for use in secure filenames.\n    @rtype: the type of C{path}\n    \"\"\"\n    secureishString = armor(randomBytes(16))[:16]\n    return _coerceToFilesystemEncoding(path, secureishString)\n\n\nOtherAnyStr = TypeVar(\"OtherAnyStr\", str, bytes)\nFileMode = Literal[\"r\", \"w\", \"a\", \"r+\", \"w+\", \"a+\"]\n\n\nclass AbstractFilePath(Generic[AnyStr]):\n    \"\"\"\n    Abstract implementation of an L{IFilePath}; must be completed by a\n    subclass.\n\n    This class primarily exists to provide common implementations of certain\n    methods in L{IFilePath}. It is *not* a required parent class for\n    L{IFilePath} implementations, just a useful starting point.\n\n    @ivar path: Subclasses must set this variable.\n    \"\"\"\n\n    Selfish = TypeVar(\"Selfish\", bound=\"AbstractFilePath[AnyStr]\")\n\n    path: AnyStr\n\n    def getAccessTime(self) -> float:\n        \"\"\"\n        Subclasses must implement this.\n\n        @see: L{FilePath.getAccessTime}\n        \"\"\"\n        raise NotImplementedError()\n\n    def getModificationTime(self) -> float:\n        \"\"\"\n        Subclasses must implement this.\n\n        @see: L{FilePath.getModificationTime}\n        \"\"\"\n        raise NotImplementedError()\n\n    def getStatusChangeTime(self) -> float:\n        \"\"\"\n        Subclasses must implement this.\n\n        @see: L{FilePath.getStatusChangeTime}\n        \"\"\"\n        raise NotImplementedError()\n\n    def open(self, mode: FileMode = \"r\") -> IO[bytes]:\n        \"\"\"\n        Subclasses must implement this.\n        \"\"\"\n        raise NotImplementedError()\n\n    def isdir(self) -> bool:\n        \"\"\"\n        Subclasses must implement this.\n        \"\"\"\n        raise NotImplementedError()\n\n    def basename(self) -> AnyStr:\n        \"\"\"\n        Subclasses must implement this.\n        \"\"\"\n        raise NotImplementedError()\n\n    def parent(self) -> AbstractFilePath[AnyStr]:\n        \"\"\"\n        Subclasses must implement this.\n        \"\"\"\n        raise NotImplementedError()\n\n    def listdir(self) -> List[AnyStr]:\n        \"\"\"\n        Subclasses must implement this.\n        \"\"\"\n        raise NotImplementedError()\n\n    def child(self, path: OtherAnyStr) -> AbstractFilePath[OtherAnyStr]:\n        \"\"\"\n        Subclasses must implement this.\n        \"\"\"\n        raise NotImplementedError()\n\n    def getContent(self) -> bytes:\n        \"\"\"\n        Retrieve the contents of the file at this path.\n\n        @return: the contents of the file\n        @rtype: L{bytes}\n        \"\"\"\n        with self.open() as fp:\n            return fp.read()\n\n    def parents(self) -> Iterable[AbstractFilePath[AnyStr]]:\n        \"\"\"\n        Retrieve an iterator of all the ancestors of this path.\n\n        @return: an iterator of all the ancestors of this path, from the most\n        recent (its immediate parent) to the root of its filesystem.\n        \"\"\"\n        path = self\n        parent = path.parent()\n        # root.parent() == root, so this means \"are we the root\"\n        while path != parent:\n            yield parent\n            path = parent\n            parent = parent.parent()\n\n    def children(self: _Self) -> Iterable[_Self]:\n        \"\"\"\n        List the children of this path object.\n\n        @raise OSError: If an error occurs while listing the directory.  If the\n        error is 'serious', meaning that the operation failed due to an access\n        violation, exhaustion of some kind of resource (file descriptors or\n        memory), OSError or a platform-specific variant will be raised.\n\n        @raise UnlistableError: If the inability to list the directory is due\n        to this path not existing or not being a directory, the more specific\n        OSError subclass L{UnlistableError} is raised instead.\n\n        @return: an iterable of all currently-existing children of this object.\n        \"\"\"\n        try:\n            subnames: List[AnyStr] = self.listdir()\n        except OSError as ose:\n            # Under Python 3.3 and higher on Windows, WindowsError is an\n            # alias for OSError.  OSError has a winerror attribute and an\n            # errno attribute.\n            #\n            # The winerror attribute is bound to the Windows error code while\n            # the errno attribute is bound to a translation of that code to a\n            # perhaps equivalent POSIX error number.\n            #\n            # For further details, refer to:\n            # https://docs.python.org/3/library/exceptions.html#OSError\n            if getattr(ose, \"winerror\", None) in (\n                ERROR_PATH_NOT_FOUND,\n                ERROR_FILE_NOT_FOUND,\n                ERROR_INVALID_NAME,\n                ERROR_DIRECTORY,\n            ):\n                raise UnlistableError(ose)\n            if ose.errno in (errno.ENOENT, errno.ENOTDIR):\n                raise UnlistableError(ose)\n            # Other possible errors here, according to linux manpages:\n            # EACCES, EMIFLE, ENFILE, ENOMEM.  None of these seem like the\n            # sort of thing which should be handled normally. -glyph\n            raise\n        result = []\n        for name in subnames:\n            # It's not possible to tell mypy that child/clone etc must be\n            # overridden to return respecializable forms of _Self, but they\n            # must, so we will say that they are.\n            child: _Self = self.child(name)  # type:ignore[assignment]\n            result.append(child)\n        return result\n\n    def walk(\n        self: _Self,\n        descend: Optional[Callable[[_Self], bool]] = None,\n    ) -> Iterable[_Self]:\n        \"\"\"\n        Yield myself, then each of my children, and each of those children's\n        children in turn.\n\n        The optional argument C{descend} is a predicate that takes a FilePath,\n        and determines whether or not that FilePath is traversed/descended\n        into.  It will be called with each path for which C{isdir} returns\n        C{True}.  If C{descend} is not specified, all directories will be\n        traversed (including symbolic links which refer to directories).\n\n        @param descend: A one-argument callable that will return True for\n            FilePaths that should be traversed, False otherwise.\n\n        @return: a generator yielding FilePath-like objects.\n        \"\"\"\n        yield self\n        if self.isdir():\n            for c in self.children():\n                # we should first see if it's what we want, then we\n                # can walk through the directory\n                if descend is None or descend(c):\n                    for subc in c.walk(descend):\n                        if os.path.realpath(self.path).startswith(\n                            os.path.realpath(subc.path)\n                        ):\n                            raise LinkError(\"Cycle in file graph.\")\n                        yield subc\n                else:\n                    yield c\n\n    def sibling(self: _Self, path: OtherAnyStr) -> AbstractFilePath[OtherAnyStr]:\n        \"\"\"\n        Return a L{FilePath} with the same directory as this instance but with\n        a basename of C{path}.\n\n        @note: for type-checking, subclasses should override this signature to\n            make it clear that it returns the subclass and not\n            L{AbstractFilePath}.\n\n        @param path: The basename of the L{FilePath} to return.\n        @type path: L{str}\n\n        @return: The sibling path.\n        @rtype: L{FilePath}\n        \"\"\"\n        return self.parent().child(path)\n\n    def descendant(\n        self, segments: Sequence[OtherAnyStr]\n    ) -> AbstractFilePath[OtherAnyStr]:\n        \"\"\"\n        Retrieve a child or child's child of this path.\n\n        @note: for type-checking, subclasses should override this signature to\n            make it clear that it returns the subclass and not\n            L{AbstractFilePath}.\n\n        @param segments: A sequence of path segments as L{str} instances.\n\n        @return: A L{FilePath} constructed by looking up the C{segments[0]}\n            child of this path, the C{segments[1]} child of that path, and so\n            on.\n\n        @since: 10.2\n        \"\"\"\n        path: AbstractFilePath[OtherAnyStr] = self  # type:ignore[assignment]\n        for name in segments:\n            path = path.child(name)\n        return path\n\n    def segmentsFrom(self: _Self, ancestor: _Self) -> List[AnyStr]:\n        \"\"\"\n        Return a list of segments between a child and its ancestor.\n\n        For example, in the case of a path X representing /a/b/c/d and a path Y\n        representing /a/b, C{Y.segmentsFrom(X)} will return C{['c',\n        'd']}.\n\n        @param ancestor: an instance of the same class as self, ostensibly an\n        ancestor of self.\n\n        @raise ValueError: If the C{ancestor} parameter is not actually an\n        ancestor, i.e. a path for /x/y/z is passed as an ancestor for /a/b/c/d.\n\n        @return: a list of strs\n        \"\"\"\n        # this might be an unnecessarily inefficient implementation but it will\n        # work on win32 and for zipfiles; later I will deterimine if the\n        # obvious fast implemenation does the right thing too\n        f = self\n        p: _Self = f.parent()  # type:ignore[assignment]\n        segments: List[AnyStr] = []\n        while f != ancestor and p != f:\n            segments[0:0] = [f.basename()]\n            f = p\n            p = p.parent()  # type:ignore[assignment]\n        if f == ancestor and segments:\n            return segments\n        raise ValueError(f\"{ancestor!r} not parent of {self!r}\")\n\n    # new in 8.0\n    def __hash__(self) -> int:\n        \"\"\"\n        Hash the same as another L{AbstractFilePath} with the same path as mine.\n        \"\"\"\n        return hash((self.__class__, self.path))\n\n    # pending deprecation in 8.0\n    def getmtime(self) -> int:\n        \"\"\"\n        Deprecated.  Use getModificationTime instead.\n        \"\"\"\n        return int(self.getModificationTime())\n\n    def getatime(self) -> int:\n        \"\"\"\n        Deprecated.  Use getAccessTime instead.\n        \"\"\"\n        return int(self.getAccessTime())\n\n    def getctime(self) -> int:\n        \"\"\"\n        Deprecated.  Use getStatusChangeTime instead.\n        \"\"\"\n        return int(self.getStatusChangeTime())\n\n\nclass RWX(FancyEqMixin):\n    \"\"\"\n    A class representing read/write/execute permissions for a single user\n    category (i.e. user/owner, group, or other/world).  Instantiate with\n    three boolean values: readable? writable? executable?.\n\n    @type read: C{bool}\n    @ivar read: Whether permission to read is given\n\n    @type write: C{bool}\n    @ivar write: Whether permission to write is given\n\n    @type execute: C{bool}\n    @ivar execute: Whether permission to execute is given\n\n    @since: 11.1\n    \"\"\"\n\n    compareAttributes = (\"read\", \"write\", \"execute\")\n\n    def __init__(self, readable: bool, writable: bool, executable: bool) -> None:\n        self.read = readable\n        self.write = writable\n        self.execute = executable\n\n    def __repr__(self) -> str:\n        return \"RWX(read={}, write={}, execute={})\".format(\n            self.read,\n            self.write,\n            self.execute,\n        )\n\n    def shorthand(self) -> str:\n        \"\"\"\n        Returns a short string representing the permission bits.  Looks like\n        part of what is printed by command line utilities such as 'ls -l'\n        (e.g. 'rwx')\n\n        @return: The shorthand string.\n        @rtype: L{str}\n        \"\"\"\n        returnval = [\"r\", \"w\", \"x\"]\n        i = 0\n        for val in (self.read, self.write, self.execute):\n            if not val:\n                returnval[i] = \"-\"\n            i += 1\n        return \"\".join(returnval)\n\n\nclass Permissions(FancyEqMixin):\n    \"\"\"\n    A class representing read/write/execute permissions.  Instantiate with any\n    portion of the file's mode that includes the permission bits.\n\n    @type user: L{RWX}\n    @ivar user: User/Owner permissions\n\n    @type group: L{RWX}\n    @ivar group: Group permissions\n\n    @type other: L{RWX}\n    @ivar other: Other/World permissions\n\n    @since: 11.1\n    \"\"\"\n\n    compareAttributes = (\"user\", \"group\", \"other\")\n\n    def __init__(self, statModeInt: int) -> None:\n        self.user, self.group, self.other = (\n            RWX(*(statModeInt & bit > 0 for bit in bitGroup))\n            for bitGroup in [\n                [S_IRUSR, S_IWUSR, S_IXUSR],\n                [S_IRGRP, S_IWGRP, S_IXGRP],\n                [S_IROTH, S_IWOTH, S_IXOTH],\n            ]\n        )\n\n    def __repr__(self) -> str:\n        return f\"[{str(self.user)} | {str(self.group)} | {str(self.other)}]\"\n\n    def shorthand(self) -> str:\n        \"\"\"\n        Returns a short string representing the permission bits.  Looks like\n        what is printed by command line utilities such as 'ls -l'\n        (e.g. 'rwx-wx--x')\n\n        @return: The shorthand string.\n        @rtype: L{str}\n        \"\"\"\n        return \"\".join([x.shorthand() for x in (self.user, self.group, self.other)])\n\n\ndef _asFilesystemBytes(path: Union[bytes, str], encoding: Optional[str] = \"\") -> bytes:\n    \"\"\"\n    Return C{path} as a string of L{bytes} suitable for use on this system's\n    filesystem.\n\n    @param path: The path to be made suitable.\n    @type path: L{bytes} or L{unicode}\n    @param encoding: The encoding to use if coercing to L{bytes}. If none is\n        given, L{sys.getfilesystemencoding} is used.\n\n    @return: L{bytes}\n    \"\"\"\n    if isinstance(path, bytes):\n        return path\n    else:\n        if not encoding:\n            encoding = sys.getfilesystemencoding()\n        return path.encode(encoding, errors=\"surrogateescape\")\n\n\ndef _asFilesystemText(path: Union[bytes, str], encoding: Optional[str] = None) -> str:\n    \"\"\"\n    Return C{path} as a string of L{unicode} suitable for use on this system's\n    filesystem.\n\n    @param path: The path to be made suitable.\n    @type path: L{bytes} or L{unicode}\n\n    @param encoding: The encoding to use if coercing to L{unicode}. If none\n        is given, L{sys.getfilesystemencoding} is used.\n\n    @return: L{unicode}\n    \"\"\"\n    if isinstance(path, str):\n        return path\n    else:\n        if encoding is None:\n            encoding = sys.getfilesystemencoding()\n        return path.decode(encoding, errors=\"surrogateescape\")\n\n\ndef _coerceToFilesystemEncoding(\n    path: AnyStr, newpath: Union[bytes, str], encoding: Optional[str] = None\n) -> AnyStr:\n    \"\"\"\n    Return a C{newpath} that is suitable for joining to C{path}.\n\n    @param path: The path that it should be suitable for joining to.\n    @param newpath: The new portion of the path to be coerced if needed.\n    @param encoding: If coerced, the encoding that will be used.\n    \"\"\"\n    if isinstance(path, bytes):\n        return _asFilesystemBytes(newpath, encoding=encoding)\n    else:\n        return _asFilesystemText(newpath, encoding=encoding)\n\n\n@comparable\n@implementer(IFilePath)\nclass FilePath(AbstractFilePath[AnyStr]):\n    \"\"\"\n    I am a path on the filesystem that only permits 'downwards' access.\n\n    Instantiate me with a pathname (for example,\n    FilePath('/home/myuser/public_html')) and I will attempt to only provide\n    access to files which reside inside that path.  I may be a path to a file,\n    a directory, or a file which does not exist.\n\n    The correct way to use me is to instantiate me, and then do ALL filesystem\n    access through me.  In other words, do not import the 'os' module; if you\n    need to open a file, call my 'open' method.  If you need to list a\n    directory, call my 'path' method.\n\n    Even if you pass me a relative path, I will convert that to an absolute\n    path internally.\n\n    The type of C{path} when instantiating decides the mode of the L{FilePath}.\n    That is, C{FilePath(b\"/\")} will return a L{bytes} mode L{FilePath}, and\n    C{FilePath(u\"/\")} will return a L{unicode} mode L{FilePath}.\n    C{FilePath(\"/\")} will return a L{bytes} mode L{FilePath} on Python 2, and a\n    L{unicode} mode L{FilePath} on Python 3.\n\n    Methods that return a new L{FilePath} use the type of the given subpath to\n    decide its mode. For example, C{FilePath(b\"/\").child(u\"tmp\")} will return a\n    L{unicode} mode L{FilePath}.\n\n    @type alwaysCreate: L{bool}\n    @ivar alwaysCreate: When opening this file, only succeed if the file does\n        not already exist.\n\n    @ivar path: The path from which 'downward' traversal is permitted.\n    \"\"\"\n\n    _statinfo = None\n    path: AnyStr\n\n    def __init__(self, path: AnyStr, alwaysCreate: bool = False) -> None:\n        \"\"\"\n        Convert a path string to an absolute path if necessary and initialize\n        the L{FilePath} with the result.\n        \"\"\"\n        self.path = abspath(path)\n        self.alwaysCreate = alwaysCreate\n\n    if TYPE_CHECKING:\n\n        def sibling(self: _Self, path: OtherAnyStr) -> FilePath[OtherAnyStr]:\n            ...\n\n        def descendant(self, segments: Sequence[OtherAnyStr]) -> FilePath[OtherAnyStr]:\n            ...\n\n        def parents(self) -> Iterable[FilePath[AnyStr]]:\n            ...\n\n        # provided by @comparable\n        def __gt__(self, other: object) -> bool:\n            ...\n\n        def __ge__(self, other: object) -> bool:\n            ...\n\n        def __lt__(self, other: object) -> bool:\n            ...\n\n        def __le__(self, other: object) -> bool:\n            ...\n\n        def __eq__(self, other: object) -> bool:\n            ...\n\n        def __ne__(self, other: object) -> bool:\n            ...\n\n    def clonePath(\n        self, path: OtherAnyStr, alwaysCreate: bool = False\n    ) -> FilePath[OtherAnyStr]:\n        \"\"\"\n        Make an object of the same type as this FilePath, but with path of\n        C{path}.\n        \"\"\"\n        return FilePath(path)\n\n    def __getstate__(self) -> Dict[str, object]:\n        \"\"\"\n        Support serialization by discarding cached L{os.stat} results and\n        returning everything else.\n        \"\"\"\n        d = self.__dict__.copy()\n        if \"_statinfo\" in d:\n            del d[\"_statinfo\"]\n        return d\n\n    @property\n    def sep(self) -> AnyStr:\n        \"\"\"\n        Return a filesystem separator.\n\n        @return: The native filesystem separator.\n        @returntype: The same type as C{self.path}.\n        \"\"\"\n        return _coerceToFilesystemEncoding(self.path, os.sep)\n\n    def _asBytesPath(self, encoding: Optional[str] = None) -> bytes:\n        \"\"\"\n        Return the path of this L{FilePath} as bytes.\n\n        @param encoding: The encoding to use if coercing to L{bytes}. If none is\n            given, L{sys.getfilesystemencoding} is used.\n\n        @return: L{bytes}\n        \"\"\"\n        return _asFilesystemBytes(self.path, encoding=encoding)\n\n    def _asTextPath(self, encoding: Optional[str] = None) -> str:\n        \"\"\"\n        Return the path of this L{FilePath} as text.\n\n        @param encoding: The encoding to use if coercing to L{unicode}. If none\n            is given, L{sys.getfilesystemencoding} is used.\n\n        @return: L{unicode}\n        \"\"\"\n        return _asFilesystemText(self.path, encoding=encoding)\n\n    def asBytesMode(self, encoding: Optional[str] = None) -> FilePath[bytes]:\n        \"\"\"\n        Return this L{FilePath} in L{bytes}-mode.\n\n        @param encoding: The encoding to use if coercing to L{bytes}. If none is\n            given, L{sys.getfilesystemencoding} is used.\n\n        @return: L{bytes} mode L{FilePath}\n        \"\"\"\n        if isinstance(self.path, str):\n            return self.clonePath(self._asBytesPath(encoding=encoding))\n        return self\n\n    def asTextMode(self, encoding: Optional[str] = None) -> FilePath[str]:\n        \"\"\"\n        Return this L{FilePath} in L{unicode}-mode.\n\n        @param encoding: The encoding to use if coercing to L{unicode}. If none\n            is given, L{sys.getfilesystemencoding} is used.\n\n        @return: L{unicode} mode L{FilePath}\n        \"\"\"\n        if isinstance(self.path, bytes):\n            return self.clonePath(self._asTextPath(encoding=encoding))\n        return self\n\n    def _getPathAsSameTypeAs(self, pattern: OtherAnyStr) -> OtherAnyStr:\n        \"\"\"\n        If C{pattern} is C{bytes}, return L{FilePath.path} as L{bytes}.\n        Otherwise, return L{FilePath.path} as L{unicode}.\n\n        @param pattern: The new element of the path that L{FilePath.path} may\n            need to be coerced to match.\n        \"\"\"\n        if isinstance(pattern, bytes):\n            return self._asBytesPath()\n        else:\n            return self._asTextPath()\n\n    def child(self, path: OtherAnyStr) -> FilePath[OtherAnyStr]:\n        \"\"\"\n        Create and return a new L{FilePath} representing a path contained by\n        C{self}.\n\n        @param path: The base name of the new L{FilePath}.  If this contains\n            directory separators or parent references it will be rejected.\n        @type path: L{bytes} or L{unicode}\n\n        @raise InsecurePath: If the result of combining this path with C{path}\n            would result in a path which is not a direct child of this path.\n\n        @return: The child path.\n        @rtype: L{FilePath} with a mode equal to the type of C{path}.\n        \"\"\"\n        colon = _coerceToFilesystemEncoding(path, \":\")\n        sep = _coerceToFilesystemEncoding(path, os.sep)\n        ourPath = self._getPathAsSameTypeAs(path)\n\n        if platform.isWindows() and path.count(colon):\n            # Catch paths like C:blah that don't have a slash\n            raise InsecurePath(f\"{path!r} contains a colon.\")\n\n        norm = normpath(path)\n        if sep in norm:\n            raise InsecurePath(f\"{path!r} contains one or more directory separators\")\n\n        newpath = abspath(joinpath(ourPath, norm))\n        if not newpath.startswith(ourPath):\n            raise InsecurePath(f\"{newpath!r} is not a child of {ourPath!r}\")\n        return self.clonePath(newpath)\n\n    def preauthChild(self, path: OtherAnyStr) -> FilePath[OtherAnyStr]:\n        \"\"\"\n        Use me if C{path} might have slashes in it, but you know they're safe.\n\n        @param path: A relative path (ie, a path not starting with C{\"/\"})\n            which will be interpreted as a child or descendant of this path.\n        @type path: L{bytes} or L{unicode}\n\n        @return: The child path.\n        @rtype: L{FilePath} with a mode equal to the type of C{path}.\n        \"\"\"\n        ourPath = self._getPathAsSameTypeAs(path)\n\n        newpath = abspath(joinpath(ourPath, normpath(path)))\n        if not newpath.startswith(ourPath):\n            raise InsecurePath(f\"{newpath!r} is not a child of {ourPath!r}\")\n        return self.clonePath(newpath)\n\n    def childSearchPreauth(\n        self, *paths: OtherAnyStr\n    ) -> Optional[FilePath[OtherAnyStr]]:\n        \"\"\"\n        Return my first existing child with a name in C{paths}.\n\n        C{paths} is expected to be a list of *pre-secured* path fragments;\n        in most cases this will be specified by a system administrator and not\n        an arbitrary user.\n\n        If no appropriately-named children exist, this will return L{None}.\n\n        @return: L{None} or the child path.\n        @rtype: L{None} or L{FilePath}\n        \"\"\"\n        for child in paths:\n            p = self._getPathAsSameTypeAs(child)\n            jp = joinpath(p, child)\n            if exists(jp):\n                return self.clonePath(jp)\n        return None\n\n    def siblingExtensionSearch(\n        self, *exts: OtherAnyStr\n    ) -> Optional[FilePath[OtherAnyStr]]:\n        \"\"\"\n        Attempt to return a path with my name, given multiple possible\n        extensions.\n\n        Each extension in C{exts} will be tested and the first path which\n        exists will be returned.  If no path exists, L{None} will be returned.\n        If C{''} is in C{exts}, then if the file referred to by this path\n        exists, C{self} will be returned.\n\n        The extension '*' has a magic meaning, which means \"any path that\n        begins with C{self.path + '.'} is acceptable\".\n        \"\"\"\n        for ext in exts:\n            if not ext and self.exists():\n                return self.clonePath(self._getPathAsSameTypeAs(ext))\n\n            p = self._getPathAsSameTypeAs(ext)\n            star = _coerceToFilesystemEncoding(ext, \"*\")\n            dot = _coerceToFilesystemEncoding(ext, \".\")\n\n            if ext == star:\n                basedot = basename(p) + dot\n                for fn in listdir(dirname(p)):\n                    if fn.startswith(basedot):\n                        return self.clonePath(joinpath(dirname(p), fn))\n            p2 = p + ext\n            if exists(p2):\n                return self.clonePath(p2)\n        return None\n\n    def realpath(self) -> FilePath[AnyStr]:\n        \"\"\"\n        Returns the absolute target as a L{FilePath} if self is a link, self\n        otherwise.\n\n        The absolute link is the ultimate file or directory the\n        link refers to (for instance, if the link refers to another link, and\n        another...).  If the filesystem does not support symlinks, or\n        if the link is cyclical, raises a L{LinkError}.\n\n        Behaves like L{os.path.realpath} in that it does not resolve link\n        names in the middle (ex. /x/y/z, y is a link to w - realpath on z\n        will return /x/y/z, not /x/w/z).\n\n        @return: L{FilePath} of the target path.\n        @rtype: L{FilePath}\n        @raises LinkError: if links are not supported or links are cyclical.\n        \"\"\"\n        if self.islink():\n            result = os.path.realpath(self.path)\n            if result == self.path:\n                raise LinkError(\"Cyclical link - will loop forever\")\n            return self.clonePath(result)\n        return self\n\n    def siblingExtension(self, ext: OtherAnyStr) -> FilePath[OtherAnyStr]:\n        \"\"\"\n        Attempt to return a path with my name, given the extension at C{ext}.\n\n        @param ext: File-extension to search for.\n        @type ext: L{bytes} or L{unicode}\n\n        @return: The sibling path.\n        @rtype: L{FilePath} with the same mode as the type of C{ext}.\n        \"\"\"\n        ourPath = self._getPathAsSameTypeAs(ext)\n        return self.clonePath(ourPath + ext)\n\n    def linkTo(self, linkFilePath: FilePath[AnyStr]) -> None:\n        \"\"\"\n        Creates a symlink to self to at the path in the L{FilePath}\n        C{linkFilePath}.\n\n        Only works on posix systems due to its dependence on\n        L{os.symlink}.  Propagates L{OSError}s up from L{os.symlink} if\n        C{linkFilePath.parent()} does not exist, or C{linkFilePath} already\n        exists.\n\n        @param linkFilePath: a FilePath representing the link to be created.\n        @type linkFilePath: L{FilePath}\n        \"\"\"\n        os.symlink(self.path, linkFilePath.path)\n\n    def open(self, mode: FileMode = \"r\") -> IO[bytes]:\n        \"\"\"\n        Open this file using C{mode} or for writing if C{alwaysCreate} is\n        C{True}.\n\n        In all cases the file is opened in binary mode, so it is not necessary\n        to include C{\"b\"} in C{mode}.\n\n        @param mode: The mode to open the file in.  Default is C{\"r\"}.\n        @raises AssertionError: If C{\"a\"} is included in the mode and\n            C{alwaysCreate} is C{True}.\n        @return: An open file-like object.\n        \"\"\"\n        if self.alwaysCreate:\n            assert \"a\" not in mode, (\n                \"Appending not supported when \" \"alwaysCreate == True\"\n            )\n            return self.create()\n        # Make sure we open with exactly one \"b\" in the mode.\n        return open(self.path, mode.replace(\"b\", \"\") + \"b\")\n\n    # stat methods below\n\n    def restat(self, reraise: bool = True) -> None:\n        \"\"\"\n        Re-calculate cached effects of 'stat'.  To refresh information on this\n        path after you know the filesystem may have changed, call this method.\n\n        @param reraise: a boolean.  If true, re-raise exceptions from\n            L{os.stat}; otherwise, mark this path as not existing, and remove\n            any cached stat information.\n\n        @raise Exception: If C{reraise} is C{True} and an exception occurs\n            while reloading metadata.\n        \"\"\"\n        try:\n            self._statinfo = stat(self.path)\n        except OSError:\n            self._statinfo = None\n            if reraise:\n                raise\n\n    def changed(self) -> None:\n        \"\"\"\n        Clear any cached information about the state of this path on disk.\n\n        @since: 10.1.0\n        \"\"\"\n        self._statinfo = None\n\n    def chmod(self, mode: int) -> None:\n        \"\"\"\n        Changes the permissions on self, if possible.  Propagates errors from\n        L{os.chmod} up.\n\n        @param mode: integer representing the new permissions desired (same as\n            the command line chmod)\n        @type mode: L{int}\n        \"\"\"\n        os.chmod(self.path, mode)\n\n    def getsize(self) -> int:\n        \"\"\"\n        Retrieve the size of this file in bytes.\n\n        @return: The size of the file at this file path in bytes.\n        @raise Exception: if the size cannot be obtained.\n        @rtype: L{int}\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return st.st_size\n\n    def getModificationTime(self) -> float:\n        \"\"\"\n        Retrieve the time of last access from this file.\n\n        @return: a number of seconds from the epoch.\n        @rtype: L{float}\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return float(st.st_mtime)\n\n    def getStatusChangeTime(self) -> float:\n        \"\"\"\n        Retrieve the time of the last status change for this file.\n\n        @return: a number of seconds from the epoch.\n        @rtype: L{float}\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return float(st.st_ctime)\n\n    def getAccessTime(self) -> float:\n        \"\"\"\n        Retrieve the time that this file was last accessed.\n\n        @return: a number of seconds from the epoch.\n        @rtype: L{float}\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return float(st.st_atime)\n\n    def getInodeNumber(self) -> int:\n        \"\"\"\n        Retrieve the file serial number, also called inode number, which\n        distinguishes this file from all other files on the same device.\n\n        @raise NotImplementedError: if the platform is Windows, since the\n            inode number would be a dummy value for all files in Windows\n        @return: a number representing the file serial number\n        @rtype: L{int}\n        @since: 11.0\n        \"\"\"\n        if platform.isWindows():\n            raise NotImplementedError\n\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return st.st_ino\n\n    def getDevice(self) -> int:\n        \"\"\"\n        Retrieves the device containing the file.  The inode number and device\n        number together uniquely identify the file, but the device number is\n        not necessarily consistent across reboots or system crashes.\n\n        @raise NotImplementedError: if the platform is Windows, since the\n            device number would be 0 for all partitions on a Windows platform\n\n        @return: a number representing the device\n        @rtype: L{int}\n\n        @since: 11.0\n        \"\"\"\n        if platform.isWindows():\n            raise NotImplementedError\n\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return st.st_dev\n\n    def getNumberOfHardLinks(self) -> int:\n        \"\"\"\n        Retrieves the number of hard links to the file.\n\n        This count keeps track of how many directories have entries for this\n        file. If the count is ever decremented to zero then the file itself is\n        discarded as soon as no process still holds it open.  Symbolic links\n        are not counted in the total.\n\n        @raise NotImplementedError: if the platform is Windows, since Windows\n            doesn't maintain a link count for directories, and L{os.stat} does\n            not set C{st_nlink} on Windows anyway.\n        @return: the number of hard links to the file\n        @rtype: L{int}\n        @since: 11.0\n        \"\"\"\n        if platform.isWindows():\n            raise NotImplementedError\n\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return st.st_nlink\n\n    def getUserID(self) -> int:\n        \"\"\"\n        Returns the user ID of the file's owner.\n\n        @raise NotImplementedError: if the platform is Windows, since the UID\n            is always 0 on Windows\n        @return: the user ID of the file's owner\n        @rtype: L{int}\n        @since: 11.0\n        \"\"\"\n        if platform.isWindows():\n            raise NotImplementedError\n\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return st.st_uid\n\n    def getGroupID(self) -> int:\n        \"\"\"\n        Returns the group ID of the file.\n\n        @raise NotImplementedError: if the platform is Windows, since the GID\n            is always 0 on windows\n        @return: the group ID of the file\n        @rtype: L{int}\n        @since: 11.0\n        \"\"\"\n        if platform.isWindows():\n            raise NotImplementedError\n\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return st.st_gid\n\n    def getPermissions(self) -> Permissions:\n        \"\"\"\n        Returns the permissions of the file.  Should also work on Windows,\n        however, those permissions may not be what is expected in Windows.\n\n        @return: the permissions for the file\n        @rtype: L{Permissions}\n        @since: 11.1\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat()\n            st = self._statinfo\n        assert st is not None\n        return Permissions(S_IMODE(st.st_mode))\n\n    def exists(self) -> bool:\n        \"\"\"\n        Check if this L{FilePath} exists.\n\n        @return: C{True} if the stats of C{path} can be retrieved successfully,\n            C{False} in the other cases.\n        @rtype: L{bool}\n        \"\"\"\n        if self._statinfo:\n            return True\n        else:\n            self.restat(False)\n            if self._statinfo:\n                return True\n            else:\n                return False\n\n    def isdir(self) -> bool:\n        \"\"\"\n        Check if this L{FilePath} refers to a directory.\n\n        @return: C{True} if this L{FilePath} refers to a directory, C{False}\n            otherwise.\n        @rtype: L{bool}\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat(False)\n            st = self._statinfo\n            if not st:\n                return False\n        return S_ISDIR(st.st_mode)\n\n    def isfile(self) -> bool:\n        \"\"\"\n        Check if this file path refers to a regular file.\n\n        @return: C{True} if this L{FilePath} points to a regular file (not a\n            directory, socket, named pipe, etc), C{False} otherwise.\n        @rtype: L{bool}\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat(False)\n            st = self._statinfo\n            if not st:\n                return False\n        return S_ISREG(st.st_mode)\n\n    def isBlockDevice(self) -> bool:\n        \"\"\"\n        Returns whether the underlying path is a block device.\n\n        @return: C{True} if it is a block device, C{False} otherwise\n        @rtype: L{bool}\n        @since: 11.1\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat(False)\n            st = self._statinfo\n            if not st:\n                return False\n        return S_ISBLK(st.st_mode)\n\n    def isSocket(self) -> bool:\n        \"\"\"\n        Returns whether the underlying path is a socket.\n\n        @return: C{True} if it is a socket, C{False} otherwise\n        @rtype: L{bool}\n        @since: 11.1\n        \"\"\"\n        st = self._statinfo\n        if not st:\n            self.restat(False)\n            st = self._statinfo\n            if not st:\n                return False\n        return S_ISSOCK(st.st_mode)\n\n    def islink(self) -> bool:\n        \"\"\"\n        Check if this L{FilePath} points to a symbolic link.\n\n        @return: C{True} if this L{FilePath} points to a symbolic link,\n            C{False} otherwise.\n        @rtype: L{bool}\n        \"\"\"\n        # We can't use cached stat results here, because that is the stat of\n        # the destination - (see #1773) which in *every case* but this one is\n        # the right thing to use.  We could call lstat here and use that, but\n        # it seems unlikely we'd actually save any work that way.  -glyph\n        return islink(self.path)\n\n    def isabs(self) -> bool:\n        \"\"\"\n        Check if this L{FilePath} refers to an absolute path.\n\n        This always returns C{True}.\n\n        @return: C{True}, always.\n        @rtype: L{bool}\n        \"\"\"\n        return isabs(self.path)\n\n    def listdir(self) -> List[AnyStr]:\n        \"\"\"\n        List the base names of the direct children of this L{FilePath}.\n\n        @return: A L{list} of L{bytes}/L{unicode} giving the names of the\n            contents of the directory this L{FilePath} refers to. These names\n            are relative to this L{FilePath}.\n        @rtype: L{list}\n\n        @raise OSError: Any exception the platform L{os.listdir} implementation\n            may raise.\n        \"\"\"\n        return listdir(self.path)\n\n    def splitext(self) -> Tuple[AnyStr, AnyStr]:\n        \"\"\"\n        Split the file path into a pair C{(root, ext)} such that\n        C{root + ext == path}.\n\n        @return: Tuple where the first item is the filename and second item is\n            the file extension. See Python docs for L{os.path.splitext}.\n        @rtype: L{tuple}\n        \"\"\"\n        return splitext(self.path)\n\n    def __repr__(self) -> str:\n        return f\"FilePath({self.path!r})\"\n\n    def touch(self) -> None:\n        \"\"\"\n        Updates the access and last modification times of the file at this\n        file path to the current time. Also creates the file if it does not\n        already exist.\n\n        @raise Exception: if unable to create or modify the last modification\n            time of the file.\n        \"\"\"\n        try:\n            self.open(\"a\").close()\n        except OSError:\n            pass\n        utime(self.path, None)\n\n    def remove(self) -> None:\n        \"\"\"\n        Removes the file or directory that is represented by self.  If\n        C{self.path} is a directory, recursively remove all its children\n        before removing the directory. If it's a file or link, just delete it.\n        \"\"\"\n        if self.isdir() and not self.islink():\n            for child in self.children():\n                child.remove()\n            os.rmdir(self.path)\n        else:\n            os.remove(self.path)\n        self.changed()\n\n    def makedirs(self, ignoreExistingDirectory: bool = False) -> None:\n        \"\"\"\n        Create all directories not yet existing in C{path} segments, using\n        L{os.makedirs}.\n\n        @param ignoreExistingDirectory: Don't raise L{OSError} if directory\n            already exists.\n        @type ignoreExistingDirectory: L{bool}\n\n        @return: L{None}\n        \"\"\"\n        try:\n            os.makedirs(self.path)\n        except OSError as e:\n            if not (\n                e.errno == errno.EEXIST and ignoreExistingDirectory and self.isdir()\n            ):\n                raise\n\n    def globChildren(self, pattern: OtherAnyStr) -> List[FilePath[OtherAnyStr]]:\n        \"\"\"\n        Assuming I am representing a directory, return a list of FilePaths\n        representing my children that match the given pattern.\n\n        @param pattern: A glob pattern to use to match child paths.\n        @type pattern: L{unicode} or L{bytes}\n\n        @return: A L{list} of matching children.\n        @rtype: L{list} of L{FilePath}, with the mode of C{pattern}'s type\n        \"\"\"\n        sep = _coerceToFilesystemEncoding(pattern, os.sep)\n        ourPath = self._getPathAsSameTypeAs(pattern)\n\n        import glob\n\n        path = ourPath[-1] == sep and ourPath + pattern or sep.join([ourPath, pattern])\n        return [self.clonePath(p) for p in glob.glob(path)]\n\n    def basename(self) -> AnyStr:\n        \"\"\"\n        Retrieve the final component of the file path's path (everything\n        after the final path separator).\n\n        @return: The final component of the L{FilePath}'s path (Everything\n            after the final path separator).\n        @rtype: the same type as this L{FilePath}'s C{path} attribute\n        \"\"\"\n        return basename(self.path)\n\n    def dirname(self) -> AnyStr:\n        \"\"\"\n        Retrieve all of the components of the L{FilePath}'s path except the\n        last one (everything up to the final path separator).\n\n        @return: All of the components of the L{FilePath}'s path except the\n            last one (everything up to the final path separator).\n        @rtype: the same type as this L{FilePath}'s C{path} attribute\n        \"\"\"\n        return dirname(self.path)\n\n    def parent(self) -> FilePath[AnyStr]:\n        \"\"\"\n        A file path for the directory containing the file at this file path.\n\n        @return: A L{FilePath} representing the path which directly contains\n            this L{FilePath}.\n        @rtype: L{FilePath}\n        \"\"\"\n        return self.clonePath(self.dirname())\n\n    def setContent(self, content: bytes, ext: Union[str, bytes] = \".new\") -> None:\n        \"\"\"\n        Replace the file at this path with a new file that contains the given\n        bytes, trying to avoid data-loss in the meanwhile.\n\n        On UNIX-like platforms, this method does its best to ensure that by the\n        time this method returns, either the old contents I{or} the new\n        contents of the file will be present at this path for subsequent\n        readers regardless of premature device removal, program crash, or power\n        loss, making the following assumptions:\n\n            - your filesystem is journaled (i.e. your filesystem will not\n              I{itself} lose data due to power loss)\n\n            - your filesystem's C{rename()} is atomic\n\n            - your filesystem will not discard new data while preserving new\n              metadata (see U{http://mjg59.livejournal.com/108257.html} for\n              more detail)\n\n        On most versions of Windows there is no atomic C{rename()} (see\n        U{http://bit.ly/win32-overwrite} for more information), so this method\n        is slightly less helpful.  There is a small window where the file at\n        this path may be deleted before the new file is moved to replace it:\n        however, the new file will be fully written and flushed beforehand so\n        in the unlikely event that there is a crash at that point, it should be\n        possible for the user to manually recover the new version of their\n        data.  In the future, Twisted will support atomic file moves on those\n        versions of Windows which I{do} support them: see U{Twisted ticket\n        3004<http://twistedmatrix.com/trac/ticket/3004>}.\n\n        This method should be safe for use by multiple concurrent processes,\n        but note that it is not easy to predict which process's contents will\n        ultimately end up on disk if they invoke this method at close to the\n        same time.\n\n        @param content: The desired contents of the file at this path.\n        @type content: L{bytes}\n\n        @param ext: An extension to append to the temporary filename used to\n            store the bytes while they are being written.  This can be used to\n            make sure that temporary files can be identified by their suffix,\n            for cleanup in case of crashes.\n        @type ext: L{bytes}\n        \"\"\"\n        sib = self.temporarySibling(ext)\n        with sib.open(\"w\") as f:\n            f.write(content)\n        if platform.isWindows() and exists(self.path):\n            os.unlink(self.path)\n        os.rename(sib.path, self.asBytesMode().path)\n\n    def __cmp__(self, other: object) -> int:\n        if not isinstance(other, FilePath):\n            return NotImplemented\n        return cmp(self.path, other.path)\n\n    def createDirectory(self) -> None:\n        \"\"\"\n        Create the directory the L{FilePath} refers to.\n\n        @see: L{makedirs}\n\n        @raise OSError: If the directory cannot be created.\n        \"\"\"\n        os.mkdir(self.path)\n\n    def requireCreate(self, val: bool = True) -> None:\n        \"\"\"\n        Sets the C{alwaysCreate} variable.\n\n        @param val: C{True} or C{False}, indicating whether opening this path\n            will be required to create the file or not.\n        @type val: L{bool}\n\n        @return: L{None}\n        \"\"\"\n        self.alwaysCreate = val\n\n    def create(self) -> IO[bytes]:\n        \"\"\"\n        Exclusively create a file, only if this file previously did not exist.\n\n        @return: A file-like object opened from this path.\n        \"\"\"\n        fdint = os.open(self.path, _CREATE_FLAGS)\n\n        # XXX TODO: 'name' attribute of returned files is not mutable or\n        # settable via fdopen, so this file is slightly less functional than the\n        # one returned from 'open' by default.  send a patch to Python...\n\n        return cast(IO[bytes], os.fdopen(fdint, \"w+b\"))\n\n    @overload\n    def temporarySibling(self) -> FilePath[AnyStr]:\n        ...\n\n    @overload\n    def temporarySibling(\n        self, extension: Optional[OtherAnyStr]\n    ) -> FilePath[OtherAnyStr]:\n        ...\n\n    def temporarySibling(\n        self, extension: Optional[OtherAnyStr] = None\n    ) -> FilePath[OtherAnyStr]:\n        \"\"\"\n        Construct a path referring to a sibling of this path.\n\n        The resulting path will be unpredictable, so that other subprocesses\n        should neither accidentally attempt to refer to the same path before it\n        is created, nor they should other processes be able to guess its name\n        in advance.\n\n        @param extension: A suffix to append to the created filename.  (Note\n            that if you want an extension with a '.' you must include the '.'\n            yourself.)\n        @type extension: L{bytes} or L{unicode}\n\n        @return: a path object with the given extension suffix, C{alwaysCreate}\n            set to True.\n        @rtype: L{FilePath} with a mode equal to the type of C{extension}\n        \"\"\"\n        ext: OtherAnyStr\n        if extension is None:\n            # It's not possible to provide a default type argument which is why\n            # the overload is required.\n            ext = self.path[0:0]  # type:ignore[assignment]\n        else:\n            ext = extension\n        ourPath = self._getPathAsSameTypeAs(ext)\n        sib = self.sibling(\n            _secureEnoughString(ourPath) + self.clonePath(ourPath).basename() + ext\n        )\n        sib.requireCreate()\n        return sib\n\n    _chunkSize = 2**2**2**2\n\n    def copyTo(\n        self, destination: FilePath[OtherAnyStr], followLinks: bool = True\n    ) -> None:\n        \"\"\"\n        Copies self to destination.\n\n        If self doesn't exist, an OSError is raised.\n\n        If self is a directory, this method copies its children (but not\n        itself) recursively to destination - if destination does not exist as a\n        directory, this method creates it.  If destination is a file, an\n        IOError will be raised.\n\n        If self is a file, this method copies it to destination.  If\n        destination is a file, this method overwrites it.  If destination is a\n        directory, an IOError will be raised.\n\n        If self is a link (and followLinks is False), self will be copied\n        over as a new symlink with the same target as returned by os.readlink.\n        That means that if it is absolute, both the old and new symlink will\n        link to the same thing.  If it's relative, then perhaps not (and\n        it's also possible that this relative link will be broken).\n\n        File/directory permissions and ownership will NOT be copied over.\n\n        If followLinks is True, symlinks are followed so that they're treated\n        as their targets.  In other words, if self is a link, the link's target\n        will be copied.  If destination is a link, self will be copied to the\n        destination's target (the actual destination will be destination's\n        target).  Symlinks under self (if self is a directory) will be\n        followed and its target's children be copied recursively.\n\n        If followLinks is False, symlinks will be copied over as symlinks.\n\n        @param destination: the destination (a FilePath) to which self\n            should be copied\n        @param followLinks: whether symlinks in self should be treated as links\n            or as their targets\n        \"\"\"\n        if self.islink() and not followLinks:\n            os.symlink(os.readlink(self.path), destination.path)\n            return\n        # XXX TODO: *thorough* audit and documentation of the exact desired\n        # semantics of this code.  Right now the behavior of existent\n        # destination symlinks is convenient, and quite possibly correct, but\n        # its security properties need to be explained.\n        if self.isdir():\n            if not destination.exists():\n                destination.createDirectory()\n            for child in self.children():\n                destChild = destination.child(child.basename())\n                child.copyTo(destChild, followLinks)\n        elif self.isfile():\n            with destination.open(\"w\") as writefile, self.open() as readfile:\n                while 1:\n                    # XXX TODO: optionally use os.open, os.read and\n                    # O_DIRECT and use os.fstatvfs to determine chunk sizes\n                    # and make *****sure**** copy is page-atomic; the\n                    # following is good enough for 99.9% of everybody and\n                    # won't take a week to audit though.\n                    chunk = readfile.read(self._chunkSize)\n                    writefile.write(chunk)\n                    if len(chunk) < self._chunkSize:\n                        break\n        elif not self.exists():\n            raise OSError(errno.ENOENT, \"No such file or directory\")\n        else:\n            # If you see the following message because you want to copy\n            # symlinks, fifos, block devices, character devices, or unix\n            # sockets, please feel free to add support to do sensible things in\n            # reaction to those types!\n            raise NotImplementedError(\"Only copying of files and directories supported\")\n\n    def moveTo(\n        self, destination: FilePath[OtherAnyStr], followLinks: bool = True\n    ) -> None:\n        \"\"\"\n        Move self to destination - basically renaming self to whatever\n        destination is named.\n\n        If destination is an already-existing directory,\n        moves all children to destination if destination is empty.  If\n        destination is a non-empty directory, or destination is a file, an\n        OSError will be raised.\n\n        If moving between filesystems, self needs to be copied, and everything\n        that applies to copyTo applies to moveTo.\n\n        @param destination: the destination (a FilePath) to which self\n            should be copied\n        @param followLinks: whether symlinks in self should be treated as links\n            or as their targets (only applicable when moving between\n            filesystems)\n        \"\"\"\n        try:\n            os.rename(self._getPathAsSameTypeAs(destination.path), destination.path)\n        except OSError as ose:\n            if ose.errno == errno.EXDEV:\n                # man 2 rename, ubuntu linux 5.10 \"breezy\":\n\n                #   oldpath and newpath are not on the same mounted filesystem.\n                #   (Linux permits a filesystem to be mounted at multiple\n                #   points, but rename(2) does not work across different mount\n                #   points, even if the same filesystem is mounted on both.)\n\n                # that means it's time to copy trees of directories!\n                secsib = destination.temporarySibling()\n                self.copyTo(secsib, followLinks)  # slow\n                secsib.moveTo(destination, followLinks)  # visible\n\n                # done creating new stuff.  let's clean me up.\n                mysecsib = self.temporarySibling()\n                self.moveTo(mysecsib, followLinks)  # visible\n                mysecsib.remove()  # slow\n            else:\n                raise\n        else:\n            self.changed()\n            destination.changed()\n\n\n### Dependency File: interfaces.py\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nInterface documentation.\n\nMaintainer: Itamar Shtull-Trauring\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    AnyStr,\n    Callable,\n    Iterable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom zope.interface import Attribute, Interface\n\nfrom twisted.python.failure import Failure\n\nif TYPE_CHECKING:\n    from socket import AddressFamily\n\n    try:\n        from OpenSSL.SSL import (\n            Connection as OpenSSLConnection,\n            Context as OpenSSLContext,\n        )\n    except ImportError:\n        OpenSSLConnection = OpenSSLContext = object  # type: ignore[misc,assignment]\n\n    from twisted.internet.abstract import FileDescriptor\n    from twisted.internet.address import IPv4Address, IPv6Address, UNIXAddress\n    from twisted.internet.defer import Deferred\n    from twisted.internet.protocol import (\n        ClientFactory,\n        ConnectedDatagramProtocol,\n        DatagramProtocol,\n        Factory,\n        ServerFactory,\n    )\n    from twisted.internet.ssl import ClientContextFactory\n    from twisted.names.dns import Query, RRHeader\n    from twisted.protocols.tls import TLSMemoryBIOProtocol\n    from twisted.python.runtime import platform\n\n    if platform.supportsThreads():\n        from twisted.python.threadpool import ThreadPool\n    else:\n        ThreadPool = object  # type: ignore[misc, assignment]\n\n\nclass IAddress(Interface):\n    \"\"\"\n    An address, e.g. a TCP C{(host, port)}.\n\n    Default implementations are in L{twisted.internet.address}.\n    \"\"\"\n\n\n### Reactor Interfaces\n\n\nclass IConnector(Interface):\n    \"\"\"\n    Object used to interface between connections and protocols.\n\n    Each L{IConnector} manages one connection.\n    \"\"\"\n\n    def stopConnecting() -> None:\n        \"\"\"\n        Stop attempting to connect.\n        \"\"\"\n\n    def disconnect() -> None:\n        \"\"\"\n        Disconnect regardless of the connection state.\n\n        If we are connected, disconnect, if we are trying to connect,\n        stop trying.\n        \"\"\"\n\n    def connect() -> None:\n        \"\"\"\n        Try to connect to remote address.\n        \"\"\"\n\n    def getDestination() -> IAddress:\n        \"\"\"\n        Return destination this will try to connect to.\n\n        @return: An object which provides L{IAddress}.\n        \"\"\"\n\n\nclass IResolverSimple(Interface):\n    def getHostByName(name: str, timeout: Sequence[int] = ()) -> \"Deferred[str]\":\n        \"\"\"\n        Resolve the domain name C{name} into an IP address.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: The callback of the Deferred that is returned will be\n            passed a string that represents the IP address of the\n            specified name, or the errback will be called if the\n            lookup times out.  If multiple types of address records\n            are associated with the name, A6 records will be returned\n            in preference to AAAA records, which will be returned in\n            preference to A records.  If there are multiple records of\n            the type to be returned, one will be selected at random.\n\n        @raise twisted.internet.defer.TimeoutError: Raised\n            (asynchronously) if the name cannot be resolved within the\n            specified timeout period.\n        \"\"\"\n\n\nclass IHostResolution(Interface):\n    \"\"\"\n    An L{IHostResolution} represents represents an in-progress recursive query\n    for a DNS name.\n\n    @since: Twisted 17.1.0\n    \"\"\"\n\n    name = Attribute(\n        \"\"\"\n        L{unicode}; the name of the host being resolved.\n        \"\"\"\n    )\n\n    def cancel() -> None:\n        \"\"\"\n        Stop the hostname resolution in progress.\n        \"\"\"\n\n\nclass IResolutionReceiver(Interface):\n    \"\"\"\n    An L{IResolutionReceiver} receives the results of a hostname resolution in\n    progress, initiated by an L{IHostnameResolver}.\n\n    @since: Twisted 17.1.0\n    \"\"\"\n\n    def resolutionBegan(resolutionInProgress: IHostResolution) -> None:\n        \"\"\"\n        A hostname resolution began.\n\n        @param resolutionInProgress: an L{IHostResolution}.\n        \"\"\"\n\n    def addressResolved(address: IAddress) -> None:\n        \"\"\"\n        An internet address.  This is called when an address for the given name\n        is discovered.  In the current implementation this practically means\n        L{IPv4Address} or L{IPv6Address}, but implementations of this interface\n        should be lenient to other types being passed to this interface as\n        well, for future-proofing.\n\n        @param address: An address object.\n        \"\"\"\n\n    def resolutionComplete() -> None:\n        \"\"\"\n        Resolution has completed; no further addresses will be relayed to\n        L{IResolutionReceiver.addressResolved}.\n        \"\"\"\n\n\nclass IHostnameResolver(Interface):\n    \"\"\"\n    An L{IHostnameResolver} can resolve a host name and port number into a\n    series of L{IAddress} objects.\n\n    @since: Twisted 17.1.0\n    \"\"\"\n\n    def resolveHostName(\n        resolutionReceiver: IResolutionReceiver,\n        hostName: str,\n        portNumber: int = 0,\n        addressTypes: Optional[Sequence[Type[IAddress]]] = None,\n        transportSemantics: str = \"TCP\",\n    ) -> IHostResolution:\n        \"\"\"\n        Initiate a hostname resolution.\n\n        @param resolutionReceiver: an object that will receive each resolved\n            address as it arrives.\n        @param hostName: The name of the host to resolve.  If this contains\n            non-ASCII code points, they will be converted to IDNA first.\n        @param portNumber: The port number that the returned addresses should\n            include.\n        @param addressTypes: An iterable of implementors of L{IAddress} that\n            are acceptable values for C{resolutionReceiver} to receive to its\n            L{addressResolved <IResolutionReceiver.addressResolved>}.  In\n            practice, this means an iterable containing\n            L{twisted.internet.address.IPv4Address},\n            L{twisted.internet.address.IPv6Address}, both, or neither.\n        @param transportSemantics: A string describing the semantics of the\n            transport; either C{'TCP'} for stream-oriented transports or\n            C{'UDP'} for datagram-oriented; see\n            L{twisted.internet.address.IPv6Address.type} and\n            L{twisted.internet.address.IPv4Address.type}.\n\n        @return: The resolution in progress.\n        \"\"\"\n\n\nclass IResolver(IResolverSimple):\n    def query(\n        query: \"Query\", timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Dispatch C{query} to the method which can handle its type.\n\n        @param query: The DNS query being issued, to which a response is to be\n            generated.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupAddress(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an A record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupAddress6(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an A6 record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupIPV6Address(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an AAAA record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupMailExchange(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an MX record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupNameservers(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an NS record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupCanonicalName(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a CNAME record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupMailBox(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an MB record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupMailGroup(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an MG record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupMailRename(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an MR record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupPointer(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a PTR record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupAuthority(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an SOA record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupNull(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a NULL record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupWellKnownServices(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a WKS record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupHostInfo(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a HINFO record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupMailboxInfo(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an MINFO record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupText(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a TXT record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupResponsibility(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an RP record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupAFSDatabase(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an AFSDB record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupService(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an SRV record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupAllRecords(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an ALL_RECORD lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupSenderPolicy(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a SPF record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupNamingAuthorityPointer(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform a NAPTR record lookup.\n\n        @param name: DNS name to resolve.\n        @param timeout: Number of seconds after which to reissue the query.\n            When the last timeout expires, the query is considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.  The first element of the\n            tuple gives answers.  The second element of the tuple gives\n            authorities.  The third element of the tuple gives additional\n            information.  The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n    def lookupZone(\n        name: str, timeout: Sequence[int]\n    ) -> \"Deferred[Tuple[RRHeader, RRHeader, RRHeader]]\":\n        \"\"\"\n        Perform an AXFR record lookup.\n\n        NB This is quite different from other DNS requests. See\n        U{http://cr.yp.to/djbdns/axfr-notes.html} for more\n        information.\n\n        NB Unlike other C{lookup*} methods, the timeout here is not a\n        list of ints, it is a single int.\n\n        @param name: DNS name to resolve.\n        @param timeout: When this timeout expires, the query is\n            considered failed.\n\n        @return: A L{Deferred} which fires with a three-tuple of lists of\n            L{twisted.names.dns.RRHeader} instances.\n            The first element of the tuple gives answers.\n            The second and third elements are always empty.\n            The L{Deferred} may instead fail with one of the\n            exceptions defined in L{twisted.names.error} or with\n            C{NotImplementedError}.\n        \"\"\"\n\n\nclass IReactorTCP(Interface):\n    def listenTCP(\n        port: int,\n        factory: \"ServerFactory\",\n        backlog: int = 50,\n        interface: str = \"\",\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Connects a given protocol factory to the given numeric TCP/IP port.\n\n        @param port: a port number on which to listen\n        @param factory: a L{twisted.internet.protocol.ServerFactory} instance\n        @param backlog: size of the listen queue\n        @param interface: The local IPv4 or IPv6 address to which to bind;\n            defaults to '', ie all IPv4 addresses.  To bind to all IPv4 and IPv6\n            addresses, you must call this method twice.\n\n        @return: an object that provides L{IListeningPort}.\n\n        @raise CannotListenError: as defined here\n                                  L{twisted.internet.error.CannotListenError},\n                                  if it cannot listen on this port (e.g., it\n                                  cannot bind to the required port number)\n        \"\"\"\n\n    def connectTCP(\n        host: str,\n        port: int,\n        factory: \"ClientFactory\",\n        timeout: float = 30.0,\n        bindAddress: Optional[Tuple[str, int]] = None,\n    ) -> IConnector:\n        \"\"\"\n        Connect a TCP client.\n\n        @param host: A hostname or an IPv4 or IPv6 address literal.\n        @param port: a port number\n        @param factory: a L{twisted.internet.protocol.ClientFactory} instance\n        @param timeout: number of seconds to wait before assuming the\n                        connection has failed.\n        @param bindAddress: a (host, port) tuple of local address to bind\n                            to, or None.\n\n        @return: An object which provides L{IConnector}. This connector will\n                 call various callbacks on the factory when a connection is\n                 made, failed, or lost - see\n                 L{ClientFactory<twisted.internet.protocol.ClientFactory>}\n                 docs for details.\n        \"\"\"\n\n\nclass IReactorSSL(Interface):\n    def connectSSL(\n        host: str,\n        port: int,\n        factory: \"ClientFactory\",\n        contextFactory: \"ClientContextFactory\",\n        timeout: float,\n        bindAddress: Optional[Tuple[str, int]],\n    ) -> IConnector:\n        \"\"\"\n        Connect a client Protocol to a remote SSL socket.\n\n        @param host: a host name\n        @param port: a port number\n        @param factory: a L{twisted.internet.protocol.ClientFactory} instance\n        @param contextFactory: a L{twisted.internet.ssl.ClientContextFactory} object.\n        @param timeout: number of seconds to wait before assuming the\n                        connection has failed.\n        @param bindAddress: a (host, port) tuple of local address to bind to,\n                            or L{None}.\n\n        @return: An object which provides L{IConnector}.\n        \"\"\"\n\n    def listenSSL(\n        port: int,\n        factory: \"ServerFactory\",\n        contextFactory: \"IOpenSSLContextFactory\",\n        backlog: int,\n        interface: str,\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Connects a given protocol factory to the given numeric TCP/IP port.\n        The connection is a SSL one, using contexts created by the context\n        factory.\n\n        @param port: a port number on which to listen\n        @param factory: a L{twisted.internet.protocol.ServerFactory} instance\n        @param contextFactory: an implementor of L{IOpenSSLContextFactory}\n        @param backlog: size of the listen queue\n        @param interface: the hostname to bind to, defaults to '' (all)\n        \"\"\"\n\n\nclass IReactorUNIX(Interface):\n    \"\"\"\n    UNIX socket methods.\n    \"\"\"\n\n    def connectUNIX(\n        address: str,\n        factory: \"ClientFactory\",\n        timeout: float = 30,\n        checkPID: bool = False,\n    ) -> IConnector:\n        \"\"\"\n        Connect a client protocol to a UNIX socket.\n\n        @param address: a path to a unix socket on the filesystem.\n        @param factory: a L{twisted.internet.protocol.ClientFactory} instance\n        @param timeout: number of seconds to wait before assuming the connection\n            has failed.\n        @param checkPID: if True, check for a pid file to verify that a server\n            is listening.  If C{address} is a Linux abstract namespace path,\n            this must be C{False}.\n\n        @return: An object which provides L{IConnector}.\n        \"\"\"\n\n    def listenUNIX(\n        address: str,\n        factory: \"Factory\",\n        backlog: int = 50,\n        mode: int = 0o666,\n        wantPID: bool = False,\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Listen on a UNIX socket.\n\n        @param address: a path to a unix socket on the filesystem.\n        @param factory: a L{twisted.internet.protocol.Factory} instance.\n        @param backlog: number of connections to allow in backlog.\n        @param mode: The mode (B{not} umask) to set on the unix socket.  See\n            platform specific documentation for information about how this\n            might affect connection attempts.\n        @param wantPID: if True, create a pidfile for the socket.  If C{address}\n            is a Linux abstract namespace path, this must be C{False}.\n\n        @return: An object which provides L{IListeningPort}.\n        \"\"\"\n\n\nclass IReactorUNIXDatagram(Interface):\n    \"\"\"\n    Datagram UNIX socket methods.\n    \"\"\"\n\n    def connectUNIXDatagram(\n        address: str,\n        protocol: \"ConnectedDatagramProtocol\",\n        maxPacketSize: int,\n        mode: int,\n        bindAddress: Optional[Tuple[str, int]],\n    ) -> IConnector:\n        \"\"\"\n        Connect a client protocol to a datagram UNIX socket.\n\n        @param address: a path to a unix socket on the filesystem.\n        @param protocol: a L{twisted.internet.protocol.ConnectedDatagramProtocol} instance\n        @param maxPacketSize: maximum packet size to accept\n        @param mode: The mode (B{not} umask) to set on the unix socket.  See\n            platform specific documentation for information about how this\n            might affect connection attempts.\n\n        @param bindAddress: address to bind to\n\n        @return: An object which provides L{IConnector}.\n        \"\"\"\n\n    def listenUNIXDatagram(\n        address: str, protocol: \"DatagramProtocol\", maxPacketSize: int, mode: int\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Listen on a datagram UNIX socket.\n\n        @param address: a path to a unix socket on the filesystem.\n        @param protocol: a L{twisted.internet.protocol.DatagramProtocol} instance.\n        @param maxPacketSize: maximum packet size to accept\n        @param mode: The mode (B{not} umask) to set on the unix socket.  See\n            platform specific documentation for information about how this\n            might affect connection attempts.\n\n        @return: An object which provides L{IListeningPort}.\n        \"\"\"\n\n\nclass IReactorWin32Events(Interface):\n    \"\"\"\n    Win32 Event API methods\n\n    @since: 10.2\n    \"\"\"\n\n    def addEvent(event: object, fd: \"FileDescriptor\", action: str) -> None:\n        \"\"\"\n        Add a new win32 event to the event loop.\n\n        @param event: a Win32 event object created using win32event.CreateEvent()\n        @param fd: an instance of L{twisted.internet.abstract.FileDescriptor}\n        @param action: a string that is a method name of the fd instance.\n                       This method is called in response to the event.\n        \"\"\"\n\n    def removeEvent(event: object) -> None:\n        \"\"\"\n        Remove an event.\n\n        @param event: a Win32 event object added using L{IReactorWin32Events.addEvent}\n\n        @return: None\n        \"\"\"\n\n\nclass IReactorUDP(Interface):\n    \"\"\"\n    UDP socket methods.\n    \"\"\"\n\n    def listenUDP(\n        port: int, protocol: \"DatagramProtocol\", interface: str, maxPacketSize: int\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Connects a given L{DatagramProtocol} to the given numeric UDP port.\n\n        @param port: A port number on which to listen.\n        @param protocol: A L{DatagramProtocol} instance which will be\n            connected to the given C{port}.\n        @param interface: The local IPv4 or IPv6 address to which to bind;\n            defaults to '', ie all IPv4 addresses.\n        @param maxPacketSize: The maximum packet size to accept.\n\n        @return: object which provides L{IListeningPort}.\n        \"\"\"\n\n\nclass IReactorMulticast(Interface):\n    \"\"\"\n    UDP socket methods that support multicast.\n\n    IMPORTANT: This is an experimental new interface. It may change\n    without backwards compatibility. Suggestions are welcome.\n    \"\"\"\n\n    def listenMulticast(\n        port: int,\n        protocol: \"DatagramProtocol\",\n        interface: str = \"\",\n        maxPacketSize: int = 8192,\n        listenMultiple: bool = False,\n    ) -> IMulticastTransport:\n        \"\"\"\n        Connects a given\n        L{DatagramProtocol<twisted.internet.protocol.DatagramProtocol>} to the\n        given numeric UDP port.\n\n        @param port: The port number to bind to.\n\n        @param protocol: the datagram receiver that will receive multicast\n            packets sent to the given interface and port.\n\n        @param interface: The IP address literal of the network interface to\n            bind to.  By default, this will be C{\"0.0.0.0\"}, i.e. all IPv4\n            interfaces.  Note that the format of this literal determines the\n            address family of the resulting multicast transport: passing an\n            IPv6 literal, such as C{\"::\"}, will result in an IPv6 multicast\n            transport.\n\n        @param maxPacketSize: The maximum packet size to accept.\n\n        @param listenMultiple: If set to True, allows multiple sockets to bind\n            to the same address and port number at the same time.\n\n        @returns: An L{IMulticastTransport} that can send multicast traffic to\n            C{interface}.\n\n        @see: U{http://twistedmatrix.com/documents/current/core/howto/udp.html}\n        \"\"\"\n\n\nclass IReactorSocket(Interface):\n    \"\"\"\n    Methods which allow a reactor to use externally created sockets.\n\n    For example, to use C{adoptStreamPort} to implement behavior equivalent\n    to that of L{IReactorTCP.listenTCP}, you might write code like this::\n\n        from socket import SOMAXCONN, AF_INET, SOCK_STREAM, socket\n        portSocket = socket(AF_INET, SOCK_STREAM)\n        # Set FD_CLOEXEC on port, left as an exercise.  Then make it into a\n        # non-blocking listening port:\n        portSocket.setblocking(False)\n        portSocket.bind(('192.168.1.2', 12345))\n        portSocket.listen(SOMAXCONN)\n\n        # Now have the reactor use it as a TCP port\n        port = reactor.adoptStreamPort(\n            portSocket.fileno(), AF_INET, YourFactory())\n\n        # portSocket itself is no longer necessary, and needs to be cleaned\n        # up by us.\n        portSocket.close()\n\n        # Whenever the server is no longer needed, stop it as usual.\n        stoppedDeferred = port.stopListening()\n\n    Another potential use is to inherit a listening descriptor from a parent\n    process (for example, systemd or launchd), or to receive one over a UNIX\n    domain socket.\n\n    Some plans for extending this interface exist.  See:\n\n        - U{http://twistedmatrix.com/trac/ticket/6594}: AF_UNIX SOCK_DGRAM ports\n    \"\"\"\n\n    def adoptStreamPort(\n        fileDescriptor: int, addressFamily: \"AddressFamily\", factory: \"ServerFactory\"\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Add an existing listening I{SOCK_STREAM} socket to the reactor to\n        monitor for new connections to accept and handle.\n\n        @param fileDescriptor: A file descriptor associated with a socket which\n            is already bound to an address and marked as listening.  The socket\n            must be set non-blocking.  Any additional flags (for example,\n            close-on-exec) must also be set by application code.  Application\n            code is responsible for closing the file descriptor, which may be\n            done as soon as C{adoptStreamPort} returns.\n        @param addressFamily: The address family (or I{domain}) of the socket.\n            For example, L{socket.AF_INET6}.\n        @param factory: A L{ServerFactory} instance to use to create new\n            protocols to handle connections accepted via this socket.\n\n        @return: An object providing L{IListeningPort}.\n\n        @raise twisted.internet.error.UnsupportedAddressFamily: If the\n            given address family is not supported by this reactor, or\n            not supported with the given socket type.\n        @raise twisted.internet.error.UnsupportedSocketType: If the\n            given socket type is not supported by this reactor, or not\n            supported with the given socket type.\n        \"\"\"\n\n    def adoptStreamConnection(\n        fileDescriptor: int, addressFamily: \"AddressFamily\", factory: \"ServerFactory\"\n    ) -> None:\n        \"\"\"\n        Add an existing connected I{SOCK_STREAM} socket to the reactor to\n        monitor for data.\n\n        Note that the given factory won't have its C{startFactory} and\n        C{stopFactory} methods called, as there is no sensible time to call\n        them in this situation.\n\n        @param fileDescriptor: A file descriptor associated with a socket which\n            is already connected.  The socket must be set non-blocking.  Any\n            additional flags (for example, close-on-exec) must also be set by\n            application code.  Application code is responsible for closing the\n            file descriptor, which may be done as soon as\n            C{adoptStreamConnection} returns.\n        @param addressFamily: The address family (or I{domain}) of the socket.\n            For example, L{socket.AF_INET6}.\n        @param factory: A L{ServerFactory} instance to use to create a new\n            protocol to handle the connection via this socket.\n\n        @raise UnsupportedAddressFamily: If the given address family is not\n            supported by this reactor, or not supported with the given socket\n            type.\n        @raise UnsupportedSocketType: If the given socket type is not supported\n            by this reactor, or not supported with the given socket type.\n        \"\"\"\n\n    def adoptDatagramPort(\n        fileDescriptor: int,\n        addressFamily: \"AddressFamily\",\n        protocol: \"DatagramProtocol\",\n        maxPacketSize: int,\n    ) -> \"IListeningPort\":\n        \"\"\"\n        Add an existing listening I{SOCK_DGRAM} socket to the reactor to\n        monitor for read and write readiness.\n\n        @param fileDescriptor: A file descriptor associated with a socket which\n            is already bound to an address and marked as listening.  The socket\n            must be set non-blocking.  Any additional flags (for example,\n            close-on-exec) must also be set by application code.  Application\n            code is responsible for closing the file descriptor, which may be\n            done as soon as C{adoptDatagramPort} returns.\n        @param addressFamily: The address family or I{domain} of the socket.\n            For example, L{socket.AF_INET6}.\n        @param protocol: A L{DatagramProtocol} instance to connect to\n            a UDP transport.\n        @param maxPacketSize: The maximum packet size to accept.\n\n        @return: An object providing L{IListeningPort}.\n\n        @raise UnsupportedAddressFamily: If the given address family is not\n            supported by this reactor, or not supported with the given socket\n            type.\n        @raise UnsupportedSocketType: If the given socket type is not supported\n            by this reactor, or not supported with the given socket type.\n        \"\"\"\n\n\nclass IReactorProcess(Interface):\n    def spawnProcess(\n        processProtocol: \"IProcessProtocol\",\n        executable: Union[bytes, str],\n        args: Sequence[Union[bytes, str]],\n        env: Optional[Mapping[AnyStr, AnyStr]] = None,\n        path: Union[None, bytes, str] = None,\n        uid: Optional[int] = None,\n        gid: Optional[int] = None,\n        usePTY: bool = False,\n        childFDs: Optional[Mapping[int, Union[int, str]]] = None,\n    ) -> \"IProcessTransport\":\n        \"\"\"\n        Spawn a process, with a process protocol.\n\n        Arguments given to this function that are listed as L{bytes} or\n        L{unicode} may be encoded or decoded depending on the platform and the\n        argument type given.  On UNIX systems (Linux, FreeBSD, macOS) and\n        Python 2 on Windows, L{unicode} arguments will be encoded down to\n        L{bytes} using the encoding given by L{sys.getfilesystemencoding}, to be\n        used with the \"narrow\" OS APIs.  On Python 3 on Windows, L{bytes}\n        arguments will be decoded up to L{unicode} using the encoding given by\n        L{sys.getfilesystemencoding} (C{utf8}) and given to Windows's native \"wide\" APIs.\n\n        @param processProtocol: An object which will be notified of all events\n            related to the created process.\n\n        @param executable: the file name to spawn - the full path should be\n            used.\n\n        @param args: the command line arguments to pass to the process; a\n            sequence of strings.  The first string should be the executable's\n            name.\n\n        @param env: the environment variables to pass to the child process.\n            The resulting behavior varies between platforms.  If:\n\n                - C{env} is not set:\n                  - On POSIX: pass an empty environment.\n                  - On Windows: pass L{os.environ}.\n                - C{env} is L{None}:\n                  - On POSIX: pass L{os.environ}.\n                  - On Windows: pass L{os.environ}.\n                - C{env} is a L{dict}:\n                  - On POSIX: pass the key/value pairs in C{env} as the\n                    complete environment.\n                  - On Windows: update L{os.environ} with the key/value\n                    pairs in the L{dict} before passing it. As a\n                    consequence of U{bug #1640\n                    <http://twistedmatrix.com/trac/ticket/1640>}, passing\n                    keys with empty values in an effort to unset\n                    environment variables I{won't} unset them.\n\n        @param path: the path to run the subprocess in - defaults to the\n            current directory.\n\n        @param uid: user ID to run the subprocess as.  (Only available on POSIX\n            systems.)\n\n        @param gid: group ID to run the subprocess as.  (Only available on\n            POSIX systems.)\n\n        @param usePTY: if true, run this process in a pseudo-terminal.\n            optionally a tuple of C{(masterfd, slavefd, ttyname)}, in which\n            case use those file descriptors.  (Not available on all systems.)\n\n        @param childFDs: A dictionary mapping file descriptors in the new child\n            process to an integer or to the string 'r' or 'w'.\n\n            If the value is an integer, it specifies a file descriptor in the\n            parent process which will be mapped to a file descriptor (specified\n            by the key) in the child process.  This is useful for things like\n            inetd and shell-like file redirection.\n\n            If it is the string 'r', a pipe will be created and attached to the\n            child at that file descriptor: the child will be able to write to\n            that file descriptor and the parent will receive read notification\n            via the L{IProcessProtocol.childDataReceived} callback.  This is\n            useful for the child's stdout and stderr.\n\n            If it is the string 'w', similar setup to the previous case will\n            occur, with the pipe being readable by the child instead of\n            writeable.  The parent process can write to that file descriptor\n            using L{IProcessTransport.writeToChild}.  This is useful for the\n            child's stdin.\n\n            If childFDs is not passed, the default behaviour is to use a\n            mapping that opens the usual stdin/stdout/stderr pipes.\n\n        @see: L{twisted.internet.protocol.ProcessProtocol}\n\n        @return: An object which provides L{IProcessTransport}.\n\n        @raise OSError: Raised with errno C{EAGAIN} or C{ENOMEM} if there are\n            insufficient system resources to create a new process.\n        \"\"\"\n\n\nclass IReactorTime(Interface):\n    \"\"\"\n    Time methods that a Reactor should implement.\n    \"\"\"\n\n    def seconds() -> float:\n        \"\"\"\n        Get the current time in seconds.\n\n        @return: A number-like object of some sort.\n        \"\"\"\n\n    def callLater(\n        delay: float, callable: Callable[..., Any], *args: object, **kwargs: object\n    ) -> \"IDelayedCall\":\n        \"\"\"\n        Call a function later.\n\n        @param delay: the number of seconds to wait.\n        @param callable: the callable object to call later.\n        @param args: the arguments to call it with.\n        @param kwargs: the keyword arguments to call it with.\n\n        @return: An object which provides L{IDelayedCall} and can be used to\n                 cancel the scheduled call, by calling its C{cancel()} method.\n                 It also may be rescheduled by calling its C{delay()} or\n                 C{reset()} methods.\n        \"\"\"\n\n    def getDelayedCalls() -> Sequence[\"IDelayedCall\"]:\n        \"\"\"\n        See L{twisted.internet.interfaces.IReactorTime.getDelayedCalls}\n        \"\"\"\n\n\nclass IDelayedCall(Interface):\n    \"\"\"\n    A scheduled call.\n\n    There are probably other useful methods we can add to this interface;\n    suggestions are welcome.\n    \"\"\"\n\n    def getTime() -> float:\n        \"\"\"\n        Get time when delayed call will happen.\n\n        @return: time in seconds since epoch (a float).\n        \"\"\"\n\n    def cancel() -> None:\n        \"\"\"\n        Cancel the scheduled call.\n\n        @raises twisted.internet.error.AlreadyCalled: if the call has already\n            happened.\n        @raises twisted.internet.error.AlreadyCancelled: if the call has already\n            been cancelled.\n        \"\"\"\n\n    def delay(secondsLater: float) -> None:\n        \"\"\"\n        Delay the scheduled call.\n\n        @param secondsLater: how many seconds from its current firing time to delay\n\n        @raises twisted.internet.error.AlreadyCalled: if the call has already\n            happened.\n        @raises twisted.internet.error.AlreadyCancelled: if the call has already\n            been cancelled.\n        \"\"\"\n\n    def reset(secondsFromNow: float) -> None:\n        \"\"\"\n        Reset the scheduled call's timer.\n\n        @param secondsFromNow: how many seconds from now it should fire,\n            equivalent to C{.cancel()} and then doing another\n            C{reactor.callLater(secondsLater, ...)}\n\n        @raises twisted.internet.error.AlreadyCalled: if the call has already\n            happened.\n        @raises twisted.internet.error.AlreadyCancelled: if the call has already\n            been cancelled.\n        \"\"\"\n\n    def active() -> bool:\n        \"\"\"\n        @return: True if this call is still active, False if it has been\n                 called or cancelled.\n        \"\"\"\n\n\nclass IReactorFromThreads(Interface):\n    \"\"\"\n    This interface is the set of thread-safe methods which may be invoked on\n    the reactor from other threads.\n\n    @since: 15.4\n    \"\"\"\n\n    def callFromThread(\n        callable: Callable[..., Any], *args: object, **kwargs: object\n    ) -> None:\n        \"\"\"\n        Cause a function to be executed by the reactor thread.\n\n        Use this method when you want to run a function in the reactor's thread\n        from another thread.  Calling L{callFromThread} should wake up the main\n        thread (where L{reactor.run() <IReactorCore.run>} is executing) and run\n        the given callable in that thread.\n\n        If you're writing a multi-threaded application the C{callable}\n        may need to be thread safe, but this method doesn't require it as such.\n        If you want to call a function in the next mainloop iteration, but\n        you're in the same thread, use L{callLater} with a delay of 0.\n        \"\"\"\n\n\nclass IReactorInThreads(Interface):\n    \"\"\"\n    This interface contains the methods exposed by a reactor which will let you\n    run functions in another thread.\n\n    @since: 15.4\n    \"\"\"\n\n    def callInThread(\n        callable: Callable[..., Any], *args: object, **kwargs: object\n    ) -> None:\n        \"\"\"\n        Run the given callable object in a separate thread, with the given\n        arguments and keyword arguments.\n        \"\"\"\n\n\nclass IReactorThreads(IReactorFromThreads, IReactorInThreads):\n    \"\"\"\n    Dispatch methods to be run in threads.\n\n    Internally, this should use a thread pool and dispatch methods to them.\n    \"\"\"\n\n    def getThreadPool() -> \"ThreadPool\":\n        \"\"\"\n        Return the threadpool used by L{IReactorInThreads.callInThread}.\n        Create it first if necessary.\n        \"\"\"\n\n    def suggestThreadPoolSize(size: int) -> None:\n        \"\"\"\n        Suggest the size of the internal threadpool used to dispatch functions\n        passed to L{IReactorInThreads.callInThread}.\n        \"\"\"\n\n\nclass IReactorCore(Interface):\n    \"\"\"\n    Core methods that a Reactor must implement.\n    \"\"\"\n\n    running = Attribute(\n        \"A C{bool} which is C{True} from I{during startup} to \"\n        \"I{during shutdown} and C{False} the rest of the time.\"\n    )\n\n    def resolve(name: str, timeout: Sequence[int] = (1, 3, 11, 45)) -> \"Deferred[str]\":\n        \"\"\"\n        Asynchronously resolve a hostname to a single IPv4 address.\n\n        @note: Rather than calling this API directly, you probably want to use\n            L{twisted.internet.endpoints.HostnameEndpoint} to connect to a\n            hostname.  If you do want to resolve a hostname without connecting\n            to it, see L{IReactorPluggableNameResolver} and\n            L{IHostnameResolver} so that you can receive multiple results and\n            IPv6 addresses.\n\n        @param name: The hostname to resolve.\n\n        @param timeout: A sequence of timeouts, meant to mirror the sequence of\n            timeouts used for each hop in recursive queries.  Note that\n            different implementations of the resolver backend may not honor\n            this timeout as such, or at all; if the underlying platform API\n            supports it, implementations make a best-effort attempt to cancel\n            the underlying resolution if the sum of these timeouts elapses.\n        \"\"\"\n\n    def run() -> None:\n        \"\"\"\n        Fire 'startup' System Events, move the reactor to the 'running'\n        state, then run the main loop until it is stopped with C{stop()} or\n        C{crash()}.\n        \"\"\"\n\n    def stop() -> None:\n        \"\"\"\n        Fire 'shutdown' System Events, which will move the reactor to the\n        'stopped' state and cause C{reactor.run()} to exit.\n        \"\"\"\n\n    def crash() -> None:\n        \"\"\"\n        Stop the main loop *immediately*, without firing any system events.\n\n        This is named as it is because this is an extremely \"rude\" thing to do;\n        it is possible to lose data and put your system in an inconsistent\n        state by calling this.  However, it is necessary, as sometimes a system\n        can become wedged in a pre-shutdown call.\n        \"\"\"\n\n    def iterate(delay: float) -> None:\n        \"\"\"\n        Run the main loop's I/O polling function for a period of time.\n\n        This is most useful in applications where the UI is being drawn \"as\n        fast as possible\", such as games. All pending L{IDelayedCall}s will\n        be called.\n\n        The reactor must have been started (via the C{run()} method) prior to\n        any invocations of this method.  It must also be stopped manually\n        after the last call to this method (via the C{stop()} method).  This\n        method is not re-entrant: you must not call it recursively; in\n        particular, you must not call it while the reactor is running.\n        \"\"\"\n\n    def fireSystemEvent(eventType: str) -> None:\n        \"\"\"\n        Fire a system-wide event.\n\n        System-wide events are things like 'startup', 'shutdown', and\n        'persist'.\n        \"\"\"\n\n    def addSystemEventTrigger(\n        phase: str,\n        eventType: str,\n        callable: Callable[..., Any],\n        *args: object,\n        **kwargs: object,\n    ) -> Any:\n        \"\"\"\n        Add a function to be called when a system event occurs.\n\n        Each \"system event\" in Twisted, such as 'startup', 'shutdown', and\n        'persist', has 3 phases: 'before', 'during', and 'after' (in that\n        order, of course).  These events will be fired internally by the\n        Reactor.\n\n        An implementor of this interface must only implement those events\n        described here.\n\n        Callbacks registered for the \"before\" phase may return either None or a\n        Deferred.  The \"during\" phase will not execute until all of the\n        Deferreds from the \"before\" phase have fired.\n\n        Once the \"during\" phase is running, all of the remaining triggers must\n        execute; their return values must be ignored.\n\n        @param phase: a time to call the event -- either the string 'before',\n                      'after', or 'during', describing when to call it\n                      relative to the event's execution.\n        @param eventType: this is a string describing the type of event.\n        @param callable: the object to call before shutdown.\n        @param args: the arguments to call it with.\n        @param kwargs: the keyword arguments to call it with.\n\n        @return: an ID that can be used to remove this call with\n                 removeSystemEventTrigger.\n        \"\"\"\n\n    def removeSystemEventTrigger(triggerID: Any) -> None:\n        \"\"\"\n        Removes a trigger added with addSystemEventTrigger.\n\n        @param triggerID: a value returned from addSystemEventTrigger.\n\n        @raise KeyError: If there is no system event trigger for the given\n            C{triggerID}.\n        @raise ValueError: If there is no system event trigger for the given\n            C{triggerID}.\n        @raise TypeError: If there is no system event trigger for the given\n            C{triggerID}.\n        \"\"\"\n\n    def callWhenRunning(\n        callable: Callable[..., Any], *args: object, **kwargs: object\n    ) -> Optional[Any]:\n        \"\"\"\n        Call a function when the reactor is running.\n\n        If the reactor has not started, the callable will be scheduled\n        to run when it does start. Otherwise, the callable will be invoked\n        immediately.\n\n        @param callable: the callable object to call later.\n        @param args: the arguments to call it with.\n        @param kwargs: the keyword arguments to call it with.\n\n        @return: None if the callable was invoked, otherwise a system\n                 event id for the scheduled call.\n        \"\"\"\n\n\nclass IReactorPluggableResolver(Interface):\n    \"\"\"\n    An L{IReactorPluggableResolver} is a reactor which can be customized with\n    an L{IResolverSimple}.  This is a fairly limited interface, that supports\n    only IPv4; you should use L{IReactorPluggableNameResolver} instead.\n\n    @see: L{IReactorPluggableNameResolver}\n    \"\"\"\n\n    def installResolver(resolver: IResolverSimple) -> IResolverSimple:\n        \"\"\"\n        Set the internal resolver to use to for name lookups.\n\n        @param resolver: The new resolver to use.\n\n        @return: The previously installed resolver.\n        \"\"\"\n\n\nclass IReactorPluggableNameResolver(Interface):\n    \"\"\"\n    An L{IReactorPluggableNameResolver} is a reactor whose name resolver can be\n    set to a user-supplied object.\n    \"\"\"\n\n    nameResolver: IHostnameResolver = Attribute(\n        \"\"\"\n        Read-only attribute; the resolver installed with L{installResolver}.\n        An L{IHostnameResolver}.\n        \"\"\"\n    )\n\n    def installNameResolver(resolver: IHostnameResolver) -> IHostnameResolver:\n        \"\"\"\n        Set the internal resolver to use for name lookups.\n\n        @param resolver: The new resolver to use.\n\n        @return: The previously installed resolver.\n        \"\"\"\n\n\nclass IReactorDaemonize(Interface):\n    \"\"\"\n    A reactor which provides hooks that need to be called before and after\n    daemonization.\n\n    Notes:\n       - This interface SHOULD NOT be called by applications.\n       - This interface should only be implemented by reactors as a workaround\n         (in particular, it's implemented currently only by kqueue()).\n         For details please see the comments on ticket #1918.\n    \"\"\"\n\n    def beforeDaemonize() -> None:\n        \"\"\"\n        Hook to be called immediately before daemonization. No reactor methods\n        may be called until L{afterDaemonize} is called.\n        \"\"\"\n\n    def afterDaemonize() -> None:\n        \"\"\"\n        Hook to be called immediately after daemonization. This may only be\n        called after L{beforeDaemonize} had been called previously.\n        \"\"\"\n\n\nclass IReactorFDSet(Interface):\n    \"\"\"\n    Implement me to be able to use L{IFileDescriptor} type resources.\n\n    This assumes that your main-loop uses UNIX-style numeric file descriptors\n    (or at least similarly opaque IDs returned from a .fileno() method)\n    \"\"\"\n\n    def addReader(reader: \"IReadDescriptor\") -> None:\n        \"\"\"\n        I add reader to the set of file descriptors to get read events for.\n\n        @param reader: An L{IReadDescriptor} provider that will be checked for\n                       read events until it is removed from the reactor with\n                       L{removeReader}.\n        \"\"\"\n\n    def addWriter(writer: \"IWriteDescriptor\") -> None:\n        \"\"\"\n        I add writer to the set of file descriptors to get write events for.\n\n        @param writer: An L{IWriteDescriptor} provider that will be checked for\n                       write events until it is removed from the reactor with\n                       L{removeWriter}.\n        \"\"\"\n\n    def removeReader(reader: \"IReadDescriptor\") -> None:\n        \"\"\"\n        Removes an object previously added with L{addReader}.\n        \"\"\"\n\n    def removeWriter(writer: \"IWriteDescriptor\") -> None:\n        \"\"\"\n        Removes an object previously added with L{addWriter}.\n        \"\"\"\n\n    def removeAll() -> List[Union[\"IReadDescriptor\", \"IWriteDescriptor\"]]:\n        \"\"\"\n        Remove all readers and writers.\n\n        Should not remove reactor internal reactor connections (like a waker).\n\n        @return: A list of L{IReadDescriptor} and L{IWriteDescriptor} providers\n                 which were removed.\n        \"\"\"\n\n    def getReaders() -> List[\"IReadDescriptor\"]:\n        \"\"\"\n        Return the list of file descriptors currently monitored for input\n        events by the reactor.\n\n        @return: the list of file descriptors monitored for input events.\n        \"\"\"\n\n    def getWriters() -> List[\"IWriteDescriptor\"]:\n        \"\"\"\n        Return the list file descriptors currently monitored for output events\n        by the reactor.\n\n        @return: the list of file descriptors monitored for output events.\n        \"\"\"\n\n\nclass IListeningPort(Interface):\n    \"\"\"\n    A listening port.\n    \"\"\"\n\n    def startListening() -> None:\n        \"\"\"\n        Start listening on this port.\n\n        @raise CannotListenError: If it cannot listen on this port (e.g., it is\n                                  a TCP port and it cannot bind to the required\n                                  port number).\n        \"\"\"\n\n    def stopListening() -> Optional[\"Deferred[None]\"]:\n        \"\"\"\n        Stop listening on this port.\n\n        If it does not complete immediately, will return Deferred that fires\n        upon completion.\n        \"\"\"\n\n    def getHost() -> IAddress:\n        \"\"\"\n        Get the host that this port is listening for.\n\n        @return: An L{IAddress} provider.\n        \"\"\"\n\n\nclass ILoggingContext(Interface):\n    \"\"\"\n    Give context information that will be used to log events generated by\n    this item.\n    \"\"\"\n\n    def logPrefix() -> str:\n        \"\"\"\n        @return: Prefix used during log formatting to indicate context.\n        \"\"\"\n\n\nclass IFileDescriptor(ILoggingContext):\n    \"\"\"\n    An interface representing a UNIX-style numeric file descriptor.\n    \"\"\"\n\n    def fileno() -> object:\n        \"\"\"\n        @return: The platform-specified representation of a file descriptor\n            number.  Or C{-1} if the descriptor no longer has a valid file\n            descriptor number associated with it.  As long as the descriptor\n            is valid, calls to this method on a particular instance must\n            return the same value.\n        \"\"\"\n\n    def connectionLost(reason: Failure) -> None:\n        \"\"\"\n        Called when the connection was lost.\n\n        This is called when the connection on a selectable object has been\n        lost.  It will be called whether the connection was closed explicitly,\n        an exception occurred in an event handler, or the other end of the\n        connection closed it first.\n\n        See also L{IHalfCloseableDescriptor} if your descriptor wants to be\n        notified separately of the two halves of the connection being closed.\n\n        @param reason: A failure instance indicating the reason why the\n                       connection was lost.  L{error.ConnectionLost} and\n                       L{error.ConnectionDone} are of special note, but the\n                       failure may be of other classes as well.\n        \"\"\"\n\n\nclass IReadDescriptor(IFileDescriptor):\n    \"\"\"\n    An L{IFileDescriptor} that can read.\n\n    This interface is generally used in conjunction with L{IReactorFDSet}.\n    \"\"\"\n\n    def doRead() -> Optional[Failure]:\n        \"\"\"\n        Some data is available for reading on your descriptor.\n\n        @return: If an error is encountered which causes the descriptor to\n            no longer be valid, a L{Failure} should be returned.  Otherwise,\n            L{None}.\n        \"\"\"\n\n\nclass IWriteDescriptor(IFileDescriptor):\n    \"\"\"\n    An L{IFileDescriptor} that can write.\n\n    This interface is generally used in conjunction with L{IReactorFDSet}.\n    \"\"\"\n\n    def doWrite() -> Optional[Failure]:\n        \"\"\"\n        Some data can be written to your descriptor.\n\n        @return: If an error is encountered which causes the descriptor to\n            no longer be valid, a L{Failure} should be returned.  Otherwise,\n            L{None}.\n        \"\"\"\n\n\nclass IReadWriteDescriptor(IReadDescriptor, IWriteDescriptor):\n    \"\"\"\n    An L{IFileDescriptor} that can both read and write.\n    \"\"\"\n\n\nclass IHalfCloseableDescriptor(Interface):\n    \"\"\"\n    A descriptor that can be half-closed.\n    \"\"\"\n\n    def writeConnectionLost(reason: Failure) -> None:\n        \"\"\"\n        Indicates write connection was lost.\n        \"\"\"\n\n    def readConnectionLost(reason: Failure) -> None:\n        \"\"\"\n        Indicates read connection was lost.\n        \"\"\"\n\n\nclass ISystemHandle(Interface):\n    \"\"\"\n    An object that wraps a networking OS-specific handle.\n    \"\"\"\n\n    def getHandle() -> object:\n        \"\"\"\n        Return a system- and reactor-specific handle.\n\n        This might be a socket.socket() object, or some other type of\n        object, depending on which reactor is being used. Use and\n        manipulate at your own risk.\n\n        This might be used in cases where you want to set specific\n        options not exposed by the Twisted APIs.\n        \"\"\"\n\n\nclass IConsumer(Interface):\n    \"\"\"\n    A consumer consumes data from a producer.\n    \"\"\"\n\n    def registerProducer(producer: \"IProducer\", streaming: bool) -> None:\n        \"\"\"\n        Register to receive data from a producer.\n\n        This sets self to be a consumer for a producer.  When this object runs\n        out of data (as when a send(2) call on a socket succeeds in moving the\n        last data from a userspace buffer into a kernelspace buffer), it will\n        ask the producer to resumeProducing().\n\n        For L{IPullProducer} providers, C{resumeProducing} will be called once\n        each time data is required.\n\n        For L{IPushProducer} providers, C{pauseProducing} will be called\n        whenever the write buffer fills up and C{resumeProducing} will only be\n        called when it empties.  The consumer will only call C{resumeProducing}\n        to balance a previous C{pauseProducing} call; the producer is assumed\n        to start in an un-paused state.\n\n        @param streaming: C{True} if C{producer} provides L{IPushProducer},\n            C{False} if C{producer} provides L{IPullProducer}.\n\n        @raise RuntimeError: If a producer is already registered.\n        \"\"\"\n\n    def unregisterProducer() -> None:\n        \"\"\"\n        Stop consuming data from a producer, without disconnecting.\n        \"\"\"\n\n    def write(data: bytes) -> None:\n        \"\"\"\n        The producer will write data by calling this method.\n\n        The implementation must be non-blocking and perform whatever\n        buffering is necessary.  If the producer has provided enough data\n        for now and it is a L{IPushProducer}, the consumer may call its\n        C{pauseProducing} method.\n        \"\"\"\n\n\nclass IProducer(Interface):\n    \"\"\"\n    A producer produces data for a consumer.\n\n    Typically producing is done by calling the C{write} method of a class\n    implementing L{IConsumer}.\n    \"\"\"\n\n    def stopProducing() -> None:\n        \"\"\"\n        Stop producing data.\n\n        This tells a producer that its consumer has died, so it must stop\n        producing data for good.\n        \"\"\"\n\n\nclass IPushProducer(IProducer):\n    \"\"\"\n    A push producer, also known as a streaming producer is expected to\n    produce (write to this consumer) data on a continuous basis, unless\n    it has been paused. A paused push producer will resume producing\n    after its C{resumeProducing()} method is called.   For a push producer\n    which is not pauseable, these functions may be noops.\n    \"\"\"\n\n    def pauseProducing() -> None:\n        \"\"\"\n        Pause producing data.\n\n        Tells a producer that it has produced too much data to process for\n        the time being, and to stop until C{resumeProducing()} is called.\n        \"\"\"\n\n    def resumeProducing() -> None:\n        \"\"\"\n        Resume producing data.\n\n        This tells a producer to re-add itself to the main loop and produce\n        more data for its consumer.\n        \"\"\"\n\n\nclass IPullProducer(IProducer):\n    \"\"\"\n    A pull producer, also known as a non-streaming producer, is\n    expected to produce data each time L{resumeProducing()} is called.\n    \"\"\"\n\n    def resumeProducing() -> None:\n        \"\"\"\n        Produce data for the consumer a single time.\n\n        This tells a producer to produce data for the consumer once\n        (not repeatedly, once only). Typically this will be done\n        by calling the consumer's C{write} method a single time with\n        produced data. The producer should produce data before returning\n        from C{resumeProducing()}, that is, it should not schedule a deferred\n        write.\n        \"\"\"\n\n\nclass IProtocol(Interface):\n    def dataReceived(data: bytes) -> None:\n        \"\"\"\n        Called whenever data is received.\n\n        Use this method to translate to a higher-level message.  Usually, some\n        callback will be made upon the receipt of each complete protocol\n        message.\n\n        Please keep in mind that you will probably need to buffer some data\n        as partial (or multiple) protocol messages may be received!  We\n        recommend that unit tests for protocols call through to this method\n        with differing chunk sizes, down to one byte at a time.\n\n        @param data: bytes of indeterminate length\n        \"\"\"\n\n    def connectionLost(reason: Failure) -> None:\n        \"\"\"\n        Called when the connection is shut down.\n\n        Clear any circular references here, and any external references\n        to this Protocol.  The connection has been closed. The C{reason}\n        Failure wraps a L{twisted.internet.error.ConnectionDone} or\n        L{twisted.internet.error.ConnectionLost} instance (or a subclass\n        of one of those).\n        \"\"\"\n\n    def makeConnection(transport: \"ITransport\") -> None:\n        \"\"\"\n        Make a connection to a transport and a server.\n        \"\"\"\n\n    def connectionMade() -> None:\n        \"\"\"\n        Called when a connection is made.\n\n        This may be considered the initializer of the protocol, because\n        it is called when the connection is completed.  For clients,\n        this is called once the connection to the server has been\n        established; for servers, this is called after an accept() call\n        stops blocking and a socket has been received.  If you need to\n        send any greeting or initial message, do it here.\n        \"\"\"\n\n\nclass IProcessProtocol(Interface):\n    \"\"\"\n    Interface for process-related event handlers.\n    \"\"\"\n\n    def makeConnection(process: \"IProcessTransport\") -> None:\n        \"\"\"\n        Called when the process has been created.\n\n        @param process: An object representing the process which has been\n            created and associated with this protocol.\n        \"\"\"\n\n    def childDataReceived(childFD: int, data: bytes) -> None:\n        \"\"\"\n        Called when data arrives from the child process.\n\n        @param childFD: The file descriptor from which the data was\n            received.\n        @param data: The data read from the child's file descriptor.\n        \"\"\"\n\n    def childConnectionLost(childFD: int) -> None:\n        \"\"\"\n        Called when a file descriptor associated with the child process is\n        closed.\n\n        @param childFD: The file descriptor which was closed.\n        \"\"\"\n\n    def processExited(reason: Failure) -> None:\n        \"\"\"\n        Called when the child process exits.\n\n        @param reason: A failure giving the reason the child process\n            terminated.  The type of exception for this failure is either\n            L{twisted.internet.error.ProcessDone} or\n            L{twisted.internet.error.ProcessTerminated}.\n\n        @since: 8.2\n        \"\"\"\n\n    def processEnded(reason: Failure) -> None:\n        \"\"\"\n        Called when the child process exits and all file descriptors associated\n        with it have been closed.\n\n        @param reason: A failure giving the reason the child process\n            terminated.  The type of exception for this failure is either\n            L{twisted.internet.error.ProcessDone} or\n            L{twisted.internet.error.ProcessTerminated}.\n        \"\"\"\n\n\nclass IHalfCloseableProtocol(Interface):\n    \"\"\"\n    Implemented to indicate they want notification of half-closes.\n\n    TCP supports the notion of half-closing the connection, e.g.\n    closing the write side but still not stopping reading. A protocol\n    that implements this interface will be notified of such events,\n    instead of having connectionLost called.\n    \"\"\"\n\n    def readConnectionLost() -> None:\n        \"\"\"\n        Notification of the read connection being closed.\n\n        This indicates peer did half-close of write side. It is now\n        the responsibility of the this protocol to call\n        loseConnection().  In addition, the protocol MUST make sure a\n        reference to it still exists (i.e. by doing a callLater with\n        one of its methods, etc.)  as the reactor will only have a\n        reference to it if it is writing.\n\n        If the protocol does not do so, it might get garbage collected\n        without the connectionLost method ever being called.\n        \"\"\"\n\n    def writeConnectionLost() -> None:\n        \"\"\"\n        Notification of the write connection being closed.\n\n        This will never be called for TCP connections as TCP does not\n        support notification of this type of half-close.\n        \"\"\"\n\n\nclass IHandshakeListener(Interface):\n    \"\"\"\n    An interface implemented by a L{IProtocol} to indicate that it would like\n    to be notified when TLS handshakes complete when run over a TLS-based\n    transport.\n\n    This interface is only guaranteed to be called when run over a TLS-based\n    transport: non TLS-based transports will not respect this interface.\n    \"\"\"\n\n    def handshakeCompleted() -> None:\n        \"\"\"\n        Notification of the TLS handshake being completed.\n\n        This notification fires when OpenSSL has completed the TLS handshake.\n        At this point the TLS connection is established, and the protocol can\n        interrogate its transport (usually an L{ISSLTransport}) for details of\n        the TLS connection.\n\n        This notification *also* fires whenever the TLS session is\n        renegotiated. As a result, protocols that have certain minimum security\n        requirements should implement this interface to ensure that they are\n        able to re-evaluate the security of the TLS session if it changes.\n        \"\"\"\n\n\nclass IFileDescriptorReceiver(Interface):\n    \"\"\"\n    Protocols may implement L{IFileDescriptorReceiver} to receive file\n    descriptors sent to them.  This is useful in conjunction with\n    L{IUNIXTransport}, which allows file descriptors to be sent between\n    processes on a single host.\n    \"\"\"\n\n    def fileDescriptorReceived(descriptor: int) -> None:\n        \"\"\"\n        Called when a file descriptor is received over the connection.\n\n        @param descriptor: The descriptor which was received.\n\n        @return: L{None}\n        \"\"\"\n\n\nclass IProtocolFactory(Interface):\n    \"\"\"\n    Interface for protocol factories.\n    \"\"\"\n\n    def buildProtocol(addr: IAddress) -> Optional[IProtocol]:\n        \"\"\"\n        Called when a connection has been established to addr.\n\n        If None is returned, the connection is assumed to have been refused,\n        and the Port will close the connection.\n\n        @param addr: The address of the newly-established connection\n\n        @return: None if the connection was refused, otherwise an object\n                 providing L{IProtocol}.\n        \"\"\"\n\n    def doStart() -> None:\n        \"\"\"\n        Called every time this is connected to a Port or Connector.\n        \"\"\"\n\n    def doStop() -> None:\n        \"\"\"\n        Called every time this is unconnected from a Port or Connector.\n        \"\"\"\n\n\nclass ITransport(Interface):\n    \"\"\"\n    I am a transport for bytes.\n\n    I represent (and wrap) the physical connection and synchronicity\n    of the framework which is talking to the network.  I make no\n    representations about whether calls to me will happen immediately\n    or require returning to a control loop, or whether they will happen\n    in the same or another thread.  Consider methods of this class\n    (aside from getPeer) to be 'thrown over the wall', to happen at some\n    indeterminate time.\n    \"\"\"\n\n    def write(data: bytes) -> None:\n        \"\"\"\n        Write some data to the physical connection, in sequence, in a\n        non-blocking fashion.\n\n        If possible, make sure that it is all written.  No data will\n        ever be lost, although (obviously) the connection may be closed\n        before it all gets through.\n\n        @param data: The data to write.\n        \"\"\"\n\n    def writeSequence(data: Iterable[bytes]) -> None:\n        \"\"\"\n        Write an iterable of byte strings to the physical connection.\n\n        If possible, make sure that all of the data is written to\n        the socket at once, without first copying it all into a\n        single byte string.\n\n        @param data: The data to write.\n        \"\"\"\n\n    def loseConnection() -> None:\n        \"\"\"\n        Close my connection, after writing all pending data.\n\n        Note that if there is a registered producer on a transport it\n        will not be closed until the producer has been unregistered.\n        \"\"\"\n\n    def getPeer() -> IAddress:\n        \"\"\"\n        Get the remote address of this connection.\n\n        Treat this method with caution.  It is the unfortunate result of the\n        CGI and Jabber standards, but should not be considered reliable for\n        the usual host of reasons; port forwarding, proxying, firewalls, IP\n        masquerading, etc.\n\n        @return: An L{IAddress} provider.\n        \"\"\"\n\n    def getHost() -> IAddress:\n        \"\"\"\n        Similar to getPeer, but returns an address describing this side of the\n        connection.\n\n        @return: An L{IAddress} provider.\n        \"\"\"\n\n\nclass ITCPTransport(ITransport):\n    \"\"\"\n    A TCP based transport.\n    \"\"\"\n\n    def loseWriteConnection() -> None:\n        \"\"\"\n        Half-close the write side of a TCP connection.\n\n        If the protocol instance this is attached to provides\n        IHalfCloseableProtocol, it will get notified when the operation is\n        done. When closing write connection, as with loseConnection this will\n        only happen when buffer has emptied and there is no registered\n        producer.\n        \"\"\"\n\n    def abortConnection() -> None:\n        \"\"\"\n        Close the connection abruptly.\n\n        Discards any buffered data, stops any registered producer,\n        and, if possible, notifies the other end of the unclean\n        closure.\n\n        @since: 11.1\n        \"\"\"\n\n    def getTcpNoDelay() -> bool:\n        \"\"\"\n        Return if C{TCP_NODELAY} is enabled.\n        \"\"\"\n\n    def setTcpNoDelay(enabled: bool) -> None:\n        \"\"\"\n        Enable/disable C{TCP_NODELAY}.\n\n        Enabling C{TCP_NODELAY} turns off Nagle's algorithm. Small packets are\n        sent sooner, possibly at the expense of overall throughput.\n        \"\"\"\n\n    def getTcpKeepAlive() -> bool:\n        \"\"\"\n        Return if C{SO_KEEPALIVE} is enabled.\n        \"\"\"\n\n    def setTcpKeepAlive(enabled: bool) -> None:\n        \"\"\"\n        Enable/disable C{SO_KEEPALIVE}.\n\n        Enabling C{SO_KEEPALIVE} sends packets periodically when the connection\n        is otherwise idle, usually once every two hours. They are intended\n        to allow detection of lost peers in a non-infinite amount of time.\n        \"\"\"\n\n    def getHost() -> Union[\"IPv4Address\", \"IPv6Address\"]:\n        \"\"\"\n        Returns L{IPv4Address} or L{IPv6Address}.\n        \"\"\"\n\n    def getPeer() -> Union[\"IPv4Address\", \"IPv6Address\"]:\n        \"\"\"\n        Returns L{IPv4Address} or L{IPv6Address}.\n        \"\"\"\n\n\nclass IUNIXTransport(ITransport):\n    \"\"\"\n    Transport for stream-oriented unix domain connections.\n    \"\"\"\n\n    def sendFileDescriptor(descriptor: int) -> None:\n        \"\"\"\n        Send a duplicate of this (file, socket, pipe, etc) descriptor to the\n        other end of this connection.\n\n        The send is non-blocking and will be queued if it cannot be performed\n        immediately.  The send will be processed in order with respect to other\n        C{sendFileDescriptor} calls on this transport, but not necessarily with\n        respect to C{write} calls on this transport.  The send can only be\n        processed if there are also bytes in the normal connection-oriented send\n        buffer (ie, you must call C{write} at least as many times as you call\n        C{sendFileDescriptor}).\n\n        @param descriptor: An C{int} giving a valid file descriptor in this\n            process.  Note that a I{file descriptor} may actually refer to a\n            socket, a pipe, or anything else POSIX tries to treat in the same\n            way as a file.\n        \"\"\"\n\n\nclass IOpenSSLServerConnectionCreator(Interface):\n    \"\"\"\n    A provider of L{IOpenSSLServerConnectionCreator} can create\n    L{OpenSSL.SSL.Connection} objects for TLS servers.\n\n    @see: L{twisted.internet.ssl}\n\n    @note: Creating OpenSSL connection objects is subtle, error-prone, and\n        security-critical.  Before implementing this interface yourself,\n        consider using L{twisted.internet.ssl.CertificateOptions} as your\n        C{contextFactory}.  (For historical reasons, that class does not\n        actually I{implement} this interface; nevertheless it is usable in all\n        Twisted APIs which require a provider of this interface.)\n    \"\"\"\n\n    def serverConnectionForTLS(\n        tlsProtocol: \"TLSMemoryBIOProtocol\",\n    ) -> \"OpenSSLConnection\":\n        \"\"\"\n        Create a connection for the given server protocol.\n\n        @return: an OpenSSL connection object configured appropriately for the\n            given Twisted protocol.\n        \"\"\"\n\n\nclass IOpenSSLClientConnectionCreator(Interface):\n    \"\"\"\n    A provider of L{IOpenSSLClientConnectionCreator} can create\n    L{OpenSSL.SSL.Connection} objects for TLS clients.\n\n    @see: L{twisted.internet.ssl}\n\n    @note: Creating OpenSSL connection objects is subtle, error-prone, and\n        security-critical.  Before implementing this interface yourself,\n        consider using L{twisted.internet.ssl.optionsForClientTLS} as your\n        C{contextFactory}.\n    \"\"\"\n\n    def clientConnectionForTLS(\n        tlsProtocol: \"TLSMemoryBIOProtocol\",\n    ) -> \"OpenSSLConnection\":\n        \"\"\"\n        Create a connection for the given client protocol.\n\n        @param tlsProtocol: the client protocol making the request.\n\n        @return: an OpenSSL connection object configured appropriately for the\n            given Twisted protocol.\n        \"\"\"\n\n\nclass IProtocolNegotiationFactory(Interface):\n    \"\"\"\n    A provider of L{IProtocolNegotiationFactory} can provide information about\n    the various protocols that the factory can create implementations of. This\n    can be used, for example, to provide protocol names for Next Protocol\n    Negotiation and Application Layer Protocol Negotiation.\n\n    @see: L{twisted.internet.ssl}\n    \"\"\"\n\n    def acceptableProtocols() -> List[bytes]:\n        \"\"\"\n        Returns a list of protocols that can be spoken by the connection\n        factory in the form of ALPN tokens, as laid out in the IANA registry\n        for ALPN tokens.\n\n        @return: a list of ALPN tokens in order of preference.\n        \"\"\"\n\n\nclass IOpenSSLContextFactory(Interface):\n    \"\"\"\n    A provider of L{IOpenSSLContextFactory} is capable of generating\n    L{OpenSSL.SSL.Context} classes suitable for configuring TLS on a\n    connection. A provider will store enough state to be able to generate these\n    contexts as needed for individual connections.\n\n    @see: L{twisted.internet.ssl}\n    \"\"\"\n\n    def getContext() -> \"OpenSSLContext\":\n        \"\"\"\n        Returns a TLS context object, suitable for securing a TLS connection.\n        This context object will be appropriately customized for the connection\n        based on the state in this object.\n\n        @return: A TLS context object.\n        \"\"\"\n\n\nclass ITLSTransport(ITCPTransport):\n    \"\"\"\n    A TCP transport that supports switching to TLS midstream.\n\n    Once TLS mode is started the transport will implement L{ISSLTransport}.\n    \"\"\"\n\n    def startTLS(\n        contextFactory: Union[\n            IOpenSSLClientConnectionCreator, IOpenSSLServerConnectionCreator\n        ]\n    ) -> None:\n        \"\"\"\n        Initiate TLS negotiation.\n\n        @param contextFactory: An object which creates appropriately configured\n            TLS connections.\n\n            For clients, use L{twisted.internet.ssl.optionsForClientTLS}; for\n            servers, use L{twisted.internet.ssl.CertificateOptions}.\n\n        @type contextFactory: L{IOpenSSLClientConnectionCreator} or\n            L{IOpenSSLServerConnectionCreator}, depending on whether this\n            L{ITLSTransport} is a server or not.  If the appropriate interface\n            is not provided by the value given for C{contextFactory}, it must\n            be an implementor of L{IOpenSSLContextFactory}.\n        \"\"\"\n\n\nclass ISSLTransport(ITCPTransport):\n    \"\"\"\n    A SSL/TLS based transport.\n    \"\"\"\n\n    def getPeerCertificate() -> object:\n        \"\"\"\n        Return an object with the peer's certificate info.\n        \"\"\"\n\n\nclass INegotiated(ISSLTransport):\n    \"\"\"\n    A TLS based transport that supports using ALPN/NPN to negotiate the\n    protocol to be used inside the encrypted tunnel.\n    \"\"\"\n\n    negotiatedProtocol = Attribute(\n        \"\"\"\n        The protocol selected to be spoken using ALPN/NPN. The result from ALPN\n        is preferred to the result from NPN if both were used. If the remote\n        peer does not support ALPN or NPN, or neither NPN or ALPN are available\n        on this machine, will be L{None}. Otherwise, will be the name of the\n        selected protocol as C{bytes}. Note that until the handshake has\n        completed this property may incorrectly return L{None}: wait until data\n        has been received before trusting it (see\n        https://twistedmatrix.com/trac/ticket/6024).\n        \"\"\"\n    )\n\n\nclass ICipher(Interface):\n    \"\"\"\n    A TLS cipher.\n    \"\"\"\n\n    fullName = Attribute(\"The fully qualified name of the cipher in L{unicode}.\")\n\n\nclass IAcceptableCiphers(Interface):\n    \"\"\"\n    A list of acceptable ciphers for a TLS context.\n    \"\"\"\n\n    def selectCiphers(availableCiphers: Tuple[ICipher]) -> Tuple[ICipher]:\n        \"\"\"\n        Choose which ciphers to allow to be negotiated on a TLS connection.\n\n        @param availableCiphers: A L{tuple} of L{ICipher} which gives the names\n            of all ciphers supported by the TLS implementation in use.\n\n        @return: A L{tuple} of L{ICipher} which represents the ciphers\n            which may be negotiated on the TLS connection.  The result is\n            ordered by preference with more preferred ciphers appearing\n            earlier.\n        \"\"\"\n\n\nclass IProcessTransport(ITransport):\n    \"\"\"\n    A process transport.\n    \"\"\"\n\n    pid = Attribute(\n        \"From before L{IProcessProtocol.makeConnection} is called to before \"\n        \"L{IProcessProtocol.processEnded} is called, C{pid} is an L{int} \"\n        \"giving the platform process ID of this process.  C{pid} is L{None} \"\n        \"at all other times.\"\n    )\n\n    def closeStdin() -> None:\n        \"\"\"\n        Close stdin after all data has been written out.\n        \"\"\"\n\n    def closeStdout() -> None:\n        \"\"\"\n        Close stdout.\n        \"\"\"\n\n    def closeStderr() -> None:\n        \"\"\"\n        Close stderr.\n        \"\"\"\n\n    def closeChildFD(descriptor: int) -> None:\n        \"\"\"\n        Close a file descriptor which is connected to the child process, identified\n        by its FD in the child process.\n        \"\"\"\n\n    def writeToChild(childFD: int, data: bytes) -> None:\n        \"\"\"\n        Similar to L{ITransport.write} but also allows the file descriptor in\n        the child process which will receive the bytes to be specified.\n\n        @param childFD: The file descriptor to which to write.\n        @param data: The bytes to write.\n\n        @raise KeyError: If C{childFD} is not a file descriptor that was mapped\n            in the child when L{IReactorProcess.spawnProcess} was used to create\n            it.\n        \"\"\"\n\n    def loseConnection() -> None:\n        \"\"\"\n        Close stdin, stderr and stdout.\n        \"\"\"\n\n    def signalProcess(signalID: Union[str, int]) -> None:\n        \"\"\"\n        Send a signal to the process.\n\n        @param signalID: can be\n          - one of C{\"KILL\"}, C{\"TERM\"}, or C{\"INT\"}.\n              These will be implemented in a\n              cross-platform manner, and so should be used\n              if possible.\n          - an integer, where it represents a POSIX\n              signal ID.\n\n        @raise twisted.internet.error.ProcessExitedAlready: If the process has\n            already exited.\n        @raise OSError: If the C{os.kill} call fails with an errno different\n            from C{ESRCH}.\n        \"\"\"\n\n\nclass IServiceCollection(Interface):\n    \"\"\"\n    An object which provides access to a collection of services.\n    \"\"\"\n\n    def getServiceNamed(serviceName: str) -> object:\n        \"\"\"\n        Retrieve the named service from this application.\n\n        Raise a C{KeyError} if there is no such service name.\n        \"\"\"\n\n    def addService(service: object) -> None:\n        \"\"\"\n        Add a service to this collection.\n        \"\"\"\n\n    def removeService(service: object) -> None:\n        \"\"\"\n        Remove a service from this collection.\n        \"\"\"\n\n\nclass IUDPTransport(Interface):\n    \"\"\"\n    Transport for UDP DatagramProtocols.\n    \"\"\"\n\n    def write(packet: bytes, addr: Optional[Tuple[str, int]]) -> None:\n        \"\"\"\n        Write packet to given address.\n\n        @param addr: a tuple of (ip, port). For connected transports must\n                     be the address the transport is connected to, or None.\n                     In non-connected mode this is mandatory.\n\n        @raise twisted.internet.error.MessageLengthError: C{packet} was too\n        long.\n        \"\"\"\n\n    def connect(host: str, port: int) -> None:\n        \"\"\"\n        Connect the transport to an address.\n\n        This changes it to connected mode. Datagrams can only be sent to\n        this address, and will only be received from this address. In addition\n        the protocol's connectionRefused method might get called if destination\n        is not receiving datagrams.\n\n        @param host: an IP address, not a domain name ('127.0.0.1', not 'localhost')\n        @param port: port to connect to.\n        \"\"\"\n\n    def getHost() -> Union[\"IPv4Address\", \"IPv6Address\"]:\n        \"\"\"\n        Get this port's host address.\n\n        @return: an address describing the listening port.\n        \"\"\"\n\n    def stopListening() -> Optional[\"Deferred[None]\"]:\n        \"\"\"\n        Stop listening on this port.\n\n        If it does not complete immediately, will return L{Deferred} that fires\n        upon completion.\n        \"\"\"\n\n    def setBroadcastAllowed(enabled: bool) -> None:\n        \"\"\"\n        Set whether this port may broadcast.\n\n        @param enabled: Whether the port may broadcast.\n        \"\"\"\n\n    def getBroadcastAllowed() -> bool:\n        \"\"\"\n        Checks if broadcast is currently allowed on this port.\n\n        @return: Whether this port may broadcast.\n        \"\"\"\n\n\nclass IUNIXDatagramTransport(Interface):\n    \"\"\"\n    Transport for UDP PacketProtocols.\n    \"\"\"\n\n    def write(packet: bytes, addr: str) -> None:\n        \"\"\"\n        Write packet to given address.\n        \"\"\"\n\n    def getHost() -> \"UNIXAddress\":\n        \"\"\"\n        Returns L{UNIXAddress}.\n        \"\"\"\n\n\nclass IUNIXDatagramConnectedTransport(Interface):\n    \"\"\"\n    Transport for UDP ConnectedPacketProtocols.\n    \"\"\"\n\n    def write(packet: bytes) -> None:\n        \"\"\"\n        Write packet to address we are connected to.\n        \"\"\"\n\n    def getHost() -> \"UNIXAddress\":\n        \"\"\"\n        Returns L{UNIXAddress}.\n        \"\"\"\n\n    def getPeer() -> \"UNIXAddress\":\n        \"\"\"\n        Returns L{UNIXAddress}.\n        \"\"\"\n\n\nclass IMulticastTransport(IUDPTransport):\n    \"\"\"\n    Additional functionality for multicast UDP.\n    \"\"\"\n\n    def getOutgoingInterface() -> str | int:\n        \"\"\"\n        Return interface of outgoing multicast packets.\n        \"\"\"\n\n    def setOutgoingInterface(addr: str | int) -> Deferred[int]:\n        \"\"\"\n        Set interface for outgoing multicast packets.\n\n        @note: For IPv4 multicast sockets, the address must be a hostname or IP\n            address.  For IPv6 multicast sockets, the address must be an\n            interface index, as described in L{socket.if_nameindex}.\n\n        @returns: Deferred of (1: success, 0: failure).\n        \"\"\"\n\n    def getLoopbackMode() -> bool:\n        \"\"\"\n        Return if loopback mode is enabled.\n        \"\"\"\n\n    def setLoopbackMode(mode: bool) -> None:\n        \"\"\"\n        Set if loopback mode is enabled.\n        \"\"\"\n\n    def getTTL() -> int:\n        \"\"\"\n        Get time to live for multicast packets.\n        \"\"\"\n\n    def setTTL(ttl: int) -> None:\n        \"\"\"\n        Set time to live on multicast packets.\n        \"\"\"\n\n    def joinGroup(addr: str, interface: str = \"\") -> \"Deferred[None]\":\n        \"\"\"\n        Join a multicast group. Returns L{Deferred} of success or failure.\n\n        If an error occurs, the returned L{Deferred} will fail with\n        L{error.MulticastJoinError}.\n        \"\"\"\n\n    def leaveGroup(addr: str, interface: str = \"\") -> \"Deferred[None]\":\n        \"\"\"\n        Leave multicast group, return L{Deferred} of success.\n        \"\"\"\n\n\nclass IStreamClientEndpoint(Interface):\n    \"\"\"\n    A stream client endpoint is a place that L{ClientFactory} can connect to.\n    For example, a remote TCP host/port pair would be a TCP client endpoint.\n\n    @since: 10.1\n    \"\"\"\n\n    def connect(protocolFactory: IProtocolFactory) -> \"Deferred[IProtocol]\":\n        \"\"\"\n        Connect the C{protocolFactory} to the location specified by this\n        L{IStreamClientEndpoint} provider.\n\n        @param protocolFactory: A provider of L{IProtocolFactory}\n\n        @return: A L{Deferred} that results in an L{IProtocol} upon successful\n            connection otherwise a L{Failure} wrapping L{ConnectError} or\n            L{NoProtocol <twisted.internet.error.NoProtocol>}.\n        \"\"\"\n\n\nclass IStreamServerEndpoint(Interface):\n    \"\"\"\n    A stream server endpoint is a place that a L{Factory} can listen for\n    incoming connections.\n\n    @since: 10.1\n    \"\"\"\n\n    def listen(protocolFactory: IProtocolFactory) -> \"Deferred[IListeningPort]\":\n        \"\"\"\n        Listen with C{protocolFactory} at the location specified by this\n        L{IStreamServerEndpoint} provider.\n\n        @param protocolFactory: A provider of L{IProtocolFactory}\n\n        @return: A L{Deferred} that results in an L{IListeningPort} or an\n            L{CannotListenError}\n        \"\"\"\n\n\nclass IStreamServerEndpointStringParser(Interface):\n    \"\"\"\n    An L{IStreamServerEndpointStringParser} is like an\n    L{IStreamClientEndpointStringParserWithReactor}, except for\n    L{IStreamServerEndpoint}s instead of clients.  It integrates with\n    L{endpoints.serverFromString} in much the same way.\n    \"\"\"\n\n    prefix = Attribute(\n        \"\"\"\n        A C{str}, the description prefix to respond to.  For example, an\n        L{IStreamServerEndpointStringParser} plugin which had C{\"foo\"} for its\n        C{prefix} attribute would be called for endpoint descriptions like\n        C{\"foo:bar:baz\"} or C{\"foo:\"}.\n        \"\"\"\n    )\n\n    def parseStreamServer(\n        reactor: IReactorCore, *args: object, **kwargs: object\n    ) -> IStreamServerEndpoint:\n        \"\"\"\n        Parse a stream server endpoint from a reactor and string-only arguments\n        and keyword arguments.\n\n        @see: L{IStreamClientEndpointStringParserWithReactor.parseStreamClient}\n\n        @return: a stream server endpoint\n        \"\"\"\n\n\nclass IStreamClientEndpointStringParserWithReactor(Interface):\n    \"\"\"\n    An L{IStreamClientEndpointStringParserWithReactor} is a parser which can\n    convert a set of string C{*args} and C{**kwargs} into an\n    L{IStreamClientEndpoint} provider.\n\n    This interface is really only useful in the context of the plugin system\n    for L{endpoints.clientFromString}.  See the document entitled \"I{The\n    Twisted Plugin System}\" for more details on how to write a plugin.\n\n    If you place an L{IStreamClientEndpointStringParserWithReactor} plugin in\n    the C{twisted.plugins} package, that plugin's C{parseStreamClient} method\n    will be used to produce endpoints for any description string that begins\n    with the result of that L{IStreamClientEndpointStringParserWithReactor}'s\n    prefix attribute.\n    \"\"\"\n\n    prefix = Attribute(\n        \"\"\"\n        L{bytes}, the description prefix to respond to.  For example, an\n        L{IStreamClientEndpointStringParserWithReactor} plugin which had\n        C{b\"foo\"} for its C{prefix} attribute would be called for endpoint\n        descriptions like C{b\"foo:bar:baz\"} or C{b\"foo:\"}.\n        \"\"\"\n    )\n\n    def parseStreamClient(\n        reactor: IReactorCore, *args: object, **kwargs: object\n    ) -> IStreamClientEndpoint:\n        \"\"\"\n        This method is invoked by L{endpoints.clientFromString}, if the type of\n        endpoint matches the return value from this\n        L{IStreamClientEndpointStringParserWithReactor}'s C{prefix} method.\n\n        @param reactor: The reactor passed to L{endpoints.clientFromString}.\n        @param args: The byte string arguments, minus the endpoint type, in the\n            endpoint description string, parsed according to the rules\n            described in L{endpoints.quoteStringArgument}.  For example, if the\n            description were C{b\"my-type:foo:bar:baz=qux\"}, C{args} would be\n            C{(b'foo', b'bar')}\n        @param kwargs: The byte string arguments from the endpoint description\n            passed as keyword arguments.  For example, if the description were\n            C{b\"my-type:foo:bar:baz=qux\"}, C{kwargs} would be\n            C{dict(baz=b'qux')}.\n\n        @return: a client endpoint\n        \"\"\"\n\n\nclass _ISupportsExitSignalCapturing(Interface):\n    \"\"\"\n    An implementor of L{_ISupportsExitSignalCapturing} will capture the\n    value of any delivered exit signal (SIGINT, SIGTERM, SIGBREAK) for which\n    it has installed a handler.  The caught signal number is made available in\n    the _exitSignal attribute.\n    \"\"\"\n\n    _exitSignal = Attribute(\n        \"\"\"\n        C{int} or C{None}, the integer exit signal delivered to the\n        application, or None if no signal was delivered.\n        \"\"\"\n    )\n\n\n### Dependency File: runtime.py\n# -*- test-case-name: twisted.python.test.test_runtime -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n__all__ = [\n    \"seconds\",\n    \"shortPythonVersion\",\n    \"Platform\",\n    \"platform\",\n    \"platformType\",\n]\nimport os\nimport sys\nimport warnings\nfrom time import time as seconds\nfrom typing import Optional\n\n\ndef shortPythonVersion() -> str:\n    \"\"\"\n    Returns the Python version as a dot-separated string.\n    \"\"\"\n    return \"%s.%s.%s\" % sys.version_info[:3]\n\n\nknownPlatforms = {\n    \"nt\": \"win32\",\n    \"ce\": \"win32\",\n    \"posix\": \"posix\",\n    \"java\": \"java\",\n    \"org.python.modules.os\": \"java\",\n}\n\n\nclass Platform:\n    \"\"\"\n    Gives us information about the platform we're running on.\n    \"\"\"\n\n    type: Optional[str] = knownPlatforms.get(os.name)\n    seconds = staticmethod(seconds)\n    _platform = sys.platform\n\n    def __init__(\n        self, name: Optional[str] = None, platform: Optional[str] = None\n    ) -> None:\n        if name is not None:\n            self.type = knownPlatforms.get(name)\n        if platform is not None:\n            self._platform = platform\n\n    def isKnown(self) -> bool:\n        \"\"\"\n        Do we know about this platform?\n\n        @return: Boolean indicating whether this is a known platform or not.\n        \"\"\"\n        return self.type != None\n\n    def getType(self) -> Optional[str]:\n        \"\"\"\n        Get platform type.\n\n        @return: Either 'posix', 'win32' or 'java'\n        \"\"\"\n        return self.type\n\n    def isMacOSX(self) -> bool:\n        \"\"\"\n        Check if current platform is macOS.\n\n        @return: C{True} if the current platform has been detected as macOS.\n        \"\"\"\n        return self._platform == \"darwin\"\n\n    def isWinNT(self) -> bool:\n        \"\"\"\n        Are we running in Windows NT?\n\n        This is deprecated and always returns C{True} on win32 because\n        Twisted only supports Windows NT-derived platforms at this point.\n\n        @return: C{True} if the current platform has been detected as\n            Windows NT.\n        \"\"\"\n        warnings.warn(\n            \"twisted.python.runtime.Platform.isWinNT was deprecated in \"\n            \"Twisted 13.0. Use Platform.isWindows instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return self.isWindows()\n\n    def isWindows(self) -> bool:\n        \"\"\"\n        Are we running in Windows?\n\n        @return: C{True} if the current platform has been detected as\n            Windows.\n        \"\"\"\n        return self.getType() == \"win32\"\n\n    def isVista(self) -> bool:\n        \"\"\"\n        Check if current platform is Windows Vista or Windows Server 2008.\n\n        @return: C{True} if the current platform has been detected as Vista\n        \"\"\"\n        return sys.platform == \"win32\" and sys.getwindowsversion().major == 6\n\n    def isLinux(self) -> bool:\n        \"\"\"\n        Check if current platform is Linux.\n\n        @return: C{True} if the current platform has been detected as Linux.\n        \"\"\"\n        return self._platform.startswith(\"linux\")\n\n    def isDocker(self, _initCGroupLocation: str = \"/proc/1/cgroup\") -> bool:\n        \"\"\"\n        Check if the current platform is Linux in a Docker container.\n\n        @return: C{True} if the current platform has been detected as Linux\n            inside a Docker container.\n        \"\"\"\n        if not self.isLinux():\n            return False\n\n        from twisted.python.filepath import FilePath\n\n        # Ask for the cgroups of init (pid 1)\n        initCGroups = FilePath(_initCGroupLocation)\n        if initCGroups.exists():\n            # The cgroups file looks like \"2:cpu:/\". The third element will\n            # begin with /docker if it is inside a Docker container.\n            controlGroups = [\n                x.split(b\":\") for x in initCGroups.getContent().split(b\"\\n\")\n            ]\n\n            for group in controlGroups:\n                if len(group) == 3 and group[2].startswith(b\"/docker/\"):\n                    # If it starts with /docker/, we're in a docker container\n                    return True\n\n        return False\n\n    def _supportsSymlinks(self) -> bool:\n        \"\"\"\n        Check for symlink support usable for Twisted's purposes.\n\n        @return: C{True} if symlinks are supported on the current platform,\n                 otherwise C{False}.\n        \"\"\"\n        if self.isWindows():\n            # We do the isWindows() check as newer Pythons support the symlink\n            # support in Vista+, but only if you have some obscure permission\n            # (SeCreateSymbolicLinkPrivilege), which can only be given on\n            # platforms with msc.exe (so, Business/Enterprise editions).\n            # This uncommon requirement makes the Twisted test suite test fail\n            # in 99.99% of cases as general users don't have permission to do\n            # it, even if there is \"symlink support\".\n            return False\n        else:\n            # If we're not on Windows, check for existence of os.symlink.\n            try:\n                os.symlink\n            except AttributeError:\n                return False\n            else:\n                return True\n\n    def supportsThreads(self) -> bool:\n        \"\"\"\n        Can threads be created?\n\n        @return: C{True} if the threads are supported on the current platform.\n        \"\"\"\n        try:\n            import threading\n\n            return threading is not None  # shh pyflakes\n        except ImportError:\n            return False\n\n    def supportsINotify(self) -> bool:\n        \"\"\"\n        Return C{True} if we can use the inotify API on this platform.\n\n        @since: 10.1\n        \"\"\"\n        try:\n            from twisted.python._inotify import INotifyError, init\n        except ImportError:\n            return False\n\n        try:\n            os.close(init())\n        except INotifyError:\n            return False\n        return True\n\n\nplatform = Platform()\nplatformType = platform.getType()\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_compat\\test_compat.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_compat -*-\n#\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nCompatibility module to provide backwards compatibility for useful Python\nfeatures.\n\nThis is mainly for use of internal Twisted code. We encourage you to use\nthe latest version of Python directly from your code, if possible.\n\n@var unicode: The type of Unicode strings, C{unicode} on Python 2 and C{str}\n    on Python 3.\n\n@var NativeStringIO: An in-memory file-like object that operates on the native\n    string type (bytes in Python 2, unicode in Python 3).\n\n@var urllib_parse: a URL-parsing module (urlparse on Python 2, urllib.parse on\n    Python 3)\n\"\"\"\n\n\nimport inspect\nimport os\nimport platform\nimport socket\nimport urllib.parse as urllib_parse\nfrom collections.abc import Sequence\nfrom functools import reduce\nfrom html import escape\nfrom http import cookiejar as cookielib\nfrom io import IOBase, StringIO as NativeStringIO, TextIOBase\nfrom sys import intern\nfrom types import FrameType, MethodType as _MethodType\nfrom typing import Any, AnyStr, cast\nfrom urllib.parse import quote as urlquote, unquote as urlunquote\n\nfrom incremental import Version\n\nfrom twisted.python.deprecate import deprecated, deprecatedModuleAttribute\n\nif platform.python_implementation() == \"PyPy\":\n    _PYPY = True\nelse:\n    _PYPY = False\n\nFileType = IOBase\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for io.IOBase\",\n    __name__,\n    \"FileType\",\n)\n\nfrozenset = frozenset\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for frozenset builtin type\",\n    __name__,\n    \"frozenset\",\n)\n\nInstanceType = object\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Old-style classes don't exist in Python 3\",\n    __name__,\n    \"InstanceType\",\n)\n\nizip = zip\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for zip() builtin\",\n    __name__,\n    \"izip\",\n)\n\nlong = int\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for int builtin type\",\n    __name__,\n    \"long\",\n)\n\nrange = range\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for range() builtin\",\n    __name__,\n    \"range\",\n)\n\nraw_input = input\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for input() builtin\",\n    __name__,\n    \"raw_input\",\n)\n\nset = set\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for set builtin type\",\n    __name__,\n    \"set\",\n)\n\nStringType = str\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for str builtin type\",\n    __name__,\n    \"StringType\",\n)\n\nunichr = chr\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for chr() builtin\",\n    __name__,\n    \"unichr\",\n)\n\nunicode = str\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for str builtin type\",\n    __name__,\n    \"unicode\",\n)\n\nxrange = range\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for range() builtin\",\n    __name__,\n    \"xrange\",\n)\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"d.items()\")\ndef iteritems(d):\n    \"\"\"\n    Return an iterable of the items of C{d}.\n\n    @type d: L{dict}\n    @rtype: iterable\n    \"\"\"\n    return d.items()\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"d.values()\")\ndef itervalues(d):\n    \"\"\"\n    Return an iterable of the values of C{d}.\n\n    @type d: L{dict}\n    @rtype: iterable\n    \"\"\"\n    return d.values()\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"list(d.items())\")\ndef items(d):\n    \"\"\"\n    Return a list of the items of C{d}.\n\n    @type d: L{dict}\n    @rtype: L{list}\n    \"\"\"\n    return list(d.items())\n\n\ndef currentframe(n: int = 0) -> FrameType:\n    \"\"\"\n    In Python 3, L{inspect.currentframe} does not take a stack-level argument.\n    Restore that functionality from Python 2 so we don't have to re-implement\n    the C{f_back}-walking loop in places where it's called.\n\n    @param n: The number of stack levels above the caller to walk.\n\n    @return: a frame, n levels up the stack from the caller.\n    \"\"\"\n    f = inspect.currentframe()\n    for x in range(n + 1):\n        assert f is not None\n        f = f.f_back\n    assert f is not None\n    return f\n\n\ndef execfile(filename, globals, locals=None):\n    \"\"\"\n    Execute a Python script in the given namespaces.\n\n    Similar to the execfile builtin, but a namespace is mandatory, partly\n    because that's a sensible thing to require, and because otherwise we'd\n    have to do some frame hacking.\n\n    This is a compatibility implementation for Python 3 porting, to avoid the\n    use of the deprecated builtin C{execfile} function.\n    \"\"\"\n    if locals is None:\n        locals = globals\n    with open(filename, \"rb\") as fin:\n        source = fin.read()\n    code = compile(source, filename, \"exec\")\n    exec(code, globals, locals)\n\n\n# type note: Can't find a Comparable type, despite\n# https://github.com/python/typing/issues/59\ndef cmp(a: object, b: object) -> int:\n    \"\"\"\n    Compare two objects.\n\n    Returns a negative number if C{a < b}, zero if they are equal, and a\n    positive number if C{a > b}.\n    \"\"\"\n    if a < b:  # type: ignore[operator]\n        return -1\n    elif a == b:\n        return 0\n    else:\n        return 1\n\n\ndef comparable(klass):\n    \"\"\"\n    Class decorator that ensures support for the special C{__cmp__} method.\n\n    C{__eq__}, C{__lt__}, etc. methods are added to the class, relying on\n    C{__cmp__} to implement their comparisons.\n    \"\"\"\n\n    def __eq__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c == 0\n\n    def __ne__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c != 0\n\n    def __lt__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c < 0\n\n    def __le__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c <= 0\n\n    def __gt__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c > 0\n\n    def __ge__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c >= 0\n\n    klass.__lt__ = __lt__\n    klass.__gt__ = __gt__\n    klass.__le__ = __le__\n    klass.__ge__ = __ge__\n    klass.__eq__ = __eq__\n    klass.__ne__ = __ne__\n    return klass\n\n\ndef ioType(fileIshObject, default=str):\n    \"\"\"\n    Determine the type which will be returned from the given file object's\n    read() and accepted by its write() method as an argument.\n\n    In other words, determine whether the given file is 'opened in text mode'.\n\n    @param fileIshObject: Any object, but ideally one which resembles a file.\n    @type fileIshObject: L{object}\n\n    @param default: A default value to return when the type of C{fileIshObject}\n        cannot be determined.\n    @type default: L{type}\n\n    @return: There are 3 possible return values:\n\n            1. L{str}, if the file is unambiguously opened in text mode.\n\n            2. L{bytes}, if the file is unambiguously opened in binary mode.\n\n            3. The C{default} parameter, if the given type is not understood.\n\n    @rtype: L{type}\n    \"\"\"\n    if isinstance(fileIshObject, TextIOBase):\n        # If it's for text I/O, then it's for text I/O.\n        return str\n    if isinstance(fileIshObject, IOBase):\n        # If it's for I/O but it's _not_ for text I/O, it's for bytes I/O.\n        return bytes\n    encoding = getattr(fileIshObject, \"encoding\", None)\n    import codecs\n\n    if isinstance(fileIshObject, (codecs.StreamReader, codecs.StreamWriter)):\n        # On StreamReaderWriter, the 'encoding' attribute has special meaning;\n        # it is unambiguously text.\n        if encoding:\n            return str\n        else:\n            return bytes\n    return default\n\n\ndef nativeString(s: AnyStr) -> str:\n    \"\"\"\n    Convert C{bytes} or C{str} to C{str} type, using ASCII encoding if\n    conversion is necessary.\n\n    @raise UnicodeError: The input string is not ASCII encodable/decodable.\n    @raise TypeError: The input is neither C{bytes} nor C{str}.\n    \"\"\"\n    if not isinstance(s, (bytes, str)):\n        raise TypeError(\"%r is neither bytes nor str\" % s)\n    if isinstance(s, bytes):\n        return s.decode(\"ascii\")\n    else:\n        # Ensure we're limited to ASCII subset:\n        s.encode(\"ascii\")\n    return s\n\n\ndef _matchingString(constantString, inputString):\n    \"\"\"\n    Some functions, such as C{os.path.join}, operate on string arguments which\n    may be bytes or text, and wish to return a value of the same type.  In\n    those cases you may wish to have a string constant (in the case of\n    C{os.path.join}, that constant would be C{os.path.sep}) involved in the\n    parsing or processing, that must be of a matching type in order to use\n    string operations on it.  L{_matchingString} will take a constant string\n    (either L{bytes} or L{str}) and convert it to the same type as the\n    input string.  C{constantString} should contain only characters from ASCII;\n    to ensure this, it will be encoded or decoded regardless.\n\n    @param constantString: A string literal used in processing.\n    @type constantString: L{str} or L{bytes}\n\n    @param inputString: A byte string or text string provided by the user.\n    @type inputString: L{str} or L{bytes}\n\n    @return: C{constantString} converted into the same type as C{inputString}\n    @rtype: the type of C{inputString}\n    \"\"\"\n    if isinstance(constantString, bytes):\n        otherType = constantString.decode(\"ascii\")\n    else:\n        otherType = constantString.encode(\"ascii\")\n    if type(constantString) == type(inputString):\n        return constantString\n    else:\n        return otherType\n\n\n@deprecated(\n    Version(\"Twisted\", 21, 2, 0),\n    replacement=\"raise exception.with_traceback(traceback)\",\n)\ndef reraise(exception, traceback):\n    \"\"\"\n    Re-raise an exception, with an optional traceback.\n\n    Re-raised exceptions will be mutated, with their C{__traceback__} attribute\n    being set.\n\n    @param exception: The exception instance.\n    @param traceback: The traceback to use, or L{None} indicating a new\n    traceback.\n    \"\"\"\n    raise exception.with_traceback(traceback)\n\n\ndef iterbytes(originalBytes):\n    \"\"\"\n    Return an iterable wrapper for a C{bytes} object that provides the behavior\n    of iterating over C{bytes} on Python 2.\n\n    In particular, the results of iteration are the individual bytes (rather\n    than integers as on Python 3).\n\n    @param originalBytes: A C{bytes} object that will be wrapped.\n    \"\"\"\n    for i in range(len(originalBytes)):\n        yield originalBytes[i : i + 1]\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"b'%d'\")\ndef intToBytes(i: int) -> bytes:\n    \"\"\"\n    Convert the given integer into C{bytes}, as ASCII-encoded Arab numeral.\n\n    @param i: The C{int} to convert to C{bytes}.\n    @rtype: C{bytes}\n    \"\"\"\n    return b\"%d\" % (i,)\n\n\ndef lazyByteSlice(object, offset=0, size=None):\n    \"\"\"\n    Return a memory view of the given bytes-like object.\n\n    If an offset is given, the view starts at that offset. If a size is\n    given, the view will only be of that length.\n\n    @param object: C{bytes} to be sliced.\n\n    @param offset: C{int}, starting index of view.\n\n    @param size: Optional, if an C{int} is given limit the length of the view\n        to this size.\n    \"\"\"\n    view = memoryview(object)\n    if size is None:\n        return view[offset:]\n    else:\n        return view[offset : (offset + size)]\n\n\ndef networkString(s: str) -> bytes:\n    \"\"\"\n    Convert a string to L{bytes} using ASCII encoding.\n\n    This is useful for sending text-like bytes that are constructed using\n    string interpolation.  For example::\n\n        networkString(\"Hello %d\" % (n,))\n\n    @param s: A string to convert to bytes.\n    @type s: L{str}\n\n    @raise UnicodeError: The input string is not ASCII encodable.\n    @raise TypeError: The input is not L{str}.\n\n    @rtype: L{bytes}\n    \"\"\"\n    if not isinstance(s, str):\n        raise TypeError(\"Can only convert strings to bytes\")\n    return s.encode(\"ascii\")\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"os.environb\")\ndef bytesEnviron():\n    \"\"\"\n    Return a L{dict} of L{os.environ} where all text-strings are encoded into\n    L{bytes}.\n\n    This function is POSIX only; environment variables are always text strings\n    on Windows.\n    \"\"\"\n    encodekey = os.environ.encodekey\n    encodevalue = os.environ.encodevalue\n\n    return {encodekey(x): encodevalue(y) for x, y in os.environ.items()}\n\n\ndef _constructMethod(cls, name, self):\n    \"\"\"\n    Construct a bound method.\n\n    @param cls: The class that the method should be bound to.\n    @type cls: L{type}\n\n    @param name: The name of the method.\n    @type name: native L{str}\n\n    @param self: The object that the method is bound to.\n    @type self: any object\n\n    @return: a bound method\n    @rtype: L{_MethodType}\n    \"\"\"\n    func = cls.__dict__[name]\n    return _MethodType(func, self)\n\n\ndef _pypy3BlockingHack():\n    \"\"\"\n    Work around U{https://foss.heptapod.net/pypy/pypy/-/issues/3051}\n    by replacing C{socket.fromfd} with a more conservative version.\n    \"\"\"\n    try:\n        from fcntl import F_GETFL, F_SETFL, fcntl\n    except ImportError:\n        return\n    if not _PYPY:\n        return\n\n    def fromFDWithoutModifyingFlags(fd, family, type, proto=None):\n        passproto = [proto] * (proto is not None)\n        flags = fcntl(fd, F_GETFL)\n        try:\n            return realFromFD(fd, family, type, *passproto)\n        finally:\n            fcntl(fd, F_SETFL, flags)\n\n    realFromFD = socket.fromfd\n    if realFromFD.__name__ == fromFDWithoutModifyingFlags.__name__:\n        return\n    socket.fromfd = fromFDWithoutModifyingFlags\n\n\n_pypy3BlockingHack()\n\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use functools.reduce() directly\",\n    __name__,\n    \"reduce\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use io.StringIO directly\",\n    __name__,\n    \"NativeStringIO\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Import urllib.parse directly\",\n    __name__,\n    \"urllib_parse\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0), \"Use html.escape directly\", __name__, \"escape\"\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use urllib.parse.quote() directly\",\n    __name__,\n    \"urlquote\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use urllib.parse.unquote() directly\",\n    __name__,\n    \"urlunquote\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use http.cookiejar directly\",\n    __name__,\n    \"cookielib\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0), \"Use sys.intern() directly\", __name__, \"intern\"\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use collections.abc.Sequence directly\",\n    __name__,\n    \"Sequence\",\n)\n\n\n__all__ = [\n    \"reraise\",\n    \"execfile\",\n    \"frozenset\",\n    \"reduce\",\n    \"set\",\n    \"cmp\",\n    \"comparable\",\n    \"nativeString\",\n    \"NativeStringIO\",\n    \"networkString\",\n    \"unicode\",\n    \"iterbytes\",\n    \"intToBytes\",\n    \"lazyByteSlice\",\n    \"StringType\",\n    \"InstanceType\",\n    \"FileType\",\n    \"items\",\n    \"iteritems\",\n    \"itervalues\",\n    \"range\",\n    \"xrange\",\n    \"urllib_parse\",\n    \"bytesEnviron\",\n    \"escape\",\n    \"urlquote\",\n    \"urlunquote\",\n    \"cookielib\",\n    \"intern\",\n    \"unichr\",\n    \"raw_input\",\n    \"Sequence\",\n]\n\n### Source File Dependency Files Content\n### Dependency File: deprecate.py\n# -*- test-case-name: twisted.python.test.test_deprecate -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nDeprecation framework for Twisted.\n\nTo mark a method, function, or class as being deprecated do this::\n\n    from incremental import Version\n    from twisted.python.deprecate import deprecated\n\n    @deprecated(Version(\"Twisted\", 22, 10, 0))\n    def badAPI(self, first, second):\n        '''\n        Docstring for badAPI.\n        '''\n        ...\n\n    @deprecated(Version(\"Twisted\", 22, 10, 0))\n    class BadClass:\n        '''\n        Docstring for BadClass.\n        '''\n\nThe newly-decorated badAPI will issue a warning when called, and BadClass will\nissue a warning when instantiated. Both will also have  a deprecation notice\nappended to their docstring.\n\nTo deprecate properties you can use::\n\n    from incremental import Version\n    from twisted.python.deprecate import deprecatedProperty\n\n    class OtherwiseUndeprecatedClass:\n\n        @deprecatedProperty(Version(\"Twisted\", 22, 10, 0))\n        def badProperty(self):\n            '''\n            Docstring for badProperty.\n            '''\n\n        @badProperty.setter\n        def badProperty(self, value):\n            '''\n            Setter sill also raise the deprecation warning.\n            '''\n\n\nWhile it's best to avoid this as it adds performance overhead to *any* usage of\nthe module, to mark module-level attributes as being deprecated you can use::\n\n    badAttribute = \"someValue\"\n\n    ...\n\n    deprecatedModuleAttribute(\n        Version(\"Twisted\", 22, 10, 0),\n        \"Use goodAttribute instead.\",\n        \"your.full.module.name\",\n        \"badAttribute\")\n\nThe deprecated attributes will issue a warning whenever they are accessed. If\nthe attributes being deprecated are in the same module as the\nL{deprecatedModuleAttribute} call is being made from, the C{__name__} global\ncan be used as the C{moduleName} parameter.\n\n\nTo mark an optional, keyword parameter of a function or method as deprecated\nwithout deprecating the function itself, you can use::\n\n    @deprecatedKeywordParameter(Version(\"Twisted\", 22, 10, 0), \"baz\")\n    def someFunction(foo, bar=0, baz=None):\n        ...\n\nSee also L{incremental.Version}.\n\n@type DEPRECATION_WARNING_FORMAT: C{str}\n@var DEPRECATION_WARNING_FORMAT: The default deprecation warning string format\n    to use when one is not provided by the user.\n\"\"\"\nfrom __future__ import annotations\n\n__all__ = [\n    \"deprecated\",\n    \"deprecatedProperty\",\n    \"getDeprecationWarningString\",\n    \"getWarningMethod\",\n    \"setWarningMethod\",\n    \"deprecatedModuleAttribute\",\n    \"deprecatedKeywordParameter\",\n]\n\n\nimport inspect\nimport sys\nfrom dis import findlinestarts\nfrom functools import wraps\nfrom types import ModuleType\nfrom typing import Any, Callable, Dict, Optional, TypeVar, cast\nfrom warnings import warn, warn_explicit\n\nfrom incremental import Version, getVersionString\nfrom typing_extensions import ParamSpec\n\n_P = ParamSpec(\"_P\")\n_R = TypeVar(\"_R\")\n\nDEPRECATION_WARNING_FORMAT = \"%(fqpn)s was deprecated in %(version)s\"\n\n# Notionally, part of twisted.python.reflect, but defining it there causes a\n# cyclic dependency between this module and that module.  Define it here,\n# instead, and let reflect import it to re-expose to the public.\n\n\ndef _fullyQualifiedName(obj):\n    \"\"\"\n    Return the fully qualified name of a module, class, method or function.\n    Classes and functions need to be module level ones to be correctly\n    qualified.\n\n    @rtype: C{str}.\n    \"\"\"\n    try:\n        name = obj.__qualname__\n    except AttributeError:\n        name = obj.__name__\n\n    if inspect.isclass(obj) or inspect.isfunction(obj):\n        moduleName = obj.__module__\n        return f\"{moduleName}.{name}\"\n    elif inspect.ismethod(obj):\n        return f\"{obj.__module__}.{obj.__qualname__}\"\n    return name\n\n\n# Try to keep it looking like something in twisted.python.reflect.\n_fullyQualifiedName.__module__ = \"twisted.python.reflect\"\n_fullyQualifiedName.__name__ = \"fullyQualifiedName\"\n_fullyQualifiedName.__qualname__ = \"fullyQualifiedName\"\n\n\ndef _getReplacementString(replacement):\n    \"\"\"\n    Surround a replacement for a deprecated API with some polite text exhorting\n    the user to consider it as an alternative.\n\n    @type replacement: C{str} or callable\n\n    @return: a string like \"please use twisted.python.modules.getModule\n        instead\".\n    \"\"\"\n    if callable(replacement):\n        replacement = _fullyQualifiedName(replacement)\n    return f\"please use {replacement} instead\"\n\n\ndef _getDeprecationDocstring(version, replacement=None):\n    \"\"\"\n    Generate an addition to a deprecated object's docstring that explains its\n    deprecation.\n\n    @param version: the version it was deprecated.\n    @type version: L{incremental.Version}\n\n    @param replacement: The replacement, if specified.\n    @type replacement: C{str} or callable\n\n    @return: a string like \"Deprecated in Twisted 27.2.0; please use\n        twisted.timestream.tachyon.flux instead.\"\n    \"\"\"\n    doc = f\"Deprecated in {getVersionString(version)}\"\n    if replacement:\n        doc = f\"{doc}; {_getReplacementString(replacement)}\"\n    return doc + \".\"\n\n\ndef _getDeprecationWarningString(fqpn, version, format=None, replacement=None):\n    \"\"\"\n    Return a string indicating that the Python name was deprecated in the given\n    version.\n\n    @param fqpn: Fully qualified Python name of the thing being deprecated\n    @type fqpn: C{str}\n\n    @param version: Version that C{fqpn} was deprecated in.\n    @type version: L{incremental.Version}\n\n    @param format: A user-provided format to interpolate warning values into, or\n        L{DEPRECATION_WARNING_FORMAT\n        <twisted.python.deprecate.DEPRECATION_WARNING_FORMAT>} if L{None} is\n        given.\n    @type format: C{str}\n\n    @param replacement: what should be used in place of C{fqpn}. Either pass in\n        a string, which will be inserted into the warning message, or a\n        callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n\n    @return: A textual description of the deprecation\n    @rtype: C{str}\n    \"\"\"\n    if format is None:\n        format = DEPRECATION_WARNING_FORMAT\n    warningString = format % {\"fqpn\": fqpn, \"version\": getVersionString(version)}\n    if replacement:\n        warningString = \"{}; {}\".format(\n            warningString, _getReplacementString(replacement)\n        )\n    return warningString\n\n\ndef getDeprecationWarningString(callableThing, version, format=None, replacement=None):\n    \"\"\"\n    Return a string indicating that the callable was deprecated in the given\n    version.\n\n    @type callableThing: C{callable}\n    @param callableThing: Callable object to be deprecated\n\n    @type version: L{incremental.Version}\n    @param version: Version that C{callableThing} was deprecated in.\n\n    @type format: C{str}\n    @param format: A user-provided format to interpolate warning values into,\n        or L{DEPRECATION_WARNING_FORMAT\n        <twisted.python.deprecate.DEPRECATION_WARNING_FORMAT>} if L{None} is\n        given\n\n    @param replacement: what should be used in place of the callable. Either\n        pass in a string, which will be inserted into the warning message,\n        or a callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n\n    @return: A string describing the deprecation.\n    @rtype: C{str}\n    \"\"\"\n    return _getDeprecationWarningString(\n        _fullyQualifiedName(callableThing), version, format, replacement\n    )\n\n\ndef _appendToDocstring(thingWithDoc, textToAppend):\n    \"\"\"\n    Append the given text to the docstring of C{thingWithDoc}.\n\n    If C{thingWithDoc} has no docstring, then the text just replaces the\n    docstring. If it has a single-line docstring then it appends a blank line\n    and the message text. If it has a multi-line docstring, then in appends a\n    blank line a the message text, and also does the indentation correctly.\n    \"\"\"\n    if thingWithDoc.__doc__:\n        docstringLines = thingWithDoc.__doc__.splitlines()\n    else:\n        docstringLines = []\n\n    if len(docstringLines) == 0:\n        docstringLines.append(textToAppend)\n    elif len(docstringLines) == 1:\n        docstringLines.extend([\"\", textToAppend, \"\"])\n    else:\n        trailer = docstringLines[-1]\n        spaces = \"\"\n        if not trailer.strip():\n            # Deal with differences between Python 3.13 and older versions.\n            spaces = docstringLines.pop()\n        docstringLines.extend([\"\", spaces + textToAppend, spaces])\n        docstringLines = [l.lstrip(\" \") for l in docstringLines]\n    thingWithDoc.__doc__ = \"\\n\".join(docstringLines)\n\n\ndef deprecated(\n    version: Version, replacement: str | Callable[..., object] | None = None\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:\n    \"\"\"\n    Return a decorator that marks callables as deprecated. To deprecate a\n    property, see L{deprecatedProperty}.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the callable will be marked as\n        having been deprecated.  The decorated function will be annotated\n        with this version, having it set as its C{deprecatedVersion}\n        attribute.\n\n    @param replacement: what should be used in place of the callable. Either\n        pass in a string, which will be inserted into the warning message,\n        or a callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n    \"\"\"\n\n    def deprecationDecorator(function: Callable[_P, _R]) -> Callable[_P, _R]:\n        \"\"\"\n        Decorator that marks C{function} as deprecated.\n        \"\"\"\n        warningString = getDeprecationWarningString(\n            function, version, None, replacement\n        )\n\n        @wraps(function)\n        def deprecatedFunction(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            warn(warningString, DeprecationWarning, stacklevel=2)\n            return function(*args, **kwargs)\n\n        _appendToDocstring(\n            deprecatedFunction, _getDeprecationDocstring(version, replacement)\n        )\n        deprecatedFunction.deprecatedVersion = version  # type: ignore[attr-defined]\n        return deprecatedFunction\n\n    return deprecationDecorator\n\n\ndef deprecatedProperty(\n    version: Version, replacement: str | Callable[..., object] | None = None\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:\n    \"\"\"\n    Return a decorator that marks a property as deprecated. To deprecate a\n    regular callable or class, see L{deprecated}.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the callable will be marked as\n        having been deprecated.  The decorated function will be annotated\n        with this version, having it set as its C{deprecatedVersion}\n        attribute.\n\n    @param replacement: what should be used in place of the callable.\n        Either pass in a string, which will be inserted into the warning\n        message, or a callable, which will be expanded to its full import\n        path.\n    @type replacement: C{str} or callable\n\n    @return: A new property with deprecated setter and getter.\n    @rtype: C{property}\n\n    @since: 16.1.0\n    \"\"\"\n\n    class _DeprecatedProperty(property):\n        \"\"\"\n        Extension of the build-in property to allow deprecated setters.\n        \"\"\"\n\n        def _deprecatedWrapper(self, function):\n            @wraps(function)\n            def deprecatedFunction(*args, **kwargs):\n                warn(\n                    self.warningString,  # type: ignore[attr-defined]\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                return function(*args, **kwargs)\n\n            return deprecatedFunction\n\n        def setter(self, function):\n            return property.setter(self, self._deprecatedWrapper(function))\n\n    def deprecationDecorator(function):\n        warningString = getDeprecationWarningString(\n            function, version, None, replacement\n        )\n\n        @wraps(function)\n        def deprecatedFunction(*args, **kwargs):\n            warn(warningString, DeprecationWarning, stacklevel=2)\n            return function(*args, **kwargs)\n\n        _appendToDocstring(\n            deprecatedFunction, _getDeprecationDocstring(version, replacement)\n        )\n        deprecatedFunction.deprecatedVersion = version  # type: ignore[attr-defined]\n\n        result = _DeprecatedProperty(deprecatedFunction)\n        result.warningString = warningString  # type: ignore[attr-defined]\n        return result\n\n    return deprecationDecorator\n\n\ndef getWarningMethod():\n    \"\"\"\n    Return the warning method currently used to record deprecation warnings.\n    \"\"\"\n    return warn\n\n\ndef setWarningMethod(newMethod):\n    \"\"\"\n    Set the warning method to use to record deprecation warnings.\n\n    The callable should take message, category and stacklevel. The return\n    value is ignored.\n    \"\"\"\n    global warn\n    warn = newMethod\n\n\nclass _InternalState:\n    \"\"\"\n    An L{_InternalState} is a helper object for a L{_ModuleProxy}, so that it\n    can easily access its own attributes, bypassing its logic for delegating to\n    another object that it's proxying for.\n\n    @ivar proxy: a L{_ModuleProxy}\n    \"\"\"\n\n    def __init__(self, proxy):\n        object.__setattr__(self, \"proxy\", proxy)\n\n    def __getattribute__(self, name):\n        return object.__getattribute__(object.__getattribute__(self, \"proxy\"), name)\n\n    def __setattr__(self, name, value):\n        return object.__setattr__(object.__getattribute__(self, \"proxy\"), name, value)\n\n\nclass _ModuleProxy:\n    \"\"\"\n    Python module wrapper to hook module-level attribute access.\n\n    Access to deprecated attributes first checks\n    L{_ModuleProxy._deprecatedAttributes}, if the attribute does not appear\n    there then access falls through to L{_ModuleProxy._module}, the wrapped\n    module object.\n\n    @ivar _module: Module on which to hook attribute access.\n    @type _module: C{module}\n\n    @ivar _deprecatedAttributes: Mapping of attribute names to objects that\n        retrieve the module attribute's original value.\n    @type _deprecatedAttributes: C{dict} mapping C{str} to\n        L{_DeprecatedAttribute}\n\n    @ivar _lastWasPath: Heuristic guess as to whether warnings about this\n        package should be ignored for the next call.  If the last attribute\n        access of this module was a C{getattr} of C{__path__}, we will assume\n        that it was the import system doing it and we won't emit a warning for\n        the next access, even if it is to a deprecated attribute.  The CPython\n        import system always tries to access C{__path__}, then the attribute\n        itself, then the attribute itself again, in both successful and failed\n        cases.\n    @type _lastWasPath: C{bool}\n    \"\"\"\n\n    def __init__(self, module):\n        state = _InternalState(self)\n        state._module = module\n        state._deprecatedAttributes = {}\n        state._lastWasPath = False\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Get a string containing the type of the module proxy and a\n        representation of the wrapped module object.\n        \"\"\"\n        state = _InternalState(self)\n        return f\"<{type(self).__name__} module={state._module!r}>\"\n\n    def __setattr__(self, name, value):\n        \"\"\"\n        Set an attribute on the wrapped module object.\n        \"\"\"\n        state = _InternalState(self)\n        state._lastWasPath = False\n        setattr(state._module, name, value)\n\n    def __getattribute__(self, name):\n        \"\"\"\n        Get an attribute from the module object, possibly emitting a warning.\n\n        If the specified name has been deprecated, then a warning is issued.\n        (Unless certain obscure conditions are met; see\n        L{_ModuleProxy._lastWasPath} for more information about what might quash\n        such a warning.)\n        \"\"\"\n        state = _InternalState(self)\n        if state._lastWasPath:\n            deprecatedAttribute = None\n        else:\n            deprecatedAttribute = state._deprecatedAttributes.get(name)\n\n        if deprecatedAttribute is not None:\n            # If we have a _DeprecatedAttribute object from the earlier lookup,\n            # allow it to issue the warning.\n            value = deprecatedAttribute.get()\n        else:\n            # Otherwise, just retrieve the underlying value directly; it's not\n            # deprecated, there's no warning to issue.\n            value = getattr(state._module, name)\n        if name == \"__path__\":\n            state._lastWasPath = True\n        else:\n            state._lastWasPath = False\n        return value\n\n\nclass _DeprecatedAttribute:\n    \"\"\"\n    Wrapper for deprecated attributes.\n\n    This is intended to be used by L{_ModuleProxy}. Calling\n    L{_DeprecatedAttribute.get} will issue a warning and retrieve the\n    underlying attribute's value.\n\n    @type module: C{module}\n    @ivar module: The original module instance containing this attribute\n\n    @type fqpn: C{str}\n    @ivar fqpn: Fully qualified Python name for the deprecated attribute\n\n    @type version: L{incremental.Version}\n    @ivar version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @ivar message: Deprecation message\n    \"\"\"\n\n    def __init__(self, module, name, version, message):\n        \"\"\"\n        Initialise a deprecated name wrapper.\n        \"\"\"\n        self.module = module\n        self.__name__ = name\n        self.fqpn = module.__name__ + \".\" + name\n        self.version = version\n        self.message = message\n\n    def get(self):\n        \"\"\"\n        Get the underlying attribute value and issue a deprecation warning.\n        \"\"\"\n        # This might fail if the deprecated thing is a module inside a package.\n        # In that case, don't emit the warning this time.  The import system\n        # will come back again when it's not an AttributeError and we can emit\n        # the warning then.\n        result = getattr(self.module, self.__name__)\n        message = _getDeprecationWarningString(\n            self.fqpn, self.version, DEPRECATION_WARNING_FORMAT + \": \" + self.message\n        )\n        warn(message, DeprecationWarning, stacklevel=3)\n        return result\n\n\ndef _deprecateAttribute(proxy, name, version, message):\n    \"\"\"\n    Mark a module-level attribute as being deprecated.\n\n    @type proxy: L{_ModuleProxy}\n    @param proxy: The module proxy instance proxying the deprecated attributes\n\n    @type name: C{str}\n    @param name: Attribute name\n\n    @type version: L{incremental.Version}\n    @param version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @param message: Deprecation message\n    \"\"\"\n    _module = object.__getattribute__(proxy, \"_module\")\n    attr = _DeprecatedAttribute(_module, name, version, message)\n    # Add a deprecated attribute marker for this module's attribute. When this\n    # attribute is accessed via _ModuleProxy a warning is emitted.\n    _deprecatedAttributes = object.__getattribute__(proxy, \"_deprecatedAttributes\")\n    _deprecatedAttributes[name] = attr\n\n\ndef deprecatedModuleAttribute(version, message, moduleName, name):\n    \"\"\"\n    Declare a module-level attribute as being deprecated.\n\n    @type version: L{incremental.Version}\n    @param version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @param message: Deprecation message\n\n    @type moduleName: C{str}\n    @param moduleName: Fully-qualified Python name of the module containing\n        the deprecated attribute; if called from the same module as the\n        attributes are being deprecated in, using the C{__name__} global can\n        be helpful\n\n    @type name: C{str}\n    @param name: Attribute name to deprecate\n    \"\"\"\n    module = sys.modules[moduleName]\n    if not isinstance(module, _ModuleProxy):\n        module = cast(ModuleType, _ModuleProxy(module))\n        sys.modules[moduleName] = module\n\n    _deprecateAttribute(module, name, version, message)\n\n\ndef warnAboutFunction(offender, warningString):\n    \"\"\"\n    Issue a warning string, identifying C{offender} as the responsible code.\n\n    This function is used to deprecate some behavior of a function.  It differs\n    from L{warnings.warn} in that it is not limited to deprecating the behavior\n    of a function currently on the call stack.\n\n    @param offender: The function that is being deprecated.\n\n    @param warningString: The string that should be emitted by this warning.\n    @type warningString: C{str}\n\n    @since: 11.0\n    \"\"\"\n    # inspect.getmodule() is attractive, but somewhat\n    # broken in Python < 2.6.  See Python bug 4845.\n    # In Python 3.13 line numbers returned by findlinestarts\n    # can be None for bytecode that does not map to source\n    # lines.\n    offenderModule = sys.modules[offender.__module__]\n    warn_explicit(\n        warningString,\n        category=DeprecationWarning,\n        filename=inspect.getabsfile(offenderModule),\n        lineno=max(\n            lineNumber\n            for _, lineNumber in findlinestarts(offender.__code__)\n            if lineNumber is not None\n        ),\n        module=offenderModule.__name__,\n        registry=offender.__globals__.setdefault(\"__warningregistry__\", {}),\n        module_globals=None,\n    )\n\n\ndef _passedArgSpec(argspec, positional, keyword):\n    \"\"\"\n    Take an I{inspect.ArgSpec}, a tuple of positional arguments, and a dict of\n    keyword arguments, and return a mapping of arguments that were actually\n    passed to their passed values.\n\n    @param argspec: The argument specification for the function to inspect.\n    @type argspec: I{inspect.ArgSpec}\n\n    @param positional: The positional arguments that were passed.\n    @type positional: L{tuple}\n\n    @param keyword: The keyword arguments that were passed.\n    @type keyword: L{dict}\n\n    @return: A dictionary mapping argument names (those declared in C{argspec})\n        to values that were passed explicitly by the user.\n    @rtype: L{dict} mapping L{str} to L{object}\n    \"\"\"\n    result: Dict[str, object] = {}\n    unpassed = len(argspec.args) - len(positional)\n    if argspec.keywords is not None:\n        kwargs = result[argspec.keywords] = {}\n    if unpassed < 0:\n        if argspec.varargs is None:\n            raise TypeError(\"Too many arguments.\")\n        else:\n            result[argspec.varargs] = positional[len(argspec.args) :]\n    for name, value in zip(argspec.args, positional):\n        result[name] = value\n    for name, value in keyword.items():\n        if name in argspec.args:\n            if name in result:\n                raise TypeError(\"Already passed.\")\n            result[name] = value\n        elif argspec.keywords is not None:\n            kwargs[name] = value\n        else:\n            raise TypeError(\"no such param\")\n    return result\n\n\ndef _passedSignature(signature, positional, keyword):\n    \"\"\"\n    Take an L{inspect.Signature}, a tuple of positional arguments, and a dict of\n    keyword arguments, and return a mapping of arguments that were actually\n    passed to their passed values.\n\n    @param signature: The signature of the function to inspect.\n    @type signature: L{inspect.Signature}\n\n    @param positional: The positional arguments that were passed.\n    @type positional: L{tuple}\n\n    @param keyword: The keyword arguments that were passed.\n    @type keyword: L{dict}\n\n    @return: A dictionary mapping argument names (those declared in\n        C{signature}) to values that were passed explicitly by the user.\n    @rtype: L{dict} mapping L{str} to L{object}\n    \"\"\"\n    result = {}\n    kwargs = None\n    numPositional = 0\n    for n, (name, param) in enumerate(signature.parameters.items()):\n        if param.kind == inspect.Parameter.VAR_POSITIONAL:\n            # Varargs, for example: *args\n            result[name] = positional[n:]\n            numPositional = len(result[name]) + 1\n        elif param.kind == inspect.Parameter.VAR_KEYWORD:\n            # Variable keyword args, for example: **my_kwargs\n            kwargs = result[name] = {}\n        elif param.kind in (\n            inspect.Parameter.POSITIONAL_OR_KEYWORD,\n            inspect.Parameter.POSITIONAL_ONLY,\n        ):\n            if n < len(positional):\n                result[name] = positional[n]\n                numPositional += 1\n        elif param.kind == inspect.Parameter.KEYWORD_ONLY:\n            if name not in keyword:\n                if param.default == inspect.Parameter.empty:\n                    raise TypeError(f\"missing keyword arg {name}\")\n                else:\n                    result[name] = param.default\n        else:\n            raise TypeError(f\"'{name}' parameter is invalid kind: {param.kind}\")\n\n    if len(positional) > numPositional:\n        raise TypeError(\"Too many arguments.\")\n    for name, value in keyword.items():\n        if name in signature.parameters.keys():\n            if name in result:\n                raise TypeError(\"Already passed.\")\n            result[name] = value\n        elif kwargs is not None:\n            kwargs[name] = value\n        else:\n            raise TypeError(\"no such param\")\n    return result\n\n\ndef _mutuallyExclusiveArguments(argumentPairs):\n    \"\"\"\n    Decorator which causes its decoratee to raise a L{TypeError} if two of the\n    given arguments are passed at the same time.\n\n    @param argumentPairs: pairs of argument identifiers, each pair indicating\n        an argument that may not be passed in conjunction with another.\n    @type argumentPairs: sequence of 2-sequences of L{str}\n\n    @return: A decorator, used like so::\n\n            @_mutuallyExclusiveArguments([[\"tweedledum\", \"tweedledee\"]])\n            def function(tweedledum=1, tweedledee=2):\n                \"Don't pass tweedledum and tweedledee at the same time.\"\n\n    @rtype: 1-argument callable taking a callable and returning a callable.\n    \"\"\"\n\n    def wrapper(wrappee):\n        spec = inspect.signature(wrappee)\n        _passed = _passedSignature\n\n        @wraps(wrappee)\n        def wrapped(*args, **kwargs):\n            arguments = _passed(spec, args, kwargs)\n            for this, that in argumentPairs:\n                if this in arguments and that in arguments:\n                    raise TypeError(\n                        (\"The %r and %r arguments to %s \" \"are mutually exclusive.\")\n                        % (this, that, _fullyQualifiedName(wrappee))\n                    )\n            return wrappee(*args, **kwargs)\n\n        return wrapped\n\n    return wrapper\n\n\n_Tc = TypeVar(\"_Tc\", bound=Callable[..., Any])\n\n\ndef deprecatedKeywordParameter(\n    version: Version, name: str, replacement: Optional[str] = None\n) -> Callable[[_Tc], _Tc]:\n    \"\"\"\n    Return a decorator that marks a keyword parameter of a callable\n    as deprecated. A warning will be emitted if a caller supplies\n    a value for the parameter, whether the caller uses a keyword or\n    positional syntax.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the parameter will be marked as\n        having been deprecated.\n\n    @type name: L{str}\n    @param name: The name of the deprecated parameter.\n\n    @type replacement: L{str}\n    @param replacement: Optional text indicating what should be used in\n        place of the deprecated parameter.\n\n    @since: Twisted 21.2.0\n    \"\"\"\n\n    def wrapper(wrappee: _Tc) -> _Tc:\n        warningString = _getDeprecationWarningString(\n            f\"The {name!r} parameter to {_fullyQualifiedName(wrappee)}\",\n            version,\n            replacement=replacement,\n        )\n\n        doc = \"The {!r} parameter was deprecated in {}\".format(\n            name,\n            getVersionString(version),\n        )\n        if replacement:\n            doc = doc + \"; \" + _getReplacementString(replacement)\n        doc += \".\"\n\n        params = inspect.signature(wrappee).parameters\n        if (\n            name in params\n            and params[name].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        ):\n            parameterIndex = list(params).index(name)\n\n            def checkDeprecatedParameter(*args, **kwargs):\n                if len(args) > parameterIndex or name in kwargs:\n                    warn(warningString, DeprecationWarning, stacklevel=2)\n                return wrappee(*args, **kwargs)\n\n        else:\n\n            def checkDeprecatedParameter(*args, **kwargs):\n                if name in kwargs:\n                    warn(warningString, DeprecationWarning, stacklevel=2)\n                return wrappee(*args, **kwargs)\n\n        decorated = cast(_Tc, wraps(wrappee)(checkDeprecatedParameter))\n        _appendToDocstring(decorated, doc)\n        return decorated\n\n    return wrapper\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_failure\\test_failure.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_failure -*-\n# See also test suite twisted.test.test_pbfailure\n\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nAsynchronous-friendly error mechanism.\n\nSee L{Failure}.\n\"\"\"\n\nfrom __future__ import annotations\n\n# System Imports\nimport builtins\nimport copy\nimport inspect\nimport linecache\nimport sys\nfrom functools import partial\nfrom inspect import getmro\nfrom io import StringIO\nfrom typing import Callable, NoReturn, TypeVar\n\nfrom incremental import Version\n\nfrom twisted.python import reflect\nfrom twisted.python.deprecate import deprecatedProperty\n\n_T_Callable = TypeVar(\"_T_Callable\", bound=Callable[..., object])\n\ncount = 0\ntraceupLength = 4\n\n\nclass DefaultException(Exception):\n    pass\n\n\ndef format_frames(frames, write, detail=\"default\"):\n    \"\"\"\n    Format and write frames.\n\n    @param frames: is a list of frames as used by Failure.frames, with\n        each frame being a list of\n        (funcName, fileName, lineNumber, locals.items(), globals.items())\n    @type frames: list\n    @param write: this will be called with formatted strings.\n    @type write: callable\n    @param detail: Four detail levels are available:\n        default, brief, verbose, and verbose-vars-not-captured.\n        C{Failure.printDetailedTraceback} uses the latter when the caller asks\n        for verbose, but no vars were captured, so that an explicit warning\n        about the missing data is shown.\n    @type detail: string\n    \"\"\"\n    if detail not in (\"default\", \"brief\", \"verbose\", \"verbose-vars-not-captured\"):\n        raise ValueError(\n            \"Detail must be default, brief, verbose, or \"\n            \"verbose-vars-not-captured. (not %r)\" % (detail,)\n        )\n    w = write\n    if detail == \"brief\":\n        for method, filename, lineno, localVars, globalVars in frames:\n            w(f\"{filename}:{lineno}:{method}\\n\")\n    elif detail == \"default\":\n        for method, filename, lineno, localVars, globalVars in frames:\n            w(f'  File \"{filename}\", line {lineno}, in {method}\\n')\n            w(\"    %s\\n\" % linecache.getline(filename, lineno).strip())\n    elif detail == \"verbose-vars-not-captured\":\n        for method, filename, lineno, localVars, globalVars in frames:\n            w(\"%s:%d: %s(...)\\n\" % (filename, lineno, method))\n        w(\" [Capture of Locals and Globals disabled (use captureVars=True)]\\n\")\n    elif detail == \"verbose\":\n        for method, filename, lineno, localVars, globalVars in frames:\n            w(\"%s:%d: %s(...)\\n\" % (filename, lineno, method))\n            w(\" [ Locals ]\\n\")\n            # Note: the repr(val) was (self.pickled and val) or repr(val)))\n            for name, val in localVars:\n                w(f\"  {name} : {repr(val)}\\n\")\n            w(\" ( Globals )\\n\")\n            for name, val in globalVars:\n                w(f\"  {name} : {repr(val)}\\n\")\n\n\n# Unused, here for backwards compatibility.\nEXCEPTION_CAUGHT_HERE = \"--- <exception caught here> ---\"\n\n\nclass NoCurrentExceptionError(Exception):\n    \"\"\"\n    Raised when trying to create a Failure from the current interpreter\n    exception state and there is no current exception state.\n    \"\"\"\n\n\ndef _Traceback(tbFrames):\n    \"\"\"\n    Construct a fake traceback object using a list of frames.\n\n    It should have the same API as stdlib to allow interaction with\n    other tools.\n\n    @param tbFrames: [(methodname, filename, lineno, locals, globals), ...]\n    \"\"\"\n    assert len(tbFrames) > 0, \"Must pass some frames\"\n    # We deliberately avoid using recursion here, as the frames list may be\n    # long.\n\n    stack = None\n    # 'tbFrames' is a list of frames from the point the exception was caught,\n    # down to where it was thrown, with the oldest at the start. Add these to\n    # the linked list of _Frames, but also wrap each one with a _Traceback\n    # frame which is linked in the opposite direction (towards the newest\n    # frame).\n    stack = _Frame(tbFrames[0], stack)\n    firstTb = tb = _TracebackFrame(stack)\n    for sf in tbFrames[1:]:\n        stack = _Frame(sf, stack)\n        tb.tb_next = _TracebackFrame(stack)\n        tb = tb.tb_next\n\n    # Return the first _TracebackFrame.\n    return firstTb\n\n\n# The set of attributes for _TracebackFrame, _Frame and _Code were taken from\n# https://docs.python.org/3.11/library/inspect.html Other Pythons may have a\n# few more attributes that should be added if needed.\nclass _TracebackFrame:\n    \"\"\"\n    Fake traceback object which can be passed to functions in the standard\n    library L{traceback} module.\n    \"\"\"\n\n    def __init__(self, frame):\n        \"\"\"\n        @param frame: _Frame object\n        \"\"\"\n        self.tb_frame = frame\n        self.tb_lineno = frame.f_lineno\n        self.tb_lasti = frame.f_lasti\n        self.tb_next = None\n\n\nclass _Frame:\n    \"\"\"\n    A fake frame object, used by L{_Traceback}.\n\n    @ivar f_code: fake L{code<types.CodeType>} object\n    @ivar f_lineno: line number\n    @ivar f_globals: fake f_globals dictionary (usually empty)\n    @ivar f_locals: fake f_locals dictionary (usually empty)\n    @ivar f_back: previous stack frame (towards the caller)\n    \"\"\"\n\n    def __init__(self, frameinfo, back):\n        \"\"\"\n        @param frameinfo: (methodname, filename, lineno, locals, globals)\n        @param back: previous (older) stack frame\n        @type back: C{frame}\n        \"\"\"\n        name, filename, lineno, localz, globalz = frameinfo\n        self.f_code = _Code(name, filename)\n        self.f_lineno = lineno\n        self.f_globals = dict(globalz or {})\n        self.f_locals = dict(localz or {})\n        self.f_back = back\n        self.f_lasti = 0\n        self.f_builtins = vars(builtins).copy()\n        self.f_trace = None\n\n\nclass _Code:\n    \"\"\"\n    A fake code object, used by L{_Traceback} via L{_Frame}.\n\n    It is intended to have the same API as the stdlib code type to allow\n    interoperation with other tools based on that interface.\n    \"\"\"\n\n    def __init__(self, name, filename):\n        self.co_name = name\n        self.co_filename = filename\n        self.co_lnotab = b\"\"\n        self.co_firstlineno = 0\n        self.co_argcount = 0\n        self.co_varnames = []\n        self.co_code = b\"\"\n        self.co_cellvars = ()\n        self.co_consts = ()\n        self.co_flags = 0\n        self.co_freevars = ()\n        self.co_posonlyargcount = 0\n        self.co_kwonlyargcount = 0\n        self.co_names = ()\n        self.co_nlocals = 0\n        self.co_stacksize = 0\n\n    def co_positions(self):\n        return ((None, None, None, None),)\n\n\n_inlineCallbacksExtraneous = []\n\n\ndef _extraneous(f: _T_Callable) -> _T_Callable:\n    \"\"\"\n    Mark the given callable as extraneous to inlineCallbacks exception\n    reporting; don't show these functions.\n\n    @param f: a function that you NEVER WANT TO SEE AGAIN in ANY TRACEBACK\n        reported by Failure.\n\n    @type f: function\n\n    @return: f\n    \"\"\"\n    _inlineCallbacksExtraneous.append(f.__code__)\n    return f\n\n\nclass Failure(BaseException):\n    \"\"\"\n    A basic abstraction for an error that has occurred.\n\n    This is necessary because Python's built-in error mechanisms are\n    inconvenient for asynchronous communication.\n\n    The C{frame} attribute contain the traceback frames.  Each frame is a tuple\n    of (funcName, fileName, lineNumber, localsItems, globalsItems), where\n    localsItems and globalsItems are the contents of\n    C{locals().items()}/C{globals().items()} for that frame, or an empty tuple\n    if those details were not captured.\n\n    Local/global variables in C{frame} will only be captured if\n    C{captureVars=True} when constructing the L{Failure}.\n\n    @ivar value: The exception instance responsible for this failure.\n\n    @ivar type: The exception's class.\n\n    @ivar stack: Deprecated, always an empty list.  Equivalent information can\n        be extracted from C{import traceback;\n        traceback.extract_stack(your_failure.tb)}\n\n    @ivar frames: list of frames, innermost first.\n    \"\"\"\n\n    pickled = 0\n    _parents = None\n\n    def __init__(self, exc_value=None, exc_type=None, exc_tb=None, captureVars=False):\n        \"\"\"\n        Initialize me with an explanation of the error.\n\n        By default, this will use the current C{exception}\n        (L{sys.exc_info}()).  However, if you want to specify a\n        particular kind of failure, you can pass an exception as an\n        argument.\n\n        If no C{exc_value} is passed, then an \"original\" C{Failure} will\n        be searched for. If the current exception handler that this\n        C{Failure} is being constructed in is handling an exception\n        raised by L{raiseException}, then this C{Failure} will act like\n        the original C{Failure}.\n\n        For C{exc_tb} only L{traceback} instances or L{None} are allowed.\n        If L{None} is supplied for C{exc_value}, the value of C{exc_tb} is\n        ignored, otherwise if C{exc_tb} is L{None}, it will be found from\n        execution context (ie, L{sys.exc_info}).\n\n        @param captureVars: if set, capture locals and globals of stack\n            frames.  This is pretty slow, and makes no difference unless you\n            are going to use L{printDetailedTraceback}.\n        \"\"\"\n        global count\n        count = count + 1\n        self.count = count\n        self.type = self.value = tb = None\n        self.captureVars = captureVars\n\n        if exc_value is None:\n            self.type, self.value, tb = sys.exc_info()\n            if self.type is None:\n                raise NoCurrentExceptionError()\n        elif exc_type is None:\n            if isinstance(exc_value, Exception):\n                self.type = exc_value.__class__\n            else:\n                # Allow arbitrary objects.\n                self.type = type(exc_value)\n            self.value = exc_value\n        else:\n            self.type = exc_type\n            self.value = exc_value\n\n        if isinstance(self.value, Failure):\n            self._extrapolate(self.value)\n            return\n\n        if tb is None:\n            if exc_tb:\n                tb = exc_tb\n            elif getattr(self.value, \"__traceback__\", None):\n                # Python 3\n                tb = self.value.__traceback__\n        self.tb = tb\n\n    @property\n    def frames(self):\n        if hasattr(self, \"_frames\"):\n            return self._frames\n\n        frames = self._frames = []\n        tb = self.tb\n\n        while tb is not None:\n            f = tb.tb_frame\n            if self.captureVars:\n                localz = f.f_locals.copy()\n                if f.f_locals is f.f_globals:\n                    globalz = {}\n                else:\n                    globalz = f.f_globals.copy()\n                for d in globalz, localz:\n                    if \"__builtins__\" in d:\n                        del d[\"__builtins__\"]\n                localz = list(localz.items())\n                globalz = list(globalz.items())\n            else:\n                localz = globalz = ()\n            frames.append(\n                (\n                    f.f_code.co_name,\n                    f.f_code.co_filename,\n                    tb.tb_lineno,\n                    localz,\n                    globalz,\n                )\n            )\n            tb = tb.tb_next\n        return frames\n\n    @frames.setter\n    def frames(self, frames):\n        self._frames = frames\n\n    @deprecatedProperty(Version(\"Twisted\", 24, 10, 0))\n    def stack(self):\n        return []\n\n    @stack.setter  # type: ignore[no-redef]\n    def stack(self, stack):\n        del stack\n\n    @property\n    def parents(self):\n        if self._parents is not None:\n            return self._parents\n\n        if inspect.isclass(self.type) and issubclass(self.type, Exception):\n            parentCs = getmro(self.type)\n            self._parents = list(map(reflect.qual, parentCs))\n        else:\n            self._parents = [self.type]\n        return self._parents\n\n    @parents.setter\n    def parents(self, parents):\n        self._parents = parents\n\n    def _extrapolate(self, otherFailure):\n        \"\"\"\n        Extrapolate from one failure into another, copying its stack frames.\n\n        @param otherFailure: Another L{Failure}, whose traceback information,\n            if any, should be preserved as part of the stack presented by this\n            one.\n        @type otherFailure: L{Failure}\n        \"\"\"\n        # Copy all infos from that failure (including self._frames).\n        self.__dict__ = copy.copy(otherFailure.__dict__)\n\n    @staticmethod\n    def _withoutTraceback(value: BaseException) -> Failure:\n        \"\"\"\n        Create a L{Failure} for an exception without a traceback.\n\n        By restricting the inputs significantly, this constructor runs much\n        faster.\n        \"\"\"\n        result = Failure.__new__(Failure)\n        global count\n        count += 1\n        result.captureVars = False\n        result.count = count\n        result.value = value\n        result.type = value.__class__\n        result.tb = None\n        return result\n\n    def trap(self, *errorTypes):\n        \"\"\"\n        Trap this failure if its type is in a predetermined list.\n\n        This allows you to trap a Failure in an error callback.  It will be\n        automatically re-raised if it is not a type that you expect.\n\n        The reason for having this particular API is because it's very useful\n        in Deferred errback chains::\n\n            def _ebFoo(self, failure):\n                r = failure.trap(Spam, Eggs)\n                print('The Failure is due to either Spam or Eggs!')\n                if r == Spam:\n                    print('Spam did it!')\n                elif r == Eggs:\n                    print('Eggs did it!')\n\n        If the failure is not a Spam or an Eggs, then the Failure will be\n        'passed on' to the next errback. In Python 2 the Failure will be\n        raised; in Python 3 the underlying exception will be re-raised.\n\n        @type errorTypes: L{Exception}\n        \"\"\"\n        error = self.check(*errorTypes)\n        if not error:\n            self.raiseException()\n        return error\n\n    def check(self, *errorTypes):\n        \"\"\"\n        Check if this failure's type is in a predetermined list.\n\n        @type errorTypes: list of L{Exception} classes or\n                          fully-qualified class names.\n        @returns: the matching L{Exception} type, or None if no match.\n        \"\"\"\n        for error in errorTypes:\n            err = error\n            if inspect.isclass(error) and issubclass(error, Exception):\n                err = reflect.qual(error)\n            if err in self.parents:\n                return error\n        return None\n\n    def raiseException(self) -> NoReturn:\n        \"\"\"\n        raise the original exception, preserving traceback\n        information if available.\n        \"\"\"\n        raise self.value.with_traceback(self.tb)\n\n    @_extraneous\n    def throwExceptionIntoGenerator(self, g):\n        \"\"\"\n        Throw the original exception into the given generator,\n        preserving traceback information if available.\n\n        @return: The next value yielded from the generator.\n        @raise StopIteration: If there are no more values in the generator.\n        @raise anything else: Anything that the generator raises.\n        \"\"\"\n        return g.throw(self.value.with_traceback(self.tb))\n\n    def __repr__(self) -> str:\n        return \"<{} {}: {}>\".format(\n            reflect.qual(self.__class__),\n            reflect.qual(self.type),\n            self.getErrorMessage(),\n        )\n\n    def __str__(self) -> str:\n        return \"[Failure instance: %s]\" % self.getBriefTraceback()\n\n    def __setstate__(self, state):\n        if \"stack\" in state:\n            state.pop(\"stack\")\n        state[\"_parents\"] = state.pop(\"parents\")\n        state[\"_frames\"] = state.pop(\"frames\")\n        self.__dict__.update(state)\n\n    def __getstate__(self):\n        \"\"\"\n        Avoid pickling objects in the traceback.\n\n        This is not called direclty by pickle, since C{BaseException}\n        implements reduce; instead, pickle calls C{Failure.__reduce__} which\n        then calls this API.\n        \"\"\"\n        # Make sure _parents field is populated:\n        _ = self.parents\n\n        c = self.__dict__.copy()\n\n        # Backwards compatibility with old code, e.g. for Perspective Broker:\n        c[\"parents\"] = c.pop(\"_parents\")\n        c[\"stack\"] = []\n\n        if \"_frames\" in c:\n            c.pop(\"_frames\")\n\n        if self.captureVars:\n            c[\"frames\"] = [\n                [\n                    v[0],\n                    v[1],\n                    v[2],\n                    _safeReprVars(v[3]),\n                    _safeReprVars(v[4]),\n                ]\n                for v in self.frames\n            ]\n        else:\n            c[\"frames\"] = self.frames\n\n        # Added 2003-06-23. See comment above in __init__\n        c[\"tb\"] = None\n\n        c[\"pickled\"] = 1\n        return c\n\n    def __reduce__(self):\n        # BaseException implements a __reduce__ (in C, technically), so we need\n        # to override this to get pickling working.\n        return (partial(Failure.__new__, Failure), (), self.__getstate__())\n\n    def cleanFailure(self):\n        \"\"\"\n        Remove references to other objects, replacing them with strings.\n\n        On Python 3, this will also set the C{__traceback__} attribute of the\n        exception instance to L{None}.\n        \"\"\"\n        state = self.__getstate__()\n        state[\"_frames\"] = state.pop(\"frames\")\n        self.__dict__ = state\n        if getattr(self.value, \"__traceback__\", None):\n            # Python 3\n            self.value.__traceback__ = None\n\n    def getTracebackObject(self):\n        \"\"\"\n        Get an object that represents this Failure's stack that can be passed\n        to traceback.extract_tb.\n\n        If the original traceback object is still present, return that. If this\n        traceback object has been lost but we still have the information,\n        return a fake traceback object (see L{_Traceback}). If there is no\n        traceback information at all, return None.\n        \"\"\"\n        if self.tb is not None:\n            return self.tb\n        elif len(self.frames) > 0:\n            return _Traceback(self.frames)\n        else:\n            return None\n\n    def getErrorMessage(self) -> str:\n        \"\"\"\n        Get a string of the exception which caused this Failure.\n        \"\"\"\n        if isinstance(self.value, Failure):\n            return self.value.getErrorMessage()\n        return reflect.safe_str(self.value)\n\n    def getBriefTraceback(self) -> str:\n        io = StringIO()\n        self.printBriefTraceback(file=io)\n        return io.getvalue()\n\n    def getTraceback(self, elideFrameworkCode: int = 0, detail: str = \"default\") -> str:\n        io = StringIO()\n        self.printTraceback(\n            file=io, elideFrameworkCode=elideFrameworkCode, detail=detail\n        )\n        return io.getvalue()\n\n    def printTraceback(self, file=None, elideFrameworkCode=False, detail=\"default\"):\n        \"\"\"\n        Emulate Python's standard error reporting mechanism.\n\n        @param file: If specified, a file-like object to which to write the\n            traceback.\n\n        @param elideFrameworkCode: Deprecated, ignored.\n\n        @param detail: A string indicating how much information to include\n            in the traceback.  Must be one of C{'brief'}, C{'default'}, or\n            C{'verbose'}.\n        \"\"\"\n        if file is None:\n            from twisted.python import log\n\n            file = log.logerr\n\n        w = file.write\n\n        if detail == \"verbose\" and not self.captureVars:\n            # We don't have any locals or globals, so rather than show them as\n            # empty make the output explicitly say that we don't have them at\n            # all.\n            formatDetail = \"verbose-vars-not-captured\"\n        else:\n            formatDetail = detail\n\n        # Preamble\n        if detail == \"verbose\":\n            w(\n                \"*--- Failure #%d%s---\\n\"\n                % (self.count, (self.pickled and \" (pickled) \") or \" \")\n            )\n        elif detail == \"brief\":\n            if self.frames:\n                hasFrames = \"Traceback\"\n            else:\n                hasFrames = \"Traceback (failure with no frames)\"\n            w(\n                \"%s: %s: %s\\n\"\n                % (hasFrames, reflect.safe_str(self.type), reflect.safe_str(self.value))\n            )\n        else:\n            w(\"Traceback (most recent call last):\\n\")\n\n        # Frames, formatted in appropriate style\n        if self.frames:\n            format_frames(self.frames, w, formatDetail)\n        elif not detail == \"brief\":\n            # Yeah, it's not really a traceback, despite looking like one...\n            w(\"Failure: \")\n\n        # Postamble, if any\n        if not detail == \"brief\":\n            w(f\"{reflect.qual(self.type)}: {reflect.safe_str(self.value)}\\n\")\n\n        # Chaining\n        if isinstance(self.value, Failure):\n            # TODO: indentation for chained failures?\n            file.write(\" (chained Failure)\\n\")\n            self.value.printTraceback(file, elideFrameworkCode, detail)\n        if detail == \"verbose\":\n            w(\"*--- End of Failure #%d ---\\n\" % self.count)\n\n    def printBriefTraceback(self, file=None, elideFrameworkCode=0):\n        \"\"\"\n        Print a traceback as densely as possible.\n        \"\"\"\n        self.printTraceback(file, elideFrameworkCode, detail=\"brief\")\n\n    def printDetailedTraceback(self, file=None, elideFrameworkCode=0):\n        \"\"\"\n        Print a traceback with detailed locals and globals information.\n        \"\"\"\n        self.printTraceback(file, elideFrameworkCode, detail=\"verbose\")\n\n\ndef _safeReprVars(varsDictItems):\n    \"\"\"\n    Convert a list of (name, object) pairs into (name, repr) pairs.\n\n    L{twisted.python.reflect.safe_repr} is used to generate the repr, so no\n    exceptions will be raised by faulty C{__repr__} methods.\n\n    @param varsDictItems: a sequence of (name, value) pairs as returned by e.g.\n        C{locals().items()}.\n    @returns: a sequence of (name, repr) pairs.\n    \"\"\"\n    return [(name, reflect.safe_repr(obj)) for (name, obj) in varsDictItems]\n\n\n# slyphon: make post-morteming exceptions tweakable\n\nDO_POST_MORTEM = True\n\n\ndef _debuginit(\n    self,\n    exc_value=None,\n    exc_type=None,\n    exc_tb=None,\n    captureVars=False,\n    Failure__init__=Failure.__init__,\n):\n    \"\"\"\n    Initialize failure object, possibly spawning pdb.\n    \"\"\"\n    if (exc_value, exc_type, exc_tb) == (None, None, None):\n        exc = sys.exc_info()\n        if not exc[0] == self.__class__ and DO_POST_MORTEM:\n            try:\n                strrepr = str(exc[1])\n            except BaseException:\n                strrepr = \"broken str\"\n            print(\n                \"Jumping into debugger for post-mortem of exception '{}':\".format(\n                    strrepr\n                )\n            )\n            import pdb\n\n            pdb.post_mortem(exc[2])\n    Failure__init__(self, exc_value, exc_type, exc_tb, captureVars)\n\n\ndef startDebugMode():\n    \"\"\"\n    Enable debug hooks for Failures.\n    \"\"\"\n    Failure.__init__ = _debuginit\n\n### Source File Dependency Files Content\n### Dependency File: deprecate.py\n# -*- test-case-name: twisted.python.test.test_deprecate -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nDeprecation framework for Twisted.\n\nTo mark a method, function, or class as being deprecated do this::\n\n    from incremental import Version\n    from twisted.python.deprecate import deprecated\n\n    @deprecated(Version(\"Twisted\", 22, 10, 0))\n    def badAPI(self, first, second):\n        '''\n        Docstring for badAPI.\n        '''\n        ...\n\n    @deprecated(Version(\"Twisted\", 22, 10, 0))\n    class BadClass:\n        '''\n        Docstring for BadClass.\n        '''\n\nThe newly-decorated badAPI will issue a warning when called, and BadClass will\nissue a warning when instantiated. Both will also have  a deprecation notice\nappended to their docstring.\n\nTo deprecate properties you can use::\n\n    from incremental import Version\n    from twisted.python.deprecate import deprecatedProperty\n\n    class OtherwiseUndeprecatedClass:\n\n        @deprecatedProperty(Version(\"Twisted\", 22, 10, 0))\n        def badProperty(self):\n            '''\n            Docstring for badProperty.\n            '''\n\n        @badProperty.setter\n        def badProperty(self, value):\n            '''\n            Setter sill also raise the deprecation warning.\n            '''\n\n\nWhile it's best to avoid this as it adds performance overhead to *any* usage of\nthe module, to mark module-level attributes as being deprecated you can use::\n\n    badAttribute = \"someValue\"\n\n    ...\n\n    deprecatedModuleAttribute(\n        Version(\"Twisted\", 22, 10, 0),\n        \"Use goodAttribute instead.\",\n        \"your.full.module.name\",\n        \"badAttribute\")\n\nThe deprecated attributes will issue a warning whenever they are accessed. If\nthe attributes being deprecated are in the same module as the\nL{deprecatedModuleAttribute} call is being made from, the C{__name__} global\ncan be used as the C{moduleName} parameter.\n\n\nTo mark an optional, keyword parameter of a function or method as deprecated\nwithout deprecating the function itself, you can use::\n\n    @deprecatedKeywordParameter(Version(\"Twisted\", 22, 10, 0), \"baz\")\n    def someFunction(foo, bar=0, baz=None):\n        ...\n\nSee also L{incremental.Version}.\n\n@type DEPRECATION_WARNING_FORMAT: C{str}\n@var DEPRECATION_WARNING_FORMAT: The default deprecation warning string format\n    to use when one is not provided by the user.\n\"\"\"\nfrom __future__ import annotations\n\n__all__ = [\n    \"deprecated\",\n    \"deprecatedProperty\",\n    \"getDeprecationWarningString\",\n    \"getWarningMethod\",\n    \"setWarningMethod\",\n    \"deprecatedModuleAttribute\",\n    \"deprecatedKeywordParameter\",\n]\n\n\nimport inspect\nimport sys\nfrom dis import findlinestarts\nfrom functools import wraps\nfrom types import ModuleType\nfrom typing import Any, Callable, Dict, Optional, TypeVar, cast\nfrom warnings import warn, warn_explicit\n\nfrom incremental import Version, getVersionString\nfrom typing_extensions import ParamSpec\n\n_P = ParamSpec(\"_P\")\n_R = TypeVar(\"_R\")\n\nDEPRECATION_WARNING_FORMAT = \"%(fqpn)s was deprecated in %(version)s\"\n\n# Notionally, part of twisted.python.reflect, but defining it there causes a\n# cyclic dependency between this module and that module.  Define it here,\n# instead, and let reflect import it to re-expose to the public.\n\n\ndef _fullyQualifiedName(obj):\n    \"\"\"\n    Return the fully qualified name of a module, class, method or function.\n    Classes and functions need to be module level ones to be correctly\n    qualified.\n\n    @rtype: C{str}.\n    \"\"\"\n    try:\n        name = obj.__qualname__\n    except AttributeError:\n        name = obj.__name__\n\n    if inspect.isclass(obj) or inspect.isfunction(obj):\n        moduleName = obj.__module__\n        return f\"{moduleName}.{name}\"\n    elif inspect.ismethod(obj):\n        return f\"{obj.__module__}.{obj.__qualname__}\"\n    return name\n\n\n# Try to keep it looking like something in twisted.python.reflect.\n_fullyQualifiedName.__module__ = \"twisted.python.reflect\"\n_fullyQualifiedName.__name__ = \"fullyQualifiedName\"\n_fullyQualifiedName.__qualname__ = \"fullyQualifiedName\"\n\n\ndef _getReplacementString(replacement):\n    \"\"\"\n    Surround a replacement for a deprecated API with some polite text exhorting\n    the user to consider it as an alternative.\n\n    @type replacement: C{str} or callable\n\n    @return: a string like \"please use twisted.python.modules.getModule\n        instead\".\n    \"\"\"\n    if callable(replacement):\n        replacement = _fullyQualifiedName(replacement)\n    return f\"please use {replacement} instead\"\n\n\ndef _getDeprecationDocstring(version, replacement=None):\n    \"\"\"\n    Generate an addition to a deprecated object's docstring that explains its\n    deprecation.\n\n    @param version: the version it was deprecated.\n    @type version: L{incremental.Version}\n\n    @param replacement: The replacement, if specified.\n    @type replacement: C{str} or callable\n\n    @return: a string like \"Deprecated in Twisted 27.2.0; please use\n        twisted.timestream.tachyon.flux instead.\"\n    \"\"\"\n    doc = f\"Deprecated in {getVersionString(version)}\"\n    if replacement:\n        doc = f\"{doc}; {_getReplacementString(replacement)}\"\n    return doc + \".\"\n\n\ndef _getDeprecationWarningString(fqpn, version, format=None, replacement=None):\n    \"\"\"\n    Return a string indicating that the Python name was deprecated in the given\n    version.\n\n    @param fqpn: Fully qualified Python name of the thing being deprecated\n    @type fqpn: C{str}\n\n    @param version: Version that C{fqpn} was deprecated in.\n    @type version: L{incremental.Version}\n\n    @param format: A user-provided format to interpolate warning values into, or\n        L{DEPRECATION_WARNING_FORMAT\n        <twisted.python.deprecate.DEPRECATION_WARNING_FORMAT>} if L{None} is\n        given.\n    @type format: C{str}\n\n    @param replacement: what should be used in place of C{fqpn}. Either pass in\n        a string, which will be inserted into the warning message, or a\n        callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n\n    @return: A textual description of the deprecation\n    @rtype: C{str}\n    \"\"\"\n    if format is None:\n        format = DEPRECATION_WARNING_FORMAT\n    warningString = format % {\"fqpn\": fqpn, \"version\": getVersionString(version)}\n    if replacement:\n        warningString = \"{}; {}\".format(\n            warningString, _getReplacementString(replacement)\n        )\n    return warningString\n\n\ndef getDeprecationWarningString(callableThing, version, format=None, replacement=None):\n    \"\"\"\n    Return a string indicating that the callable was deprecated in the given\n    version.\n\n    @type callableThing: C{callable}\n    @param callableThing: Callable object to be deprecated\n\n    @type version: L{incremental.Version}\n    @param version: Version that C{callableThing} was deprecated in.\n\n    @type format: C{str}\n    @param format: A user-provided format to interpolate warning values into,\n        or L{DEPRECATION_WARNING_FORMAT\n        <twisted.python.deprecate.DEPRECATION_WARNING_FORMAT>} if L{None} is\n        given\n\n    @param replacement: what should be used in place of the callable. Either\n        pass in a string, which will be inserted into the warning message,\n        or a callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n\n    @return: A string describing the deprecation.\n    @rtype: C{str}\n    \"\"\"\n    return _getDeprecationWarningString(\n        _fullyQualifiedName(callableThing), version, format, replacement\n    )\n\n\ndef _appendToDocstring(thingWithDoc, textToAppend):\n    \"\"\"\n    Append the given text to the docstring of C{thingWithDoc}.\n\n    If C{thingWithDoc} has no docstring, then the text just replaces the\n    docstring. If it has a single-line docstring then it appends a blank line\n    and the message text. If it has a multi-line docstring, then in appends a\n    blank line a the message text, and also does the indentation correctly.\n    \"\"\"\n    if thingWithDoc.__doc__:\n        docstringLines = thingWithDoc.__doc__.splitlines()\n    else:\n        docstringLines = []\n\n    if len(docstringLines) == 0:\n        docstringLines.append(textToAppend)\n    elif len(docstringLines) == 1:\n        docstringLines.extend([\"\", textToAppend, \"\"])\n    else:\n        trailer = docstringLines[-1]\n        spaces = \"\"\n        if not trailer.strip():\n            # Deal with differences between Python 3.13 and older versions.\n            spaces = docstringLines.pop()\n        docstringLines.extend([\"\", spaces + textToAppend, spaces])\n        docstringLines = [l.lstrip(\" \") for l in docstringLines]\n    thingWithDoc.__doc__ = \"\\n\".join(docstringLines)\n\n\ndef deprecated(\n    version: Version, replacement: str | Callable[..., object] | None = None\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:\n    \"\"\"\n    Return a decorator that marks callables as deprecated. To deprecate a\n    property, see L{deprecatedProperty}.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the callable will be marked as\n        having been deprecated.  The decorated function will be annotated\n        with this version, having it set as its C{deprecatedVersion}\n        attribute.\n\n    @param replacement: what should be used in place of the callable. Either\n        pass in a string, which will be inserted into the warning message,\n        or a callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n    \"\"\"\n\n    def deprecationDecorator(function: Callable[_P, _R]) -> Callable[_P, _R]:\n        \"\"\"\n        Decorator that marks C{function} as deprecated.\n        \"\"\"\n        warningString = getDeprecationWarningString(\n            function, version, None, replacement\n        )\n\n        @wraps(function)\n        def deprecatedFunction(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            warn(warningString, DeprecationWarning, stacklevel=2)\n            return function(*args, **kwargs)\n\n        _appendToDocstring(\n            deprecatedFunction, _getDeprecationDocstring(version, replacement)\n        )\n        deprecatedFunction.deprecatedVersion = version  # type: ignore[attr-defined]\n        return deprecatedFunction\n\n    return deprecationDecorator\n\n\ndef deprecatedProperty(\n    version: Version, replacement: str | Callable[..., object] | None = None\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:\n    \"\"\"\n    Return a decorator that marks a property as deprecated. To deprecate a\n    regular callable or class, see L{deprecated}.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the callable will be marked as\n        having been deprecated.  The decorated function will be annotated\n        with this version, having it set as its C{deprecatedVersion}\n        attribute.\n\n    @param replacement: what should be used in place of the callable.\n        Either pass in a string, which will be inserted into the warning\n        message, or a callable, which will be expanded to its full import\n        path.\n    @type replacement: C{str} or callable\n\n    @return: A new property with deprecated setter and getter.\n    @rtype: C{property}\n\n    @since: 16.1.0\n    \"\"\"\n\n    class _DeprecatedProperty(property):\n        \"\"\"\n        Extension of the build-in property to allow deprecated setters.\n        \"\"\"\n\n        def _deprecatedWrapper(self, function):\n            @wraps(function)\n            def deprecatedFunction(*args, **kwargs):\n                warn(\n                    self.warningString,  # type: ignore[attr-defined]\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                return function(*args, **kwargs)\n\n            return deprecatedFunction\n\n        def setter(self, function):\n            return property.setter(self, self._deprecatedWrapper(function))\n\n    def deprecationDecorator(function):\n        warningString = getDeprecationWarningString(\n            function, version, None, replacement\n        )\n\n        @wraps(function)\n        def deprecatedFunction(*args, **kwargs):\n            warn(warningString, DeprecationWarning, stacklevel=2)\n            return function(*args, **kwargs)\n\n        _appendToDocstring(\n            deprecatedFunction, _getDeprecationDocstring(version, replacement)\n        )\n        deprecatedFunction.deprecatedVersion = version  # type: ignore[attr-defined]\n\n        result = _DeprecatedProperty(deprecatedFunction)\n        result.warningString = warningString  # type: ignore[attr-defined]\n        return result\n\n    return deprecationDecorator\n\n\ndef getWarningMethod():\n    \"\"\"\n    Return the warning method currently used to record deprecation warnings.\n    \"\"\"\n    return warn\n\n\ndef setWarningMethod(newMethod):\n    \"\"\"\n    Set the warning method to use to record deprecation warnings.\n\n    The callable should take message, category and stacklevel. The return\n    value is ignored.\n    \"\"\"\n    global warn\n    warn = newMethod\n\n\nclass _InternalState:\n    \"\"\"\n    An L{_InternalState} is a helper object for a L{_ModuleProxy}, so that it\n    can easily access its own attributes, bypassing its logic for delegating to\n    another object that it's proxying for.\n\n    @ivar proxy: a L{_ModuleProxy}\n    \"\"\"\n\n    def __init__(self, proxy):\n        object.__setattr__(self, \"proxy\", proxy)\n\n    def __getattribute__(self, name):\n        return object.__getattribute__(object.__getattribute__(self, \"proxy\"), name)\n\n    def __setattr__(self, name, value):\n        return object.__setattr__(object.__getattribute__(self, \"proxy\"), name, value)\n\n\nclass _ModuleProxy:\n    \"\"\"\n    Python module wrapper to hook module-level attribute access.\n\n    Access to deprecated attributes first checks\n    L{_ModuleProxy._deprecatedAttributes}, if the attribute does not appear\n    there then access falls through to L{_ModuleProxy._module}, the wrapped\n    module object.\n\n    @ivar _module: Module on which to hook attribute access.\n    @type _module: C{module}\n\n    @ivar _deprecatedAttributes: Mapping of attribute names to objects that\n        retrieve the module attribute's original value.\n    @type _deprecatedAttributes: C{dict} mapping C{str} to\n        L{_DeprecatedAttribute}\n\n    @ivar _lastWasPath: Heuristic guess as to whether warnings about this\n        package should be ignored for the next call.  If the last attribute\n        access of this module was a C{getattr} of C{__path__}, we will assume\n        that it was the import system doing it and we won't emit a warning for\n        the next access, even if it is to a deprecated attribute.  The CPython\n        import system always tries to access C{__path__}, then the attribute\n        itself, then the attribute itself again, in both successful and failed\n        cases.\n    @type _lastWasPath: C{bool}\n    \"\"\"\n\n    def __init__(self, module):\n        state = _InternalState(self)\n        state._module = module\n        state._deprecatedAttributes = {}\n        state._lastWasPath = False\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Get a string containing the type of the module proxy and a\n        representation of the wrapped module object.\n        \"\"\"\n        state = _InternalState(self)\n        return f\"<{type(self).__name__} module={state._module!r}>\"\n\n    def __setattr__(self, name, value):\n        \"\"\"\n        Set an attribute on the wrapped module object.\n        \"\"\"\n        state = _InternalState(self)\n        state._lastWasPath = False\n        setattr(state._module, name, value)\n\n    def __getattribute__(self, name):\n        \"\"\"\n        Get an attribute from the module object, possibly emitting a warning.\n\n        If the specified name has been deprecated, then a warning is issued.\n        (Unless certain obscure conditions are met; see\n        L{_ModuleProxy._lastWasPath} for more information about what might quash\n        such a warning.)\n        \"\"\"\n        state = _InternalState(self)\n        if state._lastWasPath:\n            deprecatedAttribute = None\n        else:\n            deprecatedAttribute = state._deprecatedAttributes.get(name)\n\n        if deprecatedAttribute is not None:\n            # If we have a _DeprecatedAttribute object from the earlier lookup,\n            # allow it to issue the warning.\n            value = deprecatedAttribute.get()\n        else:\n            # Otherwise, just retrieve the underlying value directly; it's not\n            # deprecated, there's no warning to issue.\n            value = getattr(state._module, name)\n        if name == \"__path__\":\n            state._lastWasPath = True\n        else:\n            state._lastWasPath = False\n        return value\n\n\nclass _DeprecatedAttribute:\n    \"\"\"\n    Wrapper for deprecated attributes.\n\n    This is intended to be used by L{_ModuleProxy}. Calling\n    L{_DeprecatedAttribute.get} will issue a warning and retrieve the\n    underlying attribute's value.\n\n    @type module: C{module}\n    @ivar module: The original module instance containing this attribute\n\n    @type fqpn: C{str}\n    @ivar fqpn: Fully qualified Python name for the deprecated attribute\n\n    @type version: L{incremental.Version}\n    @ivar version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @ivar message: Deprecation message\n    \"\"\"\n\n    def __init__(self, module, name, version, message):\n        \"\"\"\n        Initialise a deprecated name wrapper.\n        \"\"\"\n        self.module = module\n        self.__name__ = name\n        self.fqpn = module.__name__ + \".\" + name\n        self.version = version\n        self.message = message\n\n    def get(self):\n        \"\"\"\n        Get the underlying attribute value and issue a deprecation warning.\n        \"\"\"\n        # This might fail if the deprecated thing is a module inside a package.\n        # In that case, don't emit the warning this time.  The import system\n        # will come back again when it's not an AttributeError and we can emit\n        # the warning then.\n        result = getattr(self.module, self.__name__)\n        message = _getDeprecationWarningString(\n            self.fqpn, self.version, DEPRECATION_WARNING_FORMAT + \": \" + self.message\n        )\n        warn(message, DeprecationWarning, stacklevel=3)\n        return result\n\n\ndef _deprecateAttribute(proxy, name, version, message):\n    \"\"\"\n    Mark a module-level attribute as being deprecated.\n\n    @type proxy: L{_ModuleProxy}\n    @param proxy: The module proxy instance proxying the deprecated attributes\n\n    @type name: C{str}\n    @param name: Attribute name\n\n    @type version: L{incremental.Version}\n    @param version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @param message: Deprecation message\n    \"\"\"\n    _module = object.__getattribute__(proxy, \"_module\")\n    attr = _DeprecatedAttribute(_module, name, version, message)\n    # Add a deprecated attribute marker for this module's attribute. When this\n    # attribute is accessed via _ModuleProxy a warning is emitted.\n    _deprecatedAttributes = object.__getattribute__(proxy, \"_deprecatedAttributes\")\n    _deprecatedAttributes[name] = attr\n\n\ndef deprecatedModuleAttribute(version, message, moduleName, name):\n    \"\"\"\n    Declare a module-level attribute as being deprecated.\n\n    @type version: L{incremental.Version}\n    @param version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @param message: Deprecation message\n\n    @type moduleName: C{str}\n    @param moduleName: Fully-qualified Python name of the module containing\n        the deprecated attribute; if called from the same module as the\n        attributes are being deprecated in, using the C{__name__} global can\n        be helpful\n\n    @type name: C{str}\n    @param name: Attribute name to deprecate\n    \"\"\"\n    module = sys.modules[moduleName]\n    if not isinstance(module, _ModuleProxy):\n        module = cast(ModuleType, _ModuleProxy(module))\n        sys.modules[moduleName] = module\n\n    _deprecateAttribute(module, name, version, message)\n\n\ndef warnAboutFunction(offender, warningString):\n    \"\"\"\n    Issue a warning string, identifying C{offender} as the responsible code.\n\n    This function is used to deprecate some behavior of a function.  It differs\n    from L{warnings.warn} in that it is not limited to deprecating the behavior\n    of a function currently on the call stack.\n\n    @param offender: The function that is being deprecated.\n\n    @param warningString: The string that should be emitted by this warning.\n    @type warningString: C{str}\n\n    @since: 11.0\n    \"\"\"\n    # inspect.getmodule() is attractive, but somewhat\n    # broken in Python < 2.6.  See Python bug 4845.\n    # In Python 3.13 line numbers returned by findlinestarts\n    # can be None for bytecode that does not map to source\n    # lines.\n    offenderModule = sys.modules[offender.__module__]\n    warn_explicit(\n        warningString,\n        category=DeprecationWarning,\n        filename=inspect.getabsfile(offenderModule),\n        lineno=max(\n            lineNumber\n            for _, lineNumber in findlinestarts(offender.__code__)\n            if lineNumber is not None\n        ),\n        module=offenderModule.__name__,\n        registry=offender.__globals__.setdefault(\"__warningregistry__\", {}),\n        module_globals=None,\n    )\n\n\ndef _passedArgSpec(argspec, positional, keyword):\n    \"\"\"\n    Take an I{inspect.ArgSpec}, a tuple of positional arguments, and a dict of\n    keyword arguments, and return a mapping of arguments that were actually\n    passed to their passed values.\n\n    @param argspec: The argument specification for the function to inspect.\n    @type argspec: I{inspect.ArgSpec}\n\n    @param positional: The positional arguments that were passed.\n    @type positional: L{tuple}\n\n    @param keyword: The keyword arguments that were passed.\n    @type keyword: L{dict}\n\n    @return: A dictionary mapping argument names (those declared in C{argspec})\n        to values that were passed explicitly by the user.\n    @rtype: L{dict} mapping L{str} to L{object}\n    \"\"\"\n    result: Dict[str, object] = {}\n    unpassed = len(argspec.args) - len(positional)\n    if argspec.keywords is not None:\n        kwargs = result[argspec.keywords] = {}\n    if unpassed < 0:\n        if argspec.varargs is None:\n            raise TypeError(\"Too many arguments.\")\n        else:\n            result[argspec.varargs] = positional[len(argspec.args) :]\n    for name, value in zip(argspec.args, positional):\n        result[name] = value\n    for name, value in keyword.items():\n        if name in argspec.args:\n            if name in result:\n                raise TypeError(\"Already passed.\")\n            result[name] = value\n        elif argspec.keywords is not None:\n            kwargs[name] = value\n        else:\n            raise TypeError(\"no such param\")\n    return result\n\n\ndef _passedSignature(signature, positional, keyword):\n    \"\"\"\n    Take an L{inspect.Signature}, a tuple of positional arguments, and a dict of\n    keyword arguments, and return a mapping of arguments that were actually\n    passed to their passed values.\n\n    @param signature: The signature of the function to inspect.\n    @type signature: L{inspect.Signature}\n\n    @param positional: The positional arguments that were passed.\n    @type positional: L{tuple}\n\n    @param keyword: The keyword arguments that were passed.\n    @type keyword: L{dict}\n\n    @return: A dictionary mapping argument names (those declared in\n        C{signature}) to values that were passed explicitly by the user.\n    @rtype: L{dict} mapping L{str} to L{object}\n    \"\"\"\n    result = {}\n    kwargs = None\n    numPositional = 0\n    for n, (name, param) in enumerate(signature.parameters.items()):\n        if param.kind == inspect.Parameter.VAR_POSITIONAL:\n            # Varargs, for example: *args\n            result[name] = positional[n:]\n            numPositional = len(result[name]) + 1\n        elif param.kind == inspect.Parameter.VAR_KEYWORD:\n            # Variable keyword args, for example: **my_kwargs\n            kwargs = result[name] = {}\n        elif param.kind in (\n            inspect.Parameter.POSITIONAL_OR_KEYWORD,\n            inspect.Parameter.POSITIONAL_ONLY,\n        ):\n            if n < len(positional):\n                result[name] = positional[n]\n                numPositional += 1\n        elif param.kind == inspect.Parameter.KEYWORD_ONLY:\n            if name not in keyword:\n                if param.default == inspect.Parameter.empty:\n                    raise TypeError(f\"missing keyword arg {name}\")\n                else:\n                    result[name] = param.default\n        else:\n            raise TypeError(f\"'{name}' parameter is invalid kind: {param.kind}\")\n\n    if len(positional) > numPositional:\n        raise TypeError(\"Too many arguments.\")\n    for name, value in keyword.items():\n        if name in signature.parameters.keys():\n            if name in result:\n                raise TypeError(\"Already passed.\")\n            result[name] = value\n        elif kwargs is not None:\n            kwargs[name] = value\n        else:\n            raise TypeError(\"no such param\")\n    return result\n\n\ndef _mutuallyExclusiveArguments(argumentPairs):\n    \"\"\"\n    Decorator which causes its decoratee to raise a L{TypeError} if two of the\n    given arguments are passed at the same time.\n\n    @param argumentPairs: pairs of argument identifiers, each pair indicating\n        an argument that may not be passed in conjunction with another.\n    @type argumentPairs: sequence of 2-sequences of L{str}\n\n    @return: A decorator, used like so::\n\n            @_mutuallyExclusiveArguments([[\"tweedledum\", \"tweedledee\"]])\n            def function(tweedledum=1, tweedledee=2):\n                \"Don't pass tweedledum and tweedledee at the same time.\"\n\n    @rtype: 1-argument callable taking a callable and returning a callable.\n    \"\"\"\n\n    def wrapper(wrappee):\n        spec = inspect.signature(wrappee)\n        _passed = _passedSignature\n\n        @wraps(wrappee)\n        def wrapped(*args, **kwargs):\n            arguments = _passed(spec, args, kwargs)\n            for this, that in argumentPairs:\n                if this in arguments and that in arguments:\n                    raise TypeError(\n                        (\"The %r and %r arguments to %s \" \"are mutually exclusive.\")\n                        % (this, that, _fullyQualifiedName(wrappee))\n                    )\n            return wrappee(*args, **kwargs)\n\n        return wrapped\n\n    return wrapper\n\n\n_Tc = TypeVar(\"_Tc\", bound=Callable[..., Any])\n\n\ndef deprecatedKeywordParameter(\n    version: Version, name: str, replacement: Optional[str] = None\n) -> Callable[[_Tc], _Tc]:\n    \"\"\"\n    Return a decorator that marks a keyword parameter of a callable\n    as deprecated. A warning will be emitted if a caller supplies\n    a value for the parameter, whether the caller uses a keyword or\n    positional syntax.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the parameter will be marked as\n        having been deprecated.\n\n    @type name: L{str}\n    @param name: The name of the deprecated parameter.\n\n    @type replacement: L{str}\n    @param replacement: Optional text indicating what should be used in\n        place of the deprecated parameter.\n\n    @since: Twisted 21.2.0\n    \"\"\"\n\n    def wrapper(wrappee: _Tc) -> _Tc:\n        warningString = _getDeprecationWarningString(\n            f\"The {name!r} parameter to {_fullyQualifiedName(wrappee)}\",\n            version,\n            replacement=replacement,\n        )\n\n        doc = \"The {!r} parameter was deprecated in {}\".format(\n            name,\n            getVersionString(version),\n        )\n        if replacement:\n            doc = doc + \"; \" + _getReplacementString(replacement)\n        doc += \".\"\n\n        params = inspect.signature(wrappee).parameters\n        if (\n            name in params\n            and params[name].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        ):\n            parameterIndex = list(params).index(name)\n\n            def checkDeprecatedParameter(*args, **kwargs):\n                if len(args) > parameterIndex or name in kwargs:\n                    warn(warningString, DeprecationWarning, stacklevel=2)\n                return wrappee(*args, **kwargs)\n\n        else:\n\n            def checkDeprecatedParameter(*args, **kwargs):\n                if name in kwargs:\n                    warn(warningString, DeprecationWarning, stacklevel=2)\n                return wrappee(*args, **kwargs)\n\n        decorated = cast(_Tc, wraps(wrappee)(checkDeprecatedParameter))\n        _appendToDocstring(decorated, doc)\n        return decorated\n\n    return wrapper\n\n\n### Dependency File: reflect.py\n# -*- test-case-name: twisted.test.test_reflect -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nStandardized versions of various cool and/or strange things that you can do\nwith Python's reflection capabilities.\n\"\"\"\n\n\nimport os\nimport pickle\nimport re\nimport sys\nimport traceback\nimport types\nimport weakref\nfrom collections import deque\nfrom io import IOBase, StringIO\nfrom typing import Type, Union\n\nfrom twisted.python.compat import nativeString\nfrom twisted.python.deprecate import _fullyQualifiedName as fullyQualifiedName\n\nRegexType = type(re.compile(\"\"))\n\n\ndef prefixedMethodNames(classObj, prefix):\n    \"\"\"\n    Given a class object C{classObj}, returns a list of method names that match\n    the string C{prefix}.\n\n    @param classObj: A class object from which to collect method names.\n\n    @param prefix: A native string giving a prefix.  Each method with a name\n        which begins with this prefix will be returned.\n    @type prefix: L{str}\n\n    @return: A list of the names of matching methods of C{classObj} (and base\n        classes of C{classObj}).\n    @rtype: L{list} of L{str}\n    \"\"\"\n    dct = {}\n    addMethodNamesToDict(classObj, dct, prefix)\n    return list(dct.keys())\n\n\ndef addMethodNamesToDict(classObj, dict, prefix, baseClass=None):\n    \"\"\"\n    This goes through C{classObj} (and its bases) and puts method names\n    starting with 'prefix' in 'dict' with a value of 1. if baseClass isn't\n    None, methods will only be added if classObj is-a baseClass\n\n    If the class in question has the methods 'prefix_methodname' and\n    'prefix_methodname2', the resulting dict should look something like:\n    {\"methodname\": 1, \"methodname2\": 1}.\n\n    @param classObj: A class object from which to collect method names.\n\n    @param dict: A L{dict} which will be updated with the results of the\n        accumulation.  Items are added to this dictionary, with method names as\n        keys and C{1} as values.\n    @type dict: L{dict}\n\n    @param prefix: A native string giving a prefix.  Each method of C{classObj}\n        (and base classes of C{classObj}) with a name which begins with this\n        prefix will be returned.\n    @type prefix: L{str}\n\n    @param baseClass: A class object at which to stop searching upwards for new\n        methods.  To collect all method names, do not pass a value for this\n        parameter.\n\n    @return: L{None}\n    \"\"\"\n    for base in classObj.__bases__:\n        addMethodNamesToDict(base, dict, prefix, baseClass)\n\n    if baseClass is None or baseClass in classObj.__bases__:\n        for name, method in classObj.__dict__.items():\n            optName = name[len(prefix) :]\n            if (\n                (type(method) is types.FunctionType)\n                and (name[: len(prefix)] == prefix)\n                and (len(optName))\n            ):\n                dict[optName] = 1\n\n\ndef prefixedMethods(obj, prefix=\"\"):\n    \"\"\"\n    Given an object C{obj}, returns a list of method objects that match the\n    string C{prefix}.\n\n    @param obj: An arbitrary object from which to collect methods.\n\n    @param prefix: A native string giving a prefix.  Each method of C{obj} with\n        a name which begins with this prefix will be returned.\n    @type prefix: L{str}\n\n    @return: A list of the matching method objects.\n    @rtype: L{list}\n    \"\"\"\n    dct = {}\n    accumulateMethods(obj, dct, prefix)\n    return list(dct.values())\n\n\ndef accumulateMethods(obj, dict, prefix=\"\", curClass=None):\n    \"\"\"\n    Given an object C{obj}, add all methods that begin with C{prefix}.\n\n    @param obj: An arbitrary object to collect methods from.\n\n    @param dict: A L{dict} which will be updated with the results of the\n        accumulation.  Items are added to this dictionary, with method names as\n        keys and corresponding instance method objects as values.\n    @type dict: L{dict}\n\n    @param prefix: A native string giving a prefix.  Each method of C{obj} with\n        a name which begins with this prefix will be returned.\n    @type prefix: L{str}\n\n    @param curClass: The class in the inheritance hierarchy at which to start\n        collecting methods.  Collection proceeds up.  To collect all methods\n        from C{obj}, do not pass a value for this parameter.\n\n    @return: L{None}\n    \"\"\"\n    if not curClass:\n        curClass = obj.__class__\n    for base in curClass.__bases__:\n        # The implementation of the object class is different on PyPy vs.\n        # CPython.  This has the side effect of making accumulateMethods()\n        # pick up object methods from all new-style classes -\n        # such as __getattribute__, etc.\n        # If we ignore 'object' when accumulating methods, we can get\n        # consistent behavior on Pypy and CPython.\n        if base is not object:\n            accumulateMethods(obj, dict, prefix, base)\n\n    for name, method in curClass.__dict__.items():\n        optName = name[len(prefix) :]\n        if (\n            (type(method) is types.FunctionType)\n            and (name[: len(prefix)] == prefix)\n            and (len(optName))\n        ):\n            dict[optName] = getattr(obj, name)\n\n\ndef namedModule(name):\n    \"\"\"\n    Return a module given its name.\n    \"\"\"\n    topLevel = __import__(name)\n    packages = name.split(\".\")[1:]\n    m = topLevel\n    for p in packages:\n        m = getattr(m, p)\n    return m\n\n\ndef namedObject(name):\n    \"\"\"\n    Get a fully named module-global object.\n    \"\"\"\n    classSplit = name.split(\".\")\n    module = namedModule(\".\".join(classSplit[:-1]))\n    return getattr(module, classSplit[-1])\n\n\nnamedClass = namedObject  # backwards compat\n\n\ndef requireModule(name, default=None):\n    \"\"\"\n    Try to import a module given its name, returning C{default} value if\n    C{ImportError} is raised during import.\n\n    @param name: Module name as it would have been passed to C{import}.\n    @type name: C{str}.\n\n    @param default: Value returned in case C{ImportError} is raised while\n        importing the module.\n\n    @return: Module or default value.\n    \"\"\"\n    try:\n        return namedModule(name)\n    except ImportError:\n        return default\n\n\nclass _NoModuleFound(Exception):\n    \"\"\"\n    No module was found because none exists.\n    \"\"\"\n\n\nclass InvalidName(ValueError):\n    \"\"\"\n    The given name is not a dot-separated list of Python objects.\n    \"\"\"\n\n\nclass ModuleNotFound(InvalidName):\n    \"\"\"\n    The module associated with the given name doesn't exist and it can't be\n    imported.\n    \"\"\"\n\n\nclass ObjectNotFound(InvalidName):\n    \"\"\"\n    The object associated with the given name doesn't exist and it can't be\n    imported.\n    \"\"\"\n\n\ndef _importAndCheckStack(importName):\n    \"\"\"\n    Import the given name as a module, then walk the stack to determine whether\n    the failure was the module not existing, or some code in the module (for\n    example a dependent import) failing.  This can be helpful to determine\n    whether any actual application code was run.  For example, to distiguish\n    administrative error (entering the wrong module name), from programmer\n    error (writing buggy code in a module that fails to import).\n\n    @param importName: The name of the module to import.\n    @type importName: C{str}\n    @raise Exception: if something bad happens.  This can be any type of\n        exception, since nobody knows what loading some arbitrary code might\n        do.\n    @raise _NoModuleFound: if no module was found.\n    \"\"\"\n    try:\n        return __import__(importName)\n    except ImportError:\n        excType, excValue, excTraceback = sys.exc_info()\n        while excTraceback:\n            execName = excTraceback.tb_frame.f_globals[\"__name__\"]\n            if execName == importName:\n                raise excValue.with_traceback(excTraceback)\n            excTraceback = excTraceback.tb_next\n        raise _NoModuleFound()\n\n\ndef namedAny(name):\n    \"\"\"\n    Retrieve a Python object by its fully qualified name from the global Python\n    module namespace.  The first part of the name, that describes a module,\n    will be discovered and imported.  Each subsequent part of the name is\n    treated as the name of an attribute of the object specified by all of the\n    name which came before it.  For example, the fully-qualified name of this\n    object is 'twisted.python.reflect.namedAny'.\n\n    @type name: L{str}\n    @param name: The name of the object to return.\n\n    @raise InvalidName: If the name is an empty string, starts or ends with\n        a '.', or is otherwise syntactically incorrect.\n\n    @raise ModuleNotFound: If the name is syntactically correct but the\n        module it specifies cannot be imported because it does not appear to\n        exist.\n\n    @raise ObjectNotFound: If the name is syntactically correct, includes at\n        least one '.', but the module it specifies cannot be imported because\n        it does not appear to exist.\n\n    @raise AttributeError: If an attribute of an object along the way cannot be\n        accessed, or a module along the way is not found.\n\n    @return: the Python object identified by 'name'.\n    \"\"\"\n    if not name:\n        raise InvalidName(\"Empty module name\")\n\n    names = name.split(\".\")\n\n    # if the name starts or ends with a '.' or contains '..', the __import__\n    # will raise an 'Empty module name' error. This will provide a better error\n    # message.\n    if \"\" in names:\n        raise InvalidName(\n            \"name must be a string giving a '.'-separated list of Python \"\n            \"identifiers, not %r\" % (name,)\n        )\n\n    topLevelPackage = None\n    moduleNames = names[:]\n    while not topLevelPackage:\n        if moduleNames:\n            trialname = \".\".join(moduleNames)\n            try:\n                topLevelPackage = _importAndCheckStack(trialname)\n            except _NoModuleFound:\n                moduleNames.pop()\n        else:\n            if len(names) == 1:\n                raise ModuleNotFound(f\"No module named {name!r}\")\n            else:\n                raise ObjectNotFound(f\"{name!r} does not name an object\")\n\n    obj = topLevelPackage\n    for n in names[1:]:\n        obj = getattr(obj, n)\n\n    return obj\n\n\ndef filenameToModuleName(fn):\n    \"\"\"\n    Convert a name in the filesystem to the name of the Python module it is.\n\n    This is aggressive about getting a module name back from a file; it will\n    always return a string.  Aggressive means 'sometimes wrong'; it won't look\n    at the Python path or try to do any error checking: don't use this method\n    unless you already know that the filename you're talking about is a Python\n    module.\n\n    @param fn: A filesystem path to a module or package; C{bytes} on Python 2,\n        C{bytes} or C{unicode} on Python 3.\n\n    @return: A hopefully importable module name.\n    @rtype: C{str}\n    \"\"\"\n    if isinstance(fn, bytes):\n        initPy = b\"__init__.py\"\n    else:\n        initPy = \"__init__.py\"\n    fullName = os.path.abspath(fn)\n    base = os.path.basename(fn)\n    if not base:\n        # this happens when fn ends with a path separator, just skit it\n        base = os.path.basename(fn[:-1])\n    modName = nativeString(os.path.splitext(base)[0])\n    while 1:\n        fullName = os.path.dirname(fullName)\n        if os.path.exists(os.path.join(fullName, initPy)):\n            modName = \"{}.{}\".format(\n                nativeString(os.path.basename(fullName)),\n                nativeString(modName),\n            )\n        else:\n            break\n    return modName\n\n\ndef qual(clazz: Type[object]) -> str:\n    \"\"\"\n    Return full import path of a class.\n    \"\"\"\n    return clazz.__module__ + \".\" + clazz.__name__\n\n\ndef _determineClass(x):\n    try:\n        return x.__class__\n    except BaseException:\n        return type(x)\n\n\ndef _determineClassName(x):\n    c = _determineClass(x)\n    try:\n        return c.__name__\n    except BaseException:\n        try:\n            return str(c)\n        except BaseException:\n            return \"<BROKEN CLASS AT 0x%x>\" % id(c)\n\n\ndef _safeFormat(formatter: Union[types.FunctionType, Type[str]], o: object) -> str:\n    \"\"\"\n    Helper function for L{safe_repr} and L{safe_str}.\n\n    Called when C{repr} or C{str} fail. Returns a string containing info about\n    C{o} and the latest exception.\n\n    @param formatter: C{str} or C{repr}.\n    @type formatter: C{type}\n    @param o: Any object.\n\n    @rtype: C{str}\n    @return: A string containing information about C{o} and the raised\n        exception.\n    \"\"\"\n    io = StringIO()\n    traceback.print_exc(file=io)\n    className = _determineClassName(o)\n    tbValue = io.getvalue()\n    return \"<{} instance at 0x{:x} with {} error:\\n {}>\".format(\n        className,\n        id(o),\n        formatter.__name__,\n        tbValue,\n    )\n\n\ndef safe_repr(o):\n    \"\"\"\n    Returns a string representation of an object, or a string containing a\n    traceback, if that object's __repr__ raised an exception.\n\n    @param o: Any object.\n\n    @rtype: C{str}\n    \"\"\"\n    try:\n        return repr(o)\n    except BaseException:\n        return _safeFormat(repr, o)\n\n\ndef safe_str(o: object) -> str:\n    \"\"\"\n    Returns a string representation of an object, or a string containing a\n    traceback, if that object's __str__ raised an exception.\n\n    @param o: Any object.\n    \"\"\"\n    if isinstance(o, bytes):\n        # If o is bytes and seems to holds a utf-8 encoded string,\n        # convert it to str.\n        try:\n            return o.decode(\"utf-8\")\n        except BaseException:\n            pass\n    try:\n        return str(o)\n    except BaseException:\n        return _safeFormat(str, o)\n\n\nclass QueueMethod:\n    \"\"\"\n    I represent a method that doesn't exist yet.\n    \"\"\"\n\n    def __init__(self, name, calls):\n        self.name = name\n        self.calls = calls\n\n    def __call__(self, *args):\n        self.calls.append((self.name, args))\n\n\ndef fullFuncName(func):\n    qualName = str(pickle.whichmodule(func, func.__name__)) + \".\" + func.__name__\n    if namedObject(qualName) is not func:\n        raise Exception(f\"Couldn't find {func} as {qualName}.\")\n    return qualName\n\n\ndef getClass(obj):\n    \"\"\"\n    Return the class or type of object 'obj'.\n    \"\"\"\n    return type(obj)\n\n\ndef accumulateClassDict(classObj, attr, adict, baseClass=None):\n    \"\"\"\n    Accumulate all attributes of a given name in a class hierarchy into a single dictionary.\n\n    Assuming all class attributes of this name are dictionaries.\n    If any of the dictionaries being accumulated have the same key, the\n    one highest in the class hierarchy wins.\n    (XXX: If \\\"highest\\\" means \\\"closest to the starting class\\\".)\n\n    Ex::\n\n      class Soy:\n        properties = {\\\"taste\\\": \\\"bland\\\"}\n\n      class Plant:\n        properties = {\\\"colour\\\": \\\"green\\\"}\n\n      class Seaweed(Plant):\n        pass\n\n      class Lunch(Soy, Seaweed):\n        properties = {\\\"vegan\\\": 1 }\n\n      dct = {}\n\n      accumulateClassDict(Lunch, \\\"properties\\\", dct)\n\n      print(dct)\n\n    {\\\"taste\\\": \\\"bland\\\", \\\"colour\\\": \\\"green\\\", \\\"vegan\\\": 1}\n    \"\"\"\n    for base in classObj.__bases__:\n        accumulateClassDict(base, attr, adict)\n    if baseClass is None or baseClass in classObj.__bases__:\n        adict.update(classObj.__dict__.get(attr, {}))\n\n\ndef accumulateClassList(classObj, attr, listObj, baseClass=None):\n    \"\"\"\n    Accumulate all attributes of a given name in a class hierarchy into a single list.\n\n    Assuming all class attributes of this name are lists.\n    \"\"\"\n    for base in classObj.__bases__:\n        accumulateClassList(base, attr, listObj)\n    if baseClass is None or baseClass in classObj.__bases__:\n        listObj.extend(classObj.__dict__.get(attr, []))\n\n\ndef isSame(a, b):\n    return a is b\n\n\ndef isLike(a, b):\n    return a == b\n\n\ndef modgrep(goal):\n    return objgrep(sys.modules, goal, isLike, \"sys.modules\")\n\n\ndef isOfType(start, goal):\n    return type(start) is goal\n\n\ndef findInstances(start, t):\n    return objgrep(start, t, isOfType)\n\n\ndef objgrep(\n    start,\n    goal,\n    eq=isLike,\n    path=\"\",\n    paths=None,\n    seen=None,\n    showUnknowns=0,\n    maxDepth=None,\n):\n    \"\"\"\n    L{objgrep} finds paths between C{start} and C{goal}.\n\n    Starting at the python object C{start}, we will loop over every reachable\n    reference, tring to find the python object C{goal} (i.e. every object\n    C{candidate} for whom C{eq(candidate, goal)} is truthy), and return a\n    L{list} of L{str}, where each L{str} is Python syntax for a path between\n    C{start} and C{goal}.\n\n    Since this can be slightly difficult to visualize, here's an example::\n\n        >>> class Holder:\n        ...     def __init__(self, x):\n        ...         self.x = x\n        ...\n        >>> start = Holder({\"irrelevant\": \"ignore\",\n        ...                 \"relevant\": [7, 1, 3, 5, 7]})\n        >>> for path in objgrep(start, 7):\n        ...     print(\"start\" + path)\n        start.x['relevant'][0]\n        start.x['relevant'][4]\n\n    This can be useful, for example, when debugging stateful graphs of objects\n    attached to a socket, trying to figure out where a particular connection is\n    attached.\n\n    @param start: The object to start looking at.\n\n    @param goal: The object to search for.\n\n    @param eq: A 2-argument predicate which takes an object found by traversing\n        references starting at C{start}, as well as C{goal}, and returns a\n        boolean.\n\n    @param path: The prefix of the path to include in every return value; empty\n        by default.\n\n    @param paths: The result object to append values to; a list of strings.\n\n    @param seen: A dictionary mapping ints (object IDs) to objects already\n        seen.\n\n    @param showUnknowns: if true, print a message to C{stdout} when\n        encountering objects that C{objgrep} does not know how to traverse.\n\n    @param maxDepth: The maximum number of object references to attempt\n        traversing before giving up.  If an integer, limit to that many links,\n        if C{None}, unlimited.\n\n    @return: A list of strings representing python object paths starting at\n        C{start} and terminating at C{goal}.\n    \"\"\"\n    if paths is None:\n        paths = []\n    if seen is None:\n        seen = {}\n    if eq(start, goal):\n        paths.append(path)\n    if id(start) in seen:\n        if seen[id(start)] is start:\n            return\n    if maxDepth is not None:\n        if maxDepth == 0:\n            return\n        maxDepth -= 1\n    seen[id(start)] = start\n    # Make an alias for those arguments which are passed recursively to\n    # objgrep for container objects.\n    args = (paths, seen, showUnknowns, maxDepth)\n    if isinstance(start, dict):\n        for k, v in start.items():\n            objgrep(k, goal, eq, path + \"{\" + repr(v) + \"}\", *args)\n            objgrep(v, goal, eq, path + \"[\" + repr(k) + \"]\", *args)\n    elif isinstance(start, (list, tuple, deque)):\n        for idx, _elem in enumerate(start):\n            objgrep(start[idx], goal, eq, path + \"[\" + str(idx) + \"]\", *args)\n    elif isinstance(start, types.MethodType):\n        objgrep(start.__self__, goal, eq, path + \".__self__\", *args)\n        objgrep(start.__func__, goal, eq, path + \".__func__\", *args)\n        objgrep(start.__self__.__class__, goal, eq, path + \".__self__.__class__\", *args)\n    elif hasattr(start, \"__dict__\"):\n        for k, v in start.__dict__.items():\n            objgrep(v, goal, eq, path + \".\" + k, *args)\n    elif isinstance(start, weakref.ReferenceType):\n        objgrep(start(), goal, eq, path + \"()\", *args)\n    elif isinstance(\n        start,\n        (\n            str,\n            int,\n            types.FunctionType,\n            types.BuiltinMethodType,\n            RegexType,\n            float,\n            type(None),\n            IOBase,\n        ),\n    ) or type(start).__name__ in (\n        \"wrapper_descriptor\",\n        \"method_descriptor\",\n        \"member_descriptor\",\n        \"getset_descriptor\",\n    ):\n        pass\n    elif showUnknowns:\n        print(\"unknown type\", type(start), start)\n    return paths\n\n\n__all__ = [\n    \"InvalidName\",\n    \"ModuleNotFound\",\n    \"ObjectNotFound\",\n    \"QueueMethod\",\n    \"namedModule\",\n    \"namedObject\",\n    \"namedClass\",\n    \"namedAny\",\n    \"requireModule\",\n    \"safe_repr\",\n    \"safe_str\",\n    \"prefixedMethodNames\",\n    \"addMethodNamesToDict\",\n    \"prefixedMethods\",\n    \"accumulateMethods\",\n    \"fullFuncName\",\n    \"qual\",\n    \"getClass\",\n    \"accumulateClassDict\",\n    \"accumulateClassList\",\n    \"isSame\",\n    \"isLike\",\n    \"modgrep\",\n    \"isOfType\",\n    \"findInstances\",\n    \"objgrep\",\n    \"filenameToModuleName\",\n    \"fullyQualifiedName\",\n]\n\n\n# This is to be removed when fixing #6986\n__all__.remove(\"objgrep\")\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_finger\\test_finger.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"The Finger User Information Protocol (RFC 1288)\"\"\"\n\nfrom twisted.protocols import basic\n\n\nclass Finger(basic.LineReceiver):\n    def lineReceived(self, line):\n        parts = line.split()\n        if not parts:\n            parts = [b\"\"]\n        if len(parts) == 1:\n            slash_w = 0\n        else:\n            slash_w = 1\n        user = parts[-1]\n        if b\"@\" in user:\n            hostPlace = user.rfind(b\"@\")\n            user = user[:hostPlace]\n            host = user[hostPlace + 1 :]\n            return self.forwardQuery(slash_w, user, host)\n        if user:\n            return self.getUser(slash_w, user)\n        else:\n            return self.getDomain(slash_w)\n\n    def _refuseMessage(self, message):\n        self.transport.write(message + b\"\\n\")\n        self.transport.loseConnection()\n\n    def forwardQuery(self, slash_w, user, host):\n        self._refuseMessage(b\"Finger forwarding service denied\")\n\n    def getDomain(self, slash_w):\n        self._refuseMessage(b\"Finger online list denied\")\n\n    def getUser(self, slash_w, user):\n        self.transport.write(b\"Login: \" + user + b\"\\n\")\n        self._refuseMessage(b\"No such user\")\n\n### Source File Dependency Files Content\n### Dependency File: basic.py\n# -*- test-case-name: twisted.protocols.test.test_basic -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nBasic protocols, such as line-oriented, netstring, and int prefixed strings.\n\"\"\"\n\n\nimport math\n\n# System imports\nimport re\nfrom io import BytesIO\nfrom struct import calcsize, pack, unpack\n\nfrom zope.interface import implementer\n\n# Twisted imports\nfrom twisted.internet import defer, interfaces, protocol\nfrom twisted.python import log\n\n\n# Unfortunately we cannot use regular string formatting on Python 3; see\n# http://bugs.python.org/issue3982 for details.\ndef _formatNetstring(data):\n    return b\"\".join([str(len(data)).encode(\"ascii\"), b\":\", data, b\",\"])\n\n\n_formatNetstring.__doc__ = \"\"\"\nConvert some C{bytes} into netstring format.\n\n@param data: C{bytes} that will be reformatted.\n\"\"\"\n\n\nDEBUG = 0\n\n\nclass NetstringParseError(ValueError):\n    \"\"\"\n    The incoming data is not in valid Netstring format.\n    \"\"\"\n\n\nclass IncompleteNetstring(Exception):\n    \"\"\"\n    Not enough data to complete a netstring.\n    \"\"\"\n\n\nclass NetstringReceiver(protocol.Protocol):\n    \"\"\"\n    A protocol that sends and receives netstrings.\n\n    See U{http://cr.yp.to/proto/netstrings.txt} for the specification of\n    netstrings. Every netstring starts with digits that specify the length\n    of the data. This length specification is separated from the data by\n    a colon. The data is terminated with a comma.\n\n    Override L{stringReceived} to handle received netstrings. This\n    method is called with the netstring payload as a single argument\n    whenever a complete netstring is received.\n\n    Security features:\n        1. Messages are limited in size, useful if you don't want\n           someone sending you a 500MB netstring (change C{self.MAX_LENGTH}\n           to the maximum length you wish to accept).\n        2. The connection is lost if an illegal message is received.\n\n    @ivar MAX_LENGTH: Defines the maximum length of netstrings that can be\n        received.\n    @type MAX_LENGTH: C{int}\n\n    @ivar _LENGTH: A pattern describing all strings that contain a netstring\n        length specification. Examples for length specifications are C{b'0:'},\n        C{b'12:'}, and C{b'179:'}. C{b'007:'} is not a valid length\n        specification, since leading zeros are not allowed.\n    @type _LENGTH: C{re.Match}\n\n    @ivar _LENGTH_PREFIX: A pattern describing all strings that contain\n        the first part of a netstring length specification (without the\n        trailing comma). Examples are '0', '12', and '179'. '007' does not\n        start a netstring length specification, since leading zeros are\n        not allowed.\n    @type _LENGTH_PREFIX: C{re.Match}\n\n    @ivar _PARSING_LENGTH: Indicates that the C{NetstringReceiver} is in\n        the state of parsing the length portion of a netstring.\n    @type _PARSING_LENGTH: C{int}\n\n    @ivar _PARSING_PAYLOAD: Indicates that the C{NetstringReceiver} is in\n        the state of parsing the payload portion (data and trailing comma)\n        of a netstring.\n    @type _PARSING_PAYLOAD: C{int}\n\n    @ivar brokenPeer: Indicates if the connection is still functional\n    @type brokenPeer: C{int}\n\n    @ivar _state: Indicates if the protocol is consuming the length portion\n        (C{PARSING_LENGTH}) or the payload (C{PARSING_PAYLOAD}) of a netstring\n    @type _state: C{int}\n\n    @ivar _remainingData: Holds the chunk of data that has not yet been consumed\n    @type _remainingData: C{string}\n\n    @ivar _payload: Holds the payload portion of a netstring including the\n        trailing comma\n    @type _payload: C{BytesIO}\n\n    @ivar _expectedPayloadSize: Holds the payload size plus one for the trailing\n        comma.\n    @type _expectedPayloadSize: C{int}\n    \"\"\"\n\n    MAX_LENGTH = 99999\n    _LENGTH = re.compile(rb\"(0|[1-9]\\d*)(:)\")\n\n    _LENGTH_PREFIX = re.compile(rb\"(0|[1-9]\\d*)$\")\n\n    # Some error information for NetstringParseError instances.\n    _MISSING_LENGTH = (\n        \"The received netstring does not start with a \" \"length specification.\"\n    )\n    _OVERFLOW = (\n        \"The length specification of the received netstring \"\n        \"cannot be represented in Python - it causes an \"\n        \"OverflowError!\"\n    )\n    _TOO_LONG = (\n        \"The received netstring is longer than the maximum %s \"\n        \"specified by self.MAX_LENGTH\"\n    )\n    _MISSING_COMMA = \"The received netstring is not terminated by a comma.\"\n\n    # The following constants are used for determining if the NetstringReceiver\n    # is parsing the length portion of a netstring, or the payload.\n    _PARSING_LENGTH, _PARSING_PAYLOAD = range(2)\n\n    def makeConnection(self, transport):\n        \"\"\"\n        Initializes the protocol.\n        \"\"\"\n        protocol.Protocol.makeConnection(self, transport)\n        self._remainingData = b\"\"\n        self._currentPayloadSize = 0\n        self._payload = BytesIO()\n        self._state = self._PARSING_LENGTH\n        self._expectedPayloadSize = 0\n        self.brokenPeer = 0\n\n    def sendString(self, string):\n        \"\"\"\n        Sends a netstring.\n\n        Wraps up C{string} by adding length information and a\n        trailing comma; writes the result to the transport.\n\n        @param string: The string to send.  The necessary framing (length\n            prefix, etc) will be added.\n        @type string: C{bytes}\n        \"\"\"\n        self.transport.write(_formatNetstring(string))\n\n    def dataReceived(self, data):\n        \"\"\"\n        Receives some characters of a netstring.\n\n        Whenever a complete netstring is received, this method extracts\n        its payload and calls L{stringReceived} to process it.\n\n        @param data: A chunk of data representing a (possibly partial)\n            netstring\n        @type data: C{bytes}\n        \"\"\"\n        self._remainingData += data\n        while self._remainingData:\n            try:\n                self._consumeData()\n            except IncompleteNetstring:\n                break\n            except NetstringParseError:\n                self._handleParseError()\n                break\n\n    def stringReceived(self, string):\n        \"\"\"\n        Override this for notification when each complete string is received.\n\n        @param string: The complete string which was received with all\n            framing (length prefix, etc) removed.\n        @type string: C{bytes}\n\n        @raise NotImplementedError: because the method has to be implemented\n            by the child class.\n        \"\"\"\n        raise NotImplementedError()\n\n    def _maxLengthSize(self):\n        \"\"\"\n        Calculate and return the string size of C{self.MAX_LENGTH}.\n\n        @return: The size of the string representation for C{self.MAX_LENGTH}\n        @rtype: C{float}\n        \"\"\"\n        return math.ceil(math.log10(self.MAX_LENGTH)) + 1\n\n    def _consumeData(self):\n        \"\"\"\n        Consumes the content of C{self._remainingData}.\n\n        @raise IncompleteNetstring: if C{self._remainingData} does not\n            contain enough data to complete the current netstring.\n        @raise NetstringParseError: if the received data do not\n            form a valid netstring.\n        \"\"\"\n        if self._state == self._PARSING_LENGTH:\n            self._consumeLength()\n            self._prepareForPayloadConsumption()\n        if self._state == self._PARSING_PAYLOAD:\n            self._consumePayload()\n\n    def _consumeLength(self):\n        \"\"\"\n        Consumes the length portion of C{self._remainingData}.\n\n        @raise IncompleteNetstring: if C{self._remainingData} contains\n            a partial length specification (digits without trailing\n            comma).\n        @raise NetstringParseError: if the received data do not form a valid\n            netstring.\n        \"\"\"\n        lengthMatch = self._LENGTH.match(self._remainingData)\n        if not lengthMatch:\n            self._checkPartialLengthSpecification()\n            raise IncompleteNetstring()\n        self._processLength(lengthMatch)\n\n    def _checkPartialLengthSpecification(self):\n        \"\"\"\n        Makes sure that the received data represents a valid number.\n\n        Checks if C{self._remainingData} represents a number smaller or\n        equal to C{self.MAX_LENGTH}.\n\n        @raise NetstringParseError: if C{self._remainingData} is no\n            number or is too big (checked by L{_extractLength}).\n        \"\"\"\n        partialLengthMatch = self._LENGTH_PREFIX.match(self._remainingData)\n        if not partialLengthMatch:\n            raise NetstringParseError(self._MISSING_LENGTH)\n        lengthSpecification = partialLengthMatch.group(1)\n        self._extractLength(lengthSpecification)\n\n    def _processLength(self, lengthMatch):\n        \"\"\"\n        Processes the length definition of a netstring.\n\n        Extracts and stores in C{self._expectedPayloadSize} the number\n        representing the netstring size.  Removes the prefix\n        representing the length specification from\n        C{self._remainingData}.\n\n        @raise NetstringParseError: if the received netstring does not\n            start with a number or the number is bigger than\n            C{self.MAX_LENGTH}.\n        @param lengthMatch: A regular expression match object matching\n            a netstring length specification\n        @type lengthMatch: C{re.Match}\n        \"\"\"\n        endOfNumber = lengthMatch.end(1)\n        startOfData = lengthMatch.end(2)\n        lengthString = self._remainingData[:endOfNumber]\n        # Expect payload plus trailing comma:\n        self._expectedPayloadSize = self._extractLength(lengthString) + 1\n        self._remainingData = self._remainingData[startOfData:]\n\n    def _extractLength(self, lengthAsString):\n        \"\"\"\n        Attempts to extract the length information of a netstring.\n\n        @raise NetstringParseError: if the number is bigger than\n            C{self.MAX_LENGTH}.\n        @param lengthAsString: A chunk of data starting with a length\n            specification\n        @type lengthAsString: C{bytes}\n        @return: The length of the netstring\n        @rtype: C{int}\n        \"\"\"\n        self._checkStringSize(lengthAsString)\n        length = int(lengthAsString)\n        if length > self.MAX_LENGTH:\n            raise NetstringParseError(self._TOO_LONG % (self.MAX_LENGTH,))\n        return length\n\n    def _checkStringSize(self, lengthAsString):\n        \"\"\"\n        Checks the sanity of lengthAsString.\n\n        Checks if the size of the length specification exceeds the\n        size of the string representing self.MAX_LENGTH. If this is\n        not the case, the number represented by lengthAsString is\n        certainly bigger than self.MAX_LENGTH, and a\n        NetstringParseError can be raised.\n\n        This method should make sure that netstrings with extremely\n        long length specifications are refused before even attempting\n        to convert them to an integer (which might trigger a\n        MemoryError).\n        \"\"\"\n        if len(lengthAsString) > self._maxLengthSize():\n            raise NetstringParseError(self._TOO_LONG % (self.MAX_LENGTH,))\n\n    def _prepareForPayloadConsumption(self):\n        \"\"\"\n        Sets up variables necessary for consuming the payload of a netstring.\n        \"\"\"\n        self._state = self._PARSING_PAYLOAD\n        self._currentPayloadSize = 0\n        self._payload.seek(0)\n        self._payload.truncate()\n\n    def _consumePayload(self):\n        \"\"\"\n        Consumes the payload portion of C{self._remainingData}.\n\n        If the payload is complete, checks for the trailing comma and\n        processes the payload. If not, raises an L{IncompleteNetstring}\n        exception.\n\n        @raise IncompleteNetstring: if the payload received so far\n            contains fewer characters than expected.\n        @raise NetstringParseError: if the payload does not end with a\n        comma.\n        \"\"\"\n        self._extractPayload()\n        if self._currentPayloadSize < self._expectedPayloadSize:\n            raise IncompleteNetstring()\n        self._checkForTrailingComma()\n        self._state = self._PARSING_LENGTH\n        self._processPayload()\n\n    def _extractPayload(self):\n        \"\"\"\n        Extracts payload information from C{self._remainingData}.\n\n        Splits C{self._remainingData} at the end of the netstring.  The\n        first part becomes C{self._payload}, the second part is stored\n        in C{self._remainingData}.\n\n        If the netstring is not yet complete, the whole content of\n        C{self._remainingData} is moved to C{self._payload}.\n        \"\"\"\n        if self._payloadComplete():\n            remainingPayloadSize = self._expectedPayloadSize - self._currentPayloadSize\n            self._payload.write(self._remainingData[:remainingPayloadSize])\n            self._remainingData = self._remainingData[remainingPayloadSize:]\n            self._currentPayloadSize = self._expectedPayloadSize\n        else:\n            self._payload.write(self._remainingData)\n            self._currentPayloadSize += len(self._remainingData)\n            self._remainingData = b\"\"\n\n    def _payloadComplete(self):\n        \"\"\"\n        Checks if enough data have been received to complete the netstring.\n\n        @return: C{True} iff the received data contain at least as many\n            characters as specified in the length section of the\n            netstring\n        @rtype: C{bool}\n        \"\"\"\n        return (\n            len(self._remainingData) + self._currentPayloadSize\n            >= self._expectedPayloadSize\n        )\n\n    def _processPayload(self):\n        \"\"\"\n        Processes the actual payload with L{stringReceived}.\n\n        Strips C{self._payload} of the trailing comma and calls\n        L{stringReceived} with the result.\n        \"\"\"\n        self.stringReceived(self._payload.getvalue()[:-1])\n\n    def _checkForTrailingComma(self):\n        \"\"\"\n        Checks if the netstring has a trailing comma at the expected position.\n\n        @raise NetstringParseError: if the last payload character is\n            anything but a comma.\n        \"\"\"\n        if self._payload.getvalue()[-1:] != b\",\":\n            raise NetstringParseError(self._MISSING_COMMA)\n\n    def _handleParseError(self):\n        \"\"\"\n        Terminates the connection and sets the flag C{self.brokenPeer}.\n        \"\"\"\n        self.transport.loseConnection()\n        self.brokenPeer = 1\n\n\nclass LineOnlyReceiver(protocol.Protocol):\n    \"\"\"\n    A protocol that receives only lines.\n\n    This is purely a speed optimisation over LineReceiver, for the\n    cases that raw mode is known to be unnecessary.\n\n    @cvar delimiter: The line-ending delimiter to use. By default this is\n                     C{b'\\\\r\\\\n'}.\n    @cvar MAX_LENGTH: The maximum length of a line to allow (If a\n                      sent line is longer than this, the connection is dropped).\n                      Default is 16384.\n    \"\"\"\n\n    _buffer = b\"\"\n    delimiter = b\"\\r\\n\"\n    MAX_LENGTH = 16384\n\n    def dataReceived(self, data):\n        \"\"\"\n        Translates bytes into lines, and calls lineReceived.\n        \"\"\"\n        lines = (self._buffer + data).split(self.delimiter)\n        self._buffer = lines.pop(-1)\n        for line in lines:\n            if self.transport.disconnecting:\n                # this is necessary because the transport may be told to lose\n                # the connection by a line within a larger packet, and it is\n                # important to disregard all the lines in that packet following\n                # the one that told it to close.\n                return\n            if len(line) > self.MAX_LENGTH:\n                return self.lineLengthExceeded(line)\n            else:\n                self.lineReceived(line)\n        if len(self._buffer) > self.MAX_LENGTH:\n            return self.lineLengthExceeded(self._buffer)\n\n    def lineReceived(self, line):\n        \"\"\"\n        Override this for when each line is received.\n\n        @param line: The line which was received with the delimiter removed.\n        @type line: C{bytes}\n        \"\"\"\n        raise NotImplementedError\n\n    def sendLine(self, line):\n        \"\"\"\n        Sends a line to the other end of the connection.\n\n        @param line: The line to send, not including the delimiter.\n        @type line: C{bytes}\n        \"\"\"\n        return self.transport.writeSequence((line, self.delimiter))\n\n    def lineLengthExceeded(self, line):\n        \"\"\"\n        Called when the maximum line length has been reached.\n        Override if it needs to be dealt with in some special way.\n        \"\"\"\n        return self.transport.loseConnection()\n\n\nclass _PauseableMixin:\n    paused = False\n\n    def pauseProducing(self):\n        self.paused = True\n        self.transport.pauseProducing()\n\n    def resumeProducing(self):\n        self.paused = False\n        self.transport.resumeProducing()\n        self.dataReceived(b\"\")\n\n    def stopProducing(self):\n        self.paused = True\n        self.transport.stopProducing()\n\n\nclass LineReceiver(protocol.Protocol, _PauseableMixin):\n    \"\"\"\n    A protocol that receives lines and/or raw data, depending on mode.\n\n    In line mode, each line that's received becomes a callback to\n    L{lineReceived}.  In raw data mode, each chunk of raw data becomes a\n    callback to L{LineReceiver.rawDataReceived}.\n    The L{setLineMode} and L{setRawMode} methods switch between the two modes.\n\n    This is useful for line-oriented protocols such as IRC, HTTP, POP, etc.\n\n    @cvar delimiter: The line-ending delimiter to use. By default this is\n                     C{b'\\\\r\\\\n'}.\n    @cvar MAX_LENGTH: The maximum length of a line to allow (If a\n                      sent line is longer than this, the connection is dropped).\n                      Default is 16384.\n    \"\"\"\n\n    line_mode = 1\n    _buffer = b\"\"\n    _busyReceiving = False\n    delimiter = b\"\\r\\n\"\n    MAX_LENGTH = 16384\n\n    def clearLineBuffer(self):\n        \"\"\"\n        Clear buffered data.\n\n        @return: All of the cleared buffered data.\n        @rtype: C{bytes}\n        \"\"\"\n        b, self._buffer = self._buffer, b\"\"\n        return b\n\n    def dataReceived(self, data):\n        \"\"\"\n        Protocol.dataReceived.\n        Translates bytes into lines, and calls lineReceived (or\n        rawDataReceived, depending on mode.)\n        \"\"\"\n        if self._busyReceiving:\n            self._buffer += data\n            return\n\n        try:\n            self._busyReceiving = True\n            self._buffer += data\n            while self._buffer and not self.paused:\n                if self.line_mode:\n                    try:\n                        line, self._buffer = self._buffer.split(self.delimiter, 1)\n                    except ValueError:\n                        if len(self._buffer) >= (self.MAX_LENGTH + len(self.delimiter)):\n                            line, self._buffer = self._buffer, b\"\"\n                            return self.lineLengthExceeded(line)\n                        return\n                    else:\n                        lineLength = len(line)\n                        if lineLength > self.MAX_LENGTH:\n                            exceeded = line + self.delimiter + self._buffer\n                            self._buffer = b\"\"\n                            return self.lineLengthExceeded(exceeded)\n                        why = self.lineReceived(line)\n                        if why or self.transport and self.transport.disconnecting:\n                            return why\n                else:\n                    data = self._buffer\n                    self._buffer = b\"\"\n                    why = self.rawDataReceived(data)\n                    if why:\n                        return why\n        finally:\n            self._busyReceiving = False\n\n    def setLineMode(self, extra=b\"\"):\n        \"\"\"\n        Sets the line-mode of this receiver.\n\n        If you are calling this from a rawDataReceived callback,\n        you can pass in extra unhandled data, and that data will\n        be parsed for lines.  Further data received will be sent\n        to lineReceived rather than rawDataReceived.\n\n        Do not pass extra data if calling this function from\n        within a lineReceived callback.\n        \"\"\"\n        self.line_mode = 1\n        if extra:\n            return self.dataReceived(extra)\n\n    def setRawMode(self):\n        \"\"\"\n        Sets the raw mode of this receiver.\n        Further data received will be sent to rawDataReceived rather\n        than lineReceived.\n        \"\"\"\n        self.line_mode = 0\n\n    def rawDataReceived(self, data):\n        \"\"\"\n        Override this for when raw data is received.\n        \"\"\"\n        raise NotImplementedError\n\n    def lineReceived(self, line):\n        \"\"\"\n        Override this for when each line is received.\n\n        @param line: The line which was received with the delimiter removed.\n        @type line: C{bytes}\n        \"\"\"\n        raise NotImplementedError\n\n    def sendLine(self, line):\n        \"\"\"\n        Sends a line to the other end of the connection.\n\n        @param line: The line to send, not including the delimiter.\n        @type line: C{bytes}\n        \"\"\"\n        return self.transport.write(line + self.delimiter)\n\n    def lineLengthExceeded(self, line):\n        \"\"\"\n        Called when the maximum line length has been reached.\n        Override if it needs to be dealt with in some special way.\n\n        The argument 'line' contains the remainder of the buffer, starting\n        with (at least some part) of the line which is too long. This may\n        be more than one line, or may be only the initial portion of the\n        line.\n        \"\"\"\n        return self.transport.loseConnection()\n\n\nclass StringTooLongError(AssertionError):\n    \"\"\"\n    Raised when trying to send a string too long for a length prefixed\n    protocol.\n    \"\"\"\n\n\nclass _RecvdCompatHack:\n    \"\"\"\n    Emulates the to-be-deprecated C{IntNStringReceiver.recvd} attribute.\n\n    The C{recvd} attribute was where the working buffer for buffering and\n    parsing netstrings was kept.  It was updated each time new data arrived and\n    each time some of that data was parsed and delivered to application code.\n    The piecemeal updates to its string value were expensive and have been\n    removed from C{IntNStringReceiver} in the normal case.  However, for\n    applications directly reading this attribute, this descriptor restores that\n    behavior.  It only copies the working buffer when necessary (ie, when\n    accessed).  This avoids the cost for applications not using the data.\n\n    This is a custom descriptor rather than a property, because we still need\n    the default __set__ behavior in both new-style and old-style subclasses.\n    \"\"\"\n\n    def __get__(self, oself, type=None):\n        return oself._unprocessed[oself._compatibilityOffset :]\n\n\nclass IntNStringReceiver(protocol.Protocol, _PauseableMixin):\n    \"\"\"\n    Generic class for length prefixed protocols.\n\n    @ivar _unprocessed: bytes received, but not yet broken up into messages /\n        sent to stringReceived.  _compatibilityOffset must be updated when this\n        value is updated so that the C{recvd} attribute can be generated\n        correctly.\n    @type _unprocessed: C{bytes}\n\n    @ivar structFormat: format used for struct packing/unpacking. Define it in\n        subclass.\n    @type structFormat: C{str}\n\n    @ivar prefixLength: length of the prefix, in bytes. Define it in subclass,\n        using C{struct.calcsize(structFormat)}\n    @type prefixLength: C{int}\n\n    @ivar _compatibilityOffset: the offset within C{_unprocessed} to the next\n        message to be parsed. (used to generate the recvd attribute)\n    @type _compatibilityOffset: C{int}\n    \"\"\"\n\n    MAX_LENGTH = 99999\n    _unprocessed = b\"\"\n    _compatibilityOffset = 0\n\n    # Backwards compatibility support for applications which directly touch the\n    # \"internal\" parse buffer.\n    recvd = _RecvdCompatHack()\n\n    def stringReceived(self, string):\n        \"\"\"\n        Override this for notification when each complete string is received.\n\n        @param string: The complete string which was received with all\n            framing (length prefix, etc) removed.\n        @type string: C{bytes}\n        \"\"\"\n        raise NotImplementedError\n\n    def lengthLimitExceeded(self, length):\n        \"\"\"\n        Callback invoked when a length prefix greater than C{MAX_LENGTH} is\n        received.  The default implementation disconnects the transport.\n        Override this.\n\n        @param length: The length prefix which was received.\n        @type length: C{int}\n        \"\"\"\n        self.transport.loseConnection()\n\n    def dataReceived(self, data):\n        \"\"\"\n        Convert int prefixed strings into calls to stringReceived.\n        \"\"\"\n        # Try to minimize string copying (via slices) by keeping one buffer\n        # containing all the data we have so far and a separate offset into that\n        # buffer.\n        alldata = self._unprocessed + data\n        currentOffset = 0\n        prefixLength = self.prefixLength\n        fmt = self.structFormat\n        self._unprocessed = alldata\n\n        while len(alldata) >= (currentOffset + prefixLength) and not self.paused:\n            messageStart = currentOffset + prefixLength\n            (length,) = unpack(fmt, alldata[currentOffset:messageStart])\n            if length > self.MAX_LENGTH:\n                self._unprocessed = alldata\n                self._compatibilityOffset = currentOffset\n                self.lengthLimitExceeded(length)\n                return\n            messageEnd = messageStart + length\n            if len(alldata) < messageEnd:\n                break\n\n            # Here we have to slice the working buffer so we can send just the\n            # netstring into the stringReceived callback.\n            packet = alldata[messageStart:messageEnd]\n            currentOffset = messageEnd\n            self._compatibilityOffset = currentOffset\n            self.stringReceived(packet)\n\n            # Check to see if the backwards compat \"recvd\" attribute got written\n            # to by application code.  If so, drop the current data buffer and\n            # switch to the new buffer given by that attribute's value.\n            if \"recvd\" in self.__dict__:\n                alldata = self.__dict__.pop(\"recvd\")\n                self._unprocessed = alldata\n                self._compatibilityOffset = currentOffset = 0\n                if alldata:\n                    continue\n                return\n\n        # Slice off all the data that has been processed, avoiding holding onto\n        # memory to store it, and update the compatibility attributes to reflect\n        # that change.\n        self._unprocessed = alldata[currentOffset:]\n        self._compatibilityOffset = 0\n\n    def sendString(self, string):\n        \"\"\"\n        Send a prefixed string to the other end of the connection.\n\n        @param string: The string to send.  The necessary framing (length\n            prefix, etc) will be added.\n        @type string: C{bytes}\n        \"\"\"\n        if len(string) >= 2 ** (8 * self.prefixLength):\n            raise StringTooLongError(\n                \"Try to send %s bytes whereas maximum is %s\"\n                % (len(string), 2 ** (8 * self.prefixLength))\n            )\n        self.transport.write(pack(self.structFormat, len(string)) + string)\n\n\nclass Int32StringReceiver(IntNStringReceiver):\n    \"\"\"\n    A receiver for int32-prefixed strings.\n\n    An int32 string is a string prefixed by 4 bytes, the 32-bit length of\n    the string encoded in network byte order.\n\n    This class publishes the same interface as NetstringReceiver.\n    \"\"\"\n\n    structFormat = \"!I\"\n    prefixLength = calcsize(structFormat)\n\n\nclass Int16StringReceiver(IntNStringReceiver):\n    \"\"\"\n    A receiver for int16-prefixed strings.\n\n    An int16 string is a string prefixed by 2 bytes, the 16-bit length of\n    the string encoded in network byte order.\n\n    This class publishes the same interface as NetstringReceiver.\n    \"\"\"\n\n    structFormat = \"!H\"\n    prefixLength = calcsize(structFormat)\n\n\nclass Int8StringReceiver(IntNStringReceiver):\n    \"\"\"\n    A receiver for int8-prefixed strings.\n\n    An int8 string is a string prefixed by 1 byte, the 8-bit length of\n    the string.\n\n    This class publishes the same interface as NetstringReceiver.\n    \"\"\"\n\n    structFormat = \"!B\"\n    prefixLength = calcsize(structFormat)\n\n\nclass StatefulStringProtocol:\n    \"\"\"\n    A stateful string protocol.\n\n    This is a mixin for string protocols (L{Int32StringReceiver},\n    L{NetstringReceiver}) which translates L{stringReceived} into a callback\n    (prefixed with C{'proto_'}) depending on state.\n\n    The state C{'done'} is special; if a C{proto_*} method returns it, the\n    connection will be closed immediately.\n\n    @ivar state: Current state of the protocol. Defaults to C{'init'}.\n    @type state: C{str}\n    \"\"\"\n\n    state = \"init\"\n\n    def stringReceived(self, string):\n        \"\"\"\n        Choose a protocol phase function and call it.\n\n        Call back to the appropriate protocol phase; this begins with\n        the function C{proto_init} and moves on to C{proto_*} depending on\n        what each C{proto_*} function returns.  (For example, if\n        C{self.proto_init} returns 'foo', then C{self.proto_foo} will be the\n        next function called when a protocol message is received.\n        \"\"\"\n        try:\n            pto = \"proto_\" + self.state\n            statehandler = getattr(self, pto)\n        except AttributeError:\n            log.msg(\"callback\", self.state, \"not found\")\n        else:\n            self.state = statehandler(string)\n            if self.state == \"done\":\n                self.transport.loseConnection()\n\n\n@implementer(interfaces.IProducer)\nclass FileSender:\n    \"\"\"\n    A producer that sends the contents of a file to a consumer.\n\n    This is a helper for protocols that, at some point, will take a\n    file-like object, read its contents, and write them out to the network,\n    optionally performing some transformation on the bytes in between.\n    \"\"\"\n\n    CHUNK_SIZE = 2**14\n\n    lastSent = \"\"\n    deferred = None\n\n    def beginFileTransfer(self, file, consumer, transform=None):\n        \"\"\"\n        Begin transferring a file\n\n        @type file: Any file-like object\n        @param file: The file object to read data from\n\n        @type consumer: Any implementor of IConsumer\n        @param consumer: The object to write data to\n\n        @param transform: A callable taking one string argument and returning\n        the same.  All bytes read from the file are passed through this before\n        being written to the consumer.\n\n        @rtype: C{Deferred}\n        @return: A deferred whose callback will be invoked when the file has\n        been completely written to the consumer. The last byte written to the\n        consumer is passed to the callback.\n        \"\"\"\n        self.file = file\n        self.consumer = consumer\n        self.transform = transform\n\n        self.deferred = deferred = defer.Deferred()\n        self.consumer.registerProducer(self, False)\n        return deferred\n\n    def resumeProducing(self):\n        chunk = \"\"\n        if self.file:\n            chunk = self.file.read(self.CHUNK_SIZE)\n        if not chunk:\n            self.file = None\n            self.consumer.unregisterProducer()\n            if self.deferred:\n                self.deferred.callback(self.lastSent)\n                self.deferred = None\n            return\n\n        if self.transform:\n            chunk = self.transform(chunk)\n        self.consumer.write(chunk)\n        self.lastSent = chunk[-1:]\n\n    def pauseProducing(self):\n        pass\n\n    def stopProducing(self):\n        if self.deferred:\n            self.deferred.errback(Exception(\"Consumer asked us to stop producing\"))\n            self.deferred = None\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_formmethod\\test_formmethod.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_formmethod -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nForm-based method objects.\n\nThis module contains support for descriptive method signatures that can be used\nto format methods.\n\"\"\"\n\nimport calendar\nfrom typing import Any, Optional, Tuple\n\n\nclass FormException(Exception):\n    \"\"\"An error occurred calling the form method.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        Exception.__init__(self, *args)\n        self.descriptions = kwargs\n\n\nclass InputError(FormException):\n    \"\"\"\n    An error occurred with some input.\n    \"\"\"\n\n\nclass Argument:\n    \"\"\"Base class for form arguments.\"\"\"\n\n    # default value for argument, if no other default is given\n    defaultDefault: Any = None\n\n    def __init__(\n        self, name, default=None, shortDesc=None, longDesc=None, hints=None, allowNone=1\n    ):\n        self.name = name\n        self.allowNone = allowNone\n        if default is None:\n            default = self.defaultDefault\n        self.default = default\n        self.shortDesc = shortDesc\n        self.longDesc = longDesc\n        if not hints:\n            hints = {}\n        self.hints = hints\n\n    def addHints(self, **kwargs):\n        self.hints.update(kwargs)\n\n    def getHint(self, name, default=None):\n        return self.hints.get(name, default)\n\n    def getShortDescription(self):\n        return self.shortDesc or self.name.capitalize()\n\n    def getLongDescription(self):\n        return self.longDesc or \"\"  # self.shortDesc or \"The %s.\" % self.name\n\n    def coerce(self, val):\n        \"\"\"Convert the value to the correct format.\"\"\"\n        raise NotImplementedError(\"implement in subclass\")\n\n\nclass String(Argument):\n    \"\"\"A single string.\"\"\"\n\n    defaultDefault: str = \"\"\n    min = 0\n    max = None\n\n    def __init__(\n        self,\n        name,\n        default=None,\n        shortDesc=None,\n        longDesc=None,\n        hints=None,\n        allowNone=1,\n        min=0,\n        max=None,\n    ):\n        Argument.__init__(\n            self,\n            name,\n            default=default,\n            shortDesc=shortDesc,\n            longDesc=longDesc,\n            hints=hints,\n            allowNone=allowNone,\n        )\n        self.min = min\n        self.max = max\n\n    def coerce(self, val):\n        s = str(val)\n        if len(s) < self.min:\n            raise InputError(\"Value must be at least %s characters long\" % self.min)\n        if self.max is not None and len(s) > self.max:\n            raise InputError(\"Value must be at most %s characters long\" % self.max)\n        return str(val)\n\n\nclass Text(String):\n    \"\"\"A long string.\"\"\"\n\n\nclass Password(String):\n    \"\"\"A string which should be obscured when input.\"\"\"\n\n\nclass VerifiedPassword(String):\n    \"\"\"A string that should be obscured when input and needs verification.\"\"\"\n\n    def coerce(self, vals):\n        if len(vals) != 2 or vals[0] != vals[1]:\n            raise InputError(\"Please enter the same password twice.\")\n        s = str(vals[0])\n        if len(s) < self.min:\n            raise InputError(\"Value must be at least %s characters long\" % self.min)\n        if self.max is not None and len(s) > self.max:\n            raise InputError(\"Value must be at most %s characters long\" % self.max)\n        return s\n\n\nclass Hidden(String):\n    \"\"\"A string which is not displayed.\n\n    The passed default is used as the value.\n    \"\"\"\n\n\nclass Integer(Argument):\n    \"\"\"A single integer.\"\"\"\n\n    defaultDefault: Optional[int] = None\n\n    def __init__(\n        self, name, allowNone=1, default=None, shortDesc=None, longDesc=None, hints=None\n    ):\n        # although Argument now has allowNone, that was recently added, and\n        # putting it at the end kept things which relied on argument order\n        # from breaking.  However, allowNone originally was in here, so\n        # I have to keep the same order, to prevent breaking code that\n        # depends on argument order only\n        Argument.__init__(self, name, default, shortDesc, longDesc, hints, allowNone)\n\n    def coerce(self, val):\n        if not val.strip() and self.allowNone:\n            return None\n        try:\n            return int(val)\n        except ValueError:\n            raise InputError(\n                \"{} is not valid, please enter \" \"a whole number, e.g. 10\".format(val)\n            )\n\n\nclass IntegerRange(Integer):\n    def __init__(\n        self,\n        name,\n        min,\n        max,\n        allowNone=1,\n        default=None,\n        shortDesc=None,\n        longDesc=None,\n        hints=None,\n    ):\n        self.min = min\n        self.max = max\n        Integer.__init__(\n            self,\n            name,\n            allowNone=allowNone,\n            default=default,\n            shortDesc=shortDesc,\n            longDesc=longDesc,\n            hints=hints,\n        )\n\n    def coerce(self, val):\n        result = Integer.coerce(self, val)\n        if self.allowNone and result == None:\n            return result\n        if result < self.min:\n            raise InputError(\n                \"Value {} is too small, it should be at least {}\".format(\n                    result, self.min\n                )\n            )\n        if result > self.max:\n            raise InputError(\n                \"Value {} is too large, it should be at most {}\".format(\n                    result, self.max\n                )\n            )\n        return result\n\n\nclass Float(Argument):\n    defaultDefault: Optional[float] = None\n\n    def __init__(\n        self, name, allowNone=1, default=None, shortDesc=None, longDesc=None, hints=None\n    ):\n        # although Argument now has allowNone, that was recently added, and\n        # putting it at the end kept things which relied on argument order\n        # from breaking.  However, allowNone originally was in here, so\n        # I have to keep the same order, to prevent breaking code that\n        # depends on argument order only\n        Argument.__init__(self, name, default, shortDesc, longDesc, hints, allowNone)\n\n    def coerce(self, val):\n        if not val.strip() and self.allowNone:\n            return None\n        try:\n            return float(val)\n        except ValueError:\n            raise InputError(\"Invalid float: %s\" % val)\n\n\nclass Choice(Argument):\n    \"\"\"\n    The result of a choice between enumerated types.  The choices should\n    be a list of tuples of tag, value, and description.  The tag will be\n    the value returned if the user hits \"Submit\", and the description\n    is the bale for the enumerated type.  default is a list of all the\n    values (seconds element in choices).  If no defaults are specified,\n    initially the first item will be selected.  Only one item can (should)\n    be selected at once.\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        choices=[],\n        default=[],\n        shortDesc=None,\n        longDesc=None,\n        hints=None,\n        allowNone=1,\n    ):\n        self.choices = choices\n        if choices and not default:\n            default.append(choices[0][1])\n        Argument.__init__(\n            self, name, default, shortDesc, longDesc, hints, allowNone=allowNone\n        )\n\n    def coerce(self, inIdent):\n        for ident, val, desc in self.choices:\n            if ident == inIdent:\n                return val\n        else:\n            raise InputError(\"Invalid Choice: %s\" % inIdent)\n\n\nclass Flags(Argument):\n    \"\"\"\n    The result of a checkbox group or multi-menu.  The flags should be a\n    list of tuples of tag, value, and description. The tag will be\n    the value returned if the user hits \"Submit\", and the description\n    is the bale for the enumerated type.  default is a list of all the\n    values (second elements in flags).  If no defaults are specified,\n    initially nothing will be selected.  Several items may be selected at\n    once.\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        flags=(),\n        default=(),\n        shortDesc=None,\n        longDesc=None,\n        hints=None,\n        allowNone=1,\n    ):\n        self.flags = flags\n        Argument.__init__(\n            self, name, default, shortDesc, longDesc, hints, allowNone=allowNone\n        )\n\n    def coerce(self, inFlagKeys):\n        if not inFlagKeys:\n            return []\n        outFlags = []\n        for inFlagKey in inFlagKeys:\n            for flagKey, flagVal, flagDesc in self.flags:\n                if inFlagKey == flagKey:\n                    outFlags.append(flagVal)\n                    break\n            else:\n                raise InputError(\"Invalid Flag: %s\" % inFlagKey)\n        return outFlags\n\n\nclass CheckGroup(Flags):\n    pass\n\n\nclass RadioGroup(Choice):\n    pass\n\n\nclass Boolean(Argument):\n    def coerce(self, inVal):\n        if not inVal:\n            return 0\n        lInVal = str(inVal).lower()\n        if lInVal in (\"no\", \"n\", \"f\", \"false\", \"0\"):\n            return 0\n        return 1\n\n\nclass File(Argument):\n    def __init__(self, name, allowNone=1, shortDesc=None, longDesc=None, hints=None):\n        Argument.__init__(\n            self, name, None, shortDesc, longDesc, hints, allowNone=allowNone\n        )\n\n    def coerce(self, file):\n        if not file and self.allowNone:\n            return None\n        elif file:\n            return file\n        else:\n            raise InputError(\"Invalid File\")\n\n\ndef positiveInt(x):\n    x = int(x)\n    if x <= 0:\n        raise ValueError\n    return x\n\n\nclass Date(Argument):\n    \"\"\"A date -- (year, month, day) tuple.\"\"\"\n\n    defaultDefault: Optional[Tuple[int, int, int]] = None\n\n    def __init__(\n        self, name, allowNone=1, default=None, shortDesc=None, longDesc=None, hints=None\n    ):\n        Argument.__init__(self, name, default, shortDesc, longDesc, hints)\n        self.allowNone = allowNone\n        if not allowNone:\n            self.defaultDefault = (1970, 1, 1)\n\n    def coerce(self, args):\n        \"\"\"Return tuple of ints (year, month, day).\"\"\"\n        if tuple(args) == (\"\", \"\", \"\") and self.allowNone:\n            return None\n\n        try:\n            year, month, day = map(positiveInt, args)\n        except ValueError:\n            raise InputError(\"Invalid date\")\n        if (month, day) == (2, 29):\n            if not calendar.isleap(year):\n                raise InputError(\"%d was not a leap year\" % year)\n            else:\n                return year, month, day\n        try:\n            mdays = calendar.mdays[month]\n        except IndexError:\n            raise InputError(\"Invalid date\")\n        if day > mdays:\n            raise InputError(\"Invalid date\")\n        return year, month, day\n\n\nclass Submit(Choice):\n    \"\"\"Submit button or a reasonable facsimile thereof.\"\"\"\n\n    def __init__(\n        self,\n        name,\n        choices=[(\"Submit\", \"submit\", \"Submit form\")],\n        reset=0,\n        shortDesc=None,\n        longDesc=None,\n        allowNone=0,\n        hints=None,\n    ):\n        Choice.__init__(\n            self,\n            name,\n            choices=choices,\n            shortDesc=shortDesc,\n            longDesc=longDesc,\n            hints=hints,\n        )\n        self.allowNone = allowNone\n        self.reset = reset\n\n    def coerce(self, value):\n        if self.allowNone and not value:\n            return None\n        else:\n            return Choice.coerce(self, value)\n\n\nclass PresentationHint:\n    \"\"\"\n    A hint to a particular system.\n    \"\"\"\n\n\nclass MethodSignature:\n    \"\"\"\n    A signature of a callable.\n    \"\"\"\n\n    def __init__(self, *sigList):\n        \"\"\"\"\"\"\n        self.methodSignature = sigList\n\n    def getArgument(self, name):\n        for a in self.methodSignature:\n            if a.name == name:\n                return a\n\n    def method(self, callable, takesRequest=False):\n        return FormMethod(self, callable, takesRequest)\n\n\nclass FormMethod:\n    \"\"\"A callable object with a signature.\"\"\"\n\n    def __init__(self, signature, callable, takesRequest=False):\n        self.signature = signature\n        self.callable = callable\n        self.takesRequest = takesRequest\n\n    def getArgs(self):\n        return tuple(self.signature.methodSignature)\n\n    def call(self, *args, **kw):\n        return self.callable(*args, **kw)\n\n### Source File Dependency Files Content\n### Dependency File: empty.txt\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_htb\\test_htb.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_htb -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nHierarchical Token Bucket traffic shaping.\n\nPatterned after U{Martin Devera's Hierarchical Token Bucket traffic\nshaper for the Linux kernel<http://luxik.cdi.cz/~devik/qos/htb/>}.\n\n@seealso: U{HTB Linux queuing discipline manual - user guide\n  <http://luxik.cdi.cz/~devik/qos/htb/manual/userg.htm>}\n@seealso: U{Token Bucket Filter in Linux Advanced Routing & Traffic Control\n    HOWTO<http://lartc.org/howto/lartc.qdisc.classless.html#AEN682>}\n\"\"\"\n\n\n# TODO: Investigate whether we should be using os.times()[-1] instead of\n# time.time.  time.time, it has been pointed out, can go backwards.  Is\n# the same true of os.times?\nfrom time import time\nfrom typing import Optional\n\nfrom zope.interface import Interface, implementer\n\nfrom twisted.protocols import pcp\n\n\nclass Bucket:\n    \"\"\"\n    Implementation of a Token bucket.\n\n    A bucket can hold a certain number of tokens and it drains over time.\n\n    @cvar maxburst: The maximum number of tokens that the bucket can\n        hold at any given time. If this is L{None}, the bucket has\n        an infinite size.\n    @type maxburst: C{int}\n    @cvar rate: The rate at which the bucket drains, in number\n        of tokens per second. If the rate is L{None}, the bucket\n        drains instantaneously.\n    @type rate: C{int}\n    \"\"\"\n\n    maxburst: Optional[int] = None\n    rate: Optional[int] = None\n\n    _refcount = 0\n\n    def __init__(self, parentBucket=None):\n        \"\"\"\n        Create a L{Bucket} that may have a parent L{Bucket}.\n\n        @param parentBucket: If a parent Bucket is specified,\n            all L{add} and L{drip} operations on this L{Bucket}\n            will be applied on the parent L{Bucket} as well.\n        @type parentBucket: L{Bucket}\n        \"\"\"\n        self.content = 0\n        self.parentBucket = parentBucket\n        self.lastDrip = time()\n\n    def add(self, amount):\n        \"\"\"\n        Adds tokens to the L{Bucket} and its C{parentBucket}.\n\n        This will add as many of the C{amount} tokens as will fit into both\n        this L{Bucket} and its C{parentBucket}.\n\n        @param amount: The number of tokens to try to add.\n        @type amount: C{int}\n\n        @returns: The number of tokens that actually fit.\n        @returntype: C{int}\n        \"\"\"\n        self.drip()\n        if self.maxburst is None:\n            allowable = amount\n        else:\n            allowable = min(amount, self.maxburst - self.content)\n\n        if self.parentBucket is not None:\n            allowable = self.parentBucket.add(allowable)\n        self.content += allowable\n        return allowable\n\n    def drip(self):\n        \"\"\"\n        Let some of the bucket drain.\n\n        The L{Bucket} drains at the rate specified by the class\n        variable C{rate}.\n\n        @returns: C{True} if the bucket is empty after this drip.\n        @returntype: C{bool}\n        \"\"\"\n        if self.parentBucket is not None:\n            self.parentBucket.drip()\n\n        if self.rate is None:\n            self.content = 0\n        else:\n            now = time()\n            deltaTime = now - self.lastDrip\n            deltaTokens = deltaTime * self.rate\n            self.content = max(0, self.content - deltaTokens)\n            self.lastDrip = now\n        return self.content == 0\n\n\nclass IBucketFilter(Interface):\n    def getBucketFor(*somethings, **some_kw):\n        \"\"\"\n        Return a L{Bucket} corresponding to the provided parameters.\n\n        @returntype: L{Bucket}\n        \"\"\"\n\n\n@implementer(IBucketFilter)\nclass HierarchicalBucketFilter:\n    \"\"\"\n    Filter things into buckets that can be nested.\n\n    @cvar bucketFactory: Class of buckets to make.\n    @type bucketFactory: L{Bucket}\n    @cvar sweepInterval: Seconds between sweeping out the bucket cache.\n    @type sweepInterval: C{int}\n    \"\"\"\n\n    bucketFactory = Bucket\n    sweepInterval: Optional[int] = None\n\n    def __init__(self, parentFilter=None):\n        self.buckets = {}\n        self.parentFilter = parentFilter\n        self.lastSweep = time()\n\n    def getBucketFor(self, *a, **kw):\n        \"\"\"\n        Find or create a L{Bucket} corresponding to the provided parameters.\n\n        Any parameters are passed on to L{getBucketKey}, from them it\n        decides which bucket you get.\n\n        @returntype: L{Bucket}\n        \"\"\"\n        if (self.sweepInterval is not None) and (\n            (time() - self.lastSweep) > self.sweepInterval\n        ):\n            self.sweep()\n\n        if self.parentFilter:\n            parentBucket = self.parentFilter.getBucketFor(self, *a, **kw)\n        else:\n            parentBucket = None\n\n        key = self.getBucketKey(*a, **kw)\n        bucket = self.buckets.get(key)\n        if bucket is None:\n            bucket = self.bucketFactory(parentBucket)\n            self.buckets[key] = bucket\n        return bucket\n\n    def getBucketKey(self, *a, **kw):\n        \"\"\"\n        Construct a key based on the input parameters to choose a L{Bucket}.\n\n        The default implementation returns the same key for all\n        arguments. Override this method to provide L{Bucket} selection.\n\n        @returns: Something to be used as a key in the bucket cache.\n        \"\"\"\n        return None\n\n    def sweep(self):\n        \"\"\"\n        Remove empty buckets.\n        \"\"\"\n        for key, bucket in self.buckets.items():\n            bucket_is_empty = bucket.drip()\n            if (bucket._refcount == 0) and bucket_is_empty:\n                del self.buckets[key]\n\n        self.lastSweep = time()\n\n\nclass FilterByHost(HierarchicalBucketFilter):\n    \"\"\"\n    A Hierarchical Bucket filter with a L{Bucket} for each host.\n    \"\"\"\n\n    sweepInterval = 60 * 20\n\n    def getBucketKey(self, transport):\n        return transport.getPeer()[1]\n\n\nclass FilterByServer(HierarchicalBucketFilter):\n    \"\"\"\n    A Hierarchical Bucket filter with a L{Bucket} for each service.\n    \"\"\"\n\n    sweepInterval = None\n\n    def getBucketKey(self, transport):\n        return transport.getHost()[2]\n\n\nclass ShapedConsumer(pcp.ProducerConsumerProxy):\n    \"\"\"\n    Wraps a C{Consumer} and shapes the rate at which it receives data.\n    \"\"\"\n\n    # Providing a Pull interface means I don't have to try to schedule\n    # traffic with callLaters.\n    iAmStreaming = False\n\n    def __init__(self, consumer, bucket):\n        pcp.ProducerConsumerProxy.__init__(self, consumer)\n        self.bucket = bucket\n        self.bucket._refcount += 1\n\n    def _writeSomeData(self, data):\n        # In practice, this actually results in obscene amounts of\n        # overhead, as a result of generating lots and lots of packets\n        # with twelve-byte payloads.  We may need to do a version of\n        # this with scheduled writes after all.\n        amount = self.bucket.add(len(data))\n        return pcp.ProducerConsumerProxy._writeSomeData(self, data[:amount])\n\n    def stopProducing(self):\n        pcp.ProducerConsumerProxy.stopProducing(self)\n        self.bucket._refcount -= 1\n\n\nclass ShapedTransport(ShapedConsumer):\n    \"\"\"\n    Wraps a C{Transport} and shapes the rate at which it receives data.\n\n    This is a L{ShapedConsumer} with a little bit of magic to provide for\n    the case where the consumer it wraps is also a C{Transport} and people\n    will be attempting to access attributes this does not proxy as a\n    C{Consumer} (e.g. C{loseConnection}).\n    \"\"\"\n\n    # Ugh.  We only wanted to filter IConsumer, not ITransport.\n\n    iAmStreaming = False\n\n    def __getattr__(self, name):\n        # Because people will be doing things like .getPeer and\n        # .loseConnection on me.\n        return getattr(self.consumer, name)\n\n\nclass ShapedProtocolFactory:\n    \"\"\"\n    Dispense C{Protocols} with traffic shaping on their transports.\n\n    Usage::\n\n        myserver = SomeFactory()\n        myserver.protocol = ShapedProtocolFactory(myserver.protocol,\n                                                  bucketFilter)\n\n    Where C{SomeServerFactory} is a L{twisted.internet.protocol.Factory}, and\n    C{bucketFilter} is an instance of L{HierarchicalBucketFilter}.\n    \"\"\"\n\n    def __init__(self, protoClass, bucketFilter):\n        \"\"\"\n        Tell me what to wrap and where to get buckets.\n\n        @param protoClass: The class of C{Protocol} this will generate\n          wrapped instances of.\n        @type protoClass: L{Protocol<twisted.internet.interfaces.IProtocol>}\n          class\n        @param bucketFilter: The filter which will determine how\n          traffic is shaped.\n        @type bucketFilter: L{HierarchicalBucketFilter}.\n        \"\"\"\n        # More precisely, protoClass can be any callable that will return\n        # instances of something that implements IProtocol.\n        self.protocol = protoClass\n        self.bucketFilter = bucketFilter\n\n    def __call__(self, *a, **kw):\n        \"\"\"\n        Make a C{Protocol} instance with a shaped transport.\n\n        Any parameters will be passed on to the protocol's initializer.\n\n        @returns: A C{Protocol} instance with a L{ShapedTransport}.\n        \"\"\"\n        proto = self.protocol(*a, **kw)\n        origMakeConnection = proto.makeConnection\n\n        def makeConnection(transport):\n            bucket = self.bucketFilter.getBucketFor(transport)\n            shapedTransport = ShapedTransport(transport, bucket)\n            return origMakeConnection(shapedTransport)\n\n        proto.makeConnection = makeConnection\n        return proto\n\n### Source File Dependency Files Content\n### Dependency File: pcp.py\n# -*- test-case-name: twisted.test.test_pcp -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nProducer-Consumer Proxy.\n\"\"\"\n\nfrom zope.interface import implementer\n\nfrom twisted.internet import interfaces\n\n\n@implementer(interfaces.IProducer, interfaces.IConsumer)\nclass BasicProducerConsumerProxy:\n    \"\"\"\n    I can act as a man in the middle between any Producer and Consumer.\n\n    @ivar producer: the Producer I subscribe to.\n    @type producer: L{IProducer<interfaces.IProducer>}\n    @ivar consumer: the Consumer I publish to.\n    @type consumer: L{IConsumer<interfaces.IConsumer>}\n    @ivar paused: As a Producer, am I paused?\n    @type paused: bool\n    \"\"\"\n\n    consumer = None\n    producer = None\n    producerIsStreaming = None\n    iAmStreaming = True\n    outstandingPull = False\n    paused = False\n    stopped = False\n\n    def __init__(self, consumer):\n        self._buffer = []\n        if consumer is not None:\n            self.consumer = consumer\n            consumer.registerProducer(self, self.iAmStreaming)\n\n    # Producer methods:\n\n    def pauseProducing(self):\n        self.paused = True\n        if self.producer:\n            self.producer.pauseProducing()\n\n    def resumeProducing(self):\n        self.paused = False\n        if self._buffer:\n            # TODO: Check to see if consumer supports writeSeq.\n            self.consumer.write(\"\".join(self._buffer))\n            self._buffer[:] = []\n        else:\n            if not self.iAmStreaming:\n                self.outstandingPull = True\n\n        if self.producer is not None:\n            self.producer.resumeProducing()\n\n    def stopProducing(self):\n        if self.producer is not None:\n            self.producer.stopProducing()\n        if self.consumer is not None:\n            del self.consumer\n\n    # Consumer methods:\n\n    def write(self, data):\n        if self.paused or (not self.iAmStreaming and not self.outstandingPull):\n            # We could use that fifo queue here.\n            self._buffer.append(data)\n\n        elif self.consumer is not None:\n            self.consumer.write(data)\n            self.outstandingPull = False\n\n    def finish(self):\n        if self.consumer is not None:\n            self.consumer.finish()\n        self.unregisterProducer()\n\n    def registerProducer(self, producer, streaming):\n        self.producer = producer\n        self.producerIsStreaming = streaming\n\n    def unregisterProducer(self):\n        if self.producer is not None:\n            del self.producer\n            del self.producerIsStreaming\n        if self.consumer:\n            self.consumer.unregisterProducer()\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__}@{id(self):x} around {self.consumer}>\"\n\n\nclass ProducerConsumerProxy(BasicProducerConsumerProxy):\n    \"\"\"ProducerConsumerProxy with a finite buffer.\n\n    When my buffer fills up, I have my parent Producer pause until my buffer\n    has room in it again.\n    \"\"\"\n\n    # Copies much from abstract.FileDescriptor\n    bufferSize = 2**2**2**2\n\n    producerPaused = False\n    unregistered = False\n\n    def pauseProducing(self):\n        # Does *not* call up to ProducerConsumerProxy to relay the pause\n        # message through to my parent Producer.\n        self.paused = True\n\n    def resumeProducing(self):\n        self.paused = False\n        if self._buffer:\n            data = \"\".join(self._buffer)\n            bytesSent = self._writeSomeData(data)\n            if bytesSent < len(data):\n                unsent = data[bytesSent:]\n                assert (\n                    not self.iAmStreaming\n                ), \"Streaming producer did not write all its data.\"\n                self._buffer[:] = [unsent]\n            else:\n                self._buffer[:] = []\n        else:\n            bytesSent = 0\n\n        if (\n            self.unregistered\n            and bytesSent\n            and not self._buffer\n            and self.consumer is not None\n        ):\n            self.consumer.unregisterProducer()\n\n        if not self.iAmStreaming:\n            self.outstandingPull = not bytesSent\n\n        if self.producer is not None:\n            bytesBuffered = sum(len(s) for s in self._buffer)\n            # TODO: You can see here the potential for high and low\n            # watermarks, where bufferSize would be the high mark when we\n            # ask the upstream producer to pause, and we wouldn't have\n            # it resume again until it hit the low mark.  Or if producer\n            # is Pull, maybe we'd like to pull from it as much as necessary\n            # to keep our buffer full to the low mark, so we're never caught\n            # without something to send.\n            if self.producerPaused and (bytesBuffered < self.bufferSize):\n                # Now that our buffer is empty,\n                self.producerPaused = False\n                self.producer.resumeProducing()\n            elif self.outstandingPull:\n                # I did not have any data to write in response to a pull,\n                # so I'd better pull some myself.\n                self.producer.resumeProducing()\n\n    def write(self, data):\n        if self.paused or (not self.iAmStreaming and not self.outstandingPull):\n            # We could use that fifo queue here.\n            self._buffer.append(data)\n\n        elif self.consumer is not None:\n            assert (\n                not self._buffer\n            ), \"Writing fresh data to consumer before my buffer is empty!\"\n            # I'm going to use _writeSomeData here so that there is only one\n            # path to self.consumer.write.  But it doesn't actually make sense,\n            # if I am streaming, for some data to not be all data.  But maybe I\n            # am not streaming, but I am writing here anyway, because there was\n            # an earlier request for data which was not answered.\n            bytesSent = self._writeSomeData(data)\n            self.outstandingPull = False\n            if not bytesSent == len(data):\n                assert (\n                    not self.iAmStreaming\n                ), \"Streaming producer did not write all its data.\"\n                self._buffer.append(data[bytesSent:])\n\n        if (self.producer is not None) and self.producerIsStreaming:\n            bytesBuffered = sum(len(s) for s in self._buffer)\n            if bytesBuffered >= self.bufferSize:\n                self.producer.pauseProducing()\n                self.producerPaused = True\n\n    def registerProducer(self, producer, streaming):\n        self.unregistered = False\n        BasicProducerConsumerProxy.registerProducer(self, producer, streaming)\n        if not streaming:\n            producer.resumeProducing()\n\n    def unregisterProducer(self):\n        if self.producer is not None:\n            del self.producer\n            del self.producerIsStreaming\n        self.unregistered = True\n        if self.consumer and not self._buffer:\n            self.consumer.unregisterProducer()\n\n    def _writeSomeData(self, data):\n        \"\"\"Write as much of this data as possible.\n\n        @returns: The number of bytes written.\n        \"\"\"\n        if self.consumer is None:\n            return 0\n        self.consumer.write(data)\n        return len(data)\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_lockfile\\test_lockfile.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_lockfile -*-\n# Copyright (c) 2005 Divmod, Inc.\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nFilesystem-based interprocess mutex.\n\"\"\"\n\n\nimport errno\nimport os\nfrom time import time as _uniquefloat\n\nfrom twisted.python.runtime import platform\n\n\ndef unique():\n    return str(int(_uniquefloat() * 1000))\n\n\nfrom os import rename\n\nif not platform.isWindows():\n    from os import kill, readlink, remove as rmlink, symlink\n\n    _windows = False\nelse:\n    _windows = True\n\n    # On UNIX, a symlink can be made to a nonexistent location, and\n    # FilesystemLock uses this by making the target of the symlink an\n    # imaginary, non-existing file named that of the PID of the process with\n    # the lock. This has some benefits on UNIX -- making and removing this\n    # symlink is atomic. However, because Windows doesn't support symlinks (at\n    # least as how we know them), we have to fake this and actually write a\n    # file with the PID of the process holding the lock instead.\n    # These functions below perform that unenviable, probably-fraught-with-\n    # race-conditions duty. - hawkie\n\n    try:\n        import pywintypes\n        from win32api import OpenProcess\n    except ImportError:\n        kill = None  # type: ignore[assignment]\n    else:\n        ERROR_ACCESS_DENIED = 5\n        ERROR_INVALID_PARAMETER = 87\n\n        # typing ignored due to:\n        # https://github.com/python/typeshed/issues/4249\n        def kill(pid, signal):  # type: ignore[misc]\n            try:\n                OpenProcess(0, 0, pid)\n            except pywintypes.error as e:\n                if e.args[0] == ERROR_ACCESS_DENIED:\n                    return\n                elif e.args[0] == ERROR_INVALID_PARAMETER:\n                    raise OSError(errno.ESRCH, None)\n                raise\n            else:\n                raise RuntimeError(\"OpenProcess is required to fail.\")\n\n    # For monkeypatching in tests\n    _open = open\n\n    # typing ignored due to:\n    # https://github.com/python/typeshed/issues/4249\n    def symlink(value, filename):  # type: ignore[misc]\n        \"\"\"\n        Write a file at C{filename} with the contents of C{value}. See the\n        above comment block as to why this is needed.\n        \"\"\"\n        # XXX Implement an atomic thingamajig for win32\n        newlinkname = filename + \".\" + unique() + \".newlink\"\n        newvalname = os.path.join(newlinkname, \"symlink\")\n        os.mkdir(newlinkname)\n\n        # Python 3 does not support the 'commit' flag of fopen in the MSVCRT\n        # (http://msdn.microsoft.com/en-us/library/yeby3zcb%28VS.71%29.aspx)\n        mode = \"w\"\n\n        with _open(newvalname, mode) as f:\n            f.write(value)\n            f.flush()\n\n        try:\n            rename(newlinkname, filename)\n        except BaseException:\n            os.remove(newvalname)\n            os.rmdir(newlinkname)\n            raise\n\n    # typing ignored due to:\n    # https://github.com/python/typeshed/issues/4249\n    def readlink(filename):  # type: ignore[misc]\n        \"\"\"\n        Read the contents of C{filename}. See the above comment block as to why\n        this is needed.\n        \"\"\"\n        try:\n            fObj = _open(os.path.join(filename, \"symlink\"), \"r\")\n        except OSError as e:\n            if e.errno == errno.ENOENT or e.errno == errno.EIO:\n                raise OSError(e.errno, None)\n            raise\n        else:\n            with fObj:\n                result = fObj.read()\n            return result\n\n    # typing ignored due to:\n    # https://github.com/python/typeshed/issues/4249\n    def rmlink(filename):  # type: ignore[misc]\n        os.remove(os.path.join(filename, \"symlink\"))\n        os.rmdir(filename)\n\n\nclass FilesystemLock:\n    \"\"\"\n    A mutex.\n\n    This relies on the filesystem property that creating\n    a symlink is an atomic operation and that it will\n    fail if the symlink already exists.  Deleting the\n    symlink will release the lock.\n\n    @ivar name: The name of the file associated with this lock.\n\n    @ivar clean: Indicates whether this lock was released cleanly by its\n        last owner.  Only meaningful after C{lock} has been called and\n        returns True.\n\n    @ivar locked: Indicates whether the lock is currently held by this\n        object.\n    \"\"\"\n\n    clean = None\n    locked = False\n\n    def __init__(self, name):\n        self.name = name\n\n    def lock(self):\n        \"\"\"\n        Acquire this lock.\n\n        @rtype: C{bool}\n        @return: True if the lock is acquired, false otherwise.\n\n        @raise OSError: Any exception L{os.symlink()} may raise,\n            other than L{errno.EEXIST}.\n        \"\"\"\n        clean = True\n        while True:\n            try:\n                symlink(str(os.getpid()), self.name)\n            except OSError as e:\n                if _windows and e.errno in (errno.EACCES, errno.EIO):\n                    # The lock is in the middle of being deleted because we're\n                    # on Windows where lock removal isn't atomic.  Give up, we\n                    # don't know how long this is going to take.\n                    return False\n                if e.errno == errno.EEXIST:\n                    try:\n                        pid = readlink(self.name)\n                    except OSError as e:\n                        if e.errno == errno.ENOENT:\n                            # The lock has vanished, try to claim it in the\n                            # next iteration through the loop.\n                            continue\n                        elif _windows and e.errno == errno.EACCES:\n                            # The lock is in the middle of being\n                            # deleted because we're on Windows where\n                            # lock removal isn't atomic.  Give up, we\n                            # don't know how long this is going to\n                            # take.\n                            return False\n                        raise\n                    try:\n                        if kill is not None:\n                            kill(int(pid), 0)\n                    except OSError as e:\n                        if e.errno == errno.ESRCH:\n                            # The owner has vanished, try to claim it in the\n                            # next iteration through the loop.\n                            try:\n                                rmlink(self.name)\n                            except OSError as e:\n                                if e.errno == errno.ENOENT:\n                                    # Another process cleaned up the lock.\n                                    # Race them to acquire it in the next\n                                    # iteration through the loop.\n                                    continue\n                                raise\n                            clean = False\n                            continue\n                        raise\n                    return False\n                raise\n            self.locked = True\n            self.clean = clean\n            return True\n\n    def unlock(self):\n        \"\"\"\n        Release this lock.\n\n        This deletes the directory with the given name.\n\n        @raise OSError: Any exception L{os.readlink()} may raise.\n        @raise ValueError: If the lock is not owned by this process.\n        \"\"\"\n        pid = readlink(self.name)\n        if int(pid) != os.getpid():\n            raise ValueError(f\"Lock {self.name!r} not owned by this process\")\n        rmlink(self.name)\n        self.locked = False\n\n\ndef isLocked(name):\n    \"\"\"\n    Determine if the lock of the given name is held or not.\n\n    @type name: C{str}\n    @param name: The filesystem path to the lock to test\n\n    @rtype: C{bool}\n    @return: True if the lock is held, False otherwise.\n    \"\"\"\n    l = FilesystemLock(name)\n    result = None\n    try:\n        result = l.lock()\n    finally:\n        if result:\n            l.unlock()\n    return not result\n\n\n__all__ = [\"FilesystemLock\", \"isLocked\"]\n\n### Source File Dependency Files Content\n### Dependency File: runtime.py\n# -*- test-case-name: twisted.python.test.test_runtime -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n__all__ = [\n    \"seconds\",\n    \"shortPythonVersion\",\n    \"Platform\",\n    \"platform\",\n    \"platformType\",\n]\nimport os\nimport sys\nimport warnings\nfrom time import time as seconds\nfrom typing import Optional\n\n\ndef shortPythonVersion() -> str:\n    \"\"\"\n    Returns the Python version as a dot-separated string.\n    \"\"\"\n    return \"%s.%s.%s\" % sys.version_info[:3]\n\n\nknownPlatforms = {\n    \"nt\": \"win32\",\n    \"ce\": \"win32\",\n    \"posix\": \"posix\",\n    \"java\": \"java\",\n    \"org.python.modules.os\": \"java\",\n}\n\n\nclass Platform:\n    \"\"\"\n    Gives us information about the platform we're running on.\n    \"\"\"\n\n    type: Optional[str] = knownPlatforms.get(os.name)\n    seconds = staticmethod(seconds)\n    _platform = sys.platform\n\n    def __init__(\n        self, name: Optional[str] = None, platform: Optional[str] = None\n    ) -> None:\n        if name is not None:\n            self.type = knownPlatforms.get(name)\n        if platform is not None:\n            self._platform = platform\n\n    def isKnown(self) -> bool:\n        \"\"\"\n        Do we know about this platform?\n\n        @return: Boolean indicating whether this is a known platform or not.\n        \"\"\"\n        return self.type != None\n\n    def getType(self) -> Optional[str]:\n        \"\"\"\n        Get platform type.\n\n        @return: Either 'posix', 'win32' or 'java'\n        \"\"\"\n        return self.type\n\n    def isMacOSX(self) -> bool:\n        \"\"\"\n        Check if current platform is macOS.\n\n        @return: C{True} if the current platform has been detected as macOS.\n        \"\"\"\n        return self._platform == \"darwin\"\n\n    def isWinNT(self) -> bool:\n        \"\"\"\n        Are we running in Windows NT?\n\n        This is deprecated and always returns C{True} on win32 because\n        Twisted only supports Windows NT-derived platforms at this point.\n\n        @return: C{True} if the current platform has been detected as\n            Windows NT.\n        \"\"\"\n        warnings.warn(\n            \"twisted.python.runtime.Platform.isWinNT was deprecated in \"\n            \"Twisted 13.0. Use Platform.isWindows instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return self.isWindows()\n\n    def isWindows(self) -> bool:\n        \"\"\"\n        Are we running in Windows?\n\n        @return: C{True} if the current platform has been detected as\n            Windows.\n        \"\"\"\n        return self.getType() == \"win32\"\n\n    def isVista(self) -> bool:\n        \"\"\"\n        Check if current platform is Windows Vista or Windows Server 2008.\n\n        @return: C{True} if the current platform has been detected as Vista\n        \"\"\"\n        return sys.platform == \"win32\" and sys.getwindowsversion().major == 6\n\n    def isLinux(self) -> bool:\n        \"\"\"\n        Check if current platform is Linux.\n\n        @return: C{True} if the current platform has been detected as Linux.\n        \"\"\"\n        return self._platform.startswith(\"linux\")\n\n    def isDocker(self, _initCGroupLocation: str = \"/proc/1/cgroup\") -> bool:\n        \"\"\"\n        Check if the current platform is Linux in a Docker container.\n\n        @return: C{True} if the current platform has been detected as Linux\n            inside a Docker container.\n        \"\"\"\n        if not self.isLinux():\n            return False\n\n        from twisted.python.filepath import FilePath\n\n        # Ask for the cgroups of init (pid 1)\n        initCGroups = FilePath(_initCGroupLocation)\n        if initCGroups.exists():\n            # The cgroups file looks like \"2:cpu:/\". The third element will\n            # begin with /docker if it is inside a Docker container.\n            controlGroups = [\n                x.split(b\":\") for x in initCGroups.getContent().split(b\"\\n\")\n            ]\n\n            for group in controlGroups:\n                if len(group) == 3 and group[2].startswith(b\"/docker/\"):\n                    # If it starts with /docker/, we're in a docker container\n                    return True\n\n        return False\n\n    def _supportsSymlinks(self) -> bool:\n        \"\"\"\n        Check for symlink support usable for Twisted's purposes.\n\n        @return: C{True} if symlinks are supported on the current platform,\n                 otherwise C{False}.\n        \"\"\"\n        if self.isWindows():\n            # We do the isWindows() check as newer Pythons support the symlink\n            # support in Vista+, but only if you have some obscure permission\n            # (SeCreateSymbolicLinkPrivilege), which can only be given on\n            # platforms with msc.exe (so, Business/Enterprise editions).\n            # This uncommon requirement makes the Twisted test suite test fail\n            # in 99.99% of cases as general users don't have permission to do\n            # it, even if there is \"symlink support\".\n            return False\n        else:\n            # If we're not on Windows, check for existence of os.symlink.\n            try:\n                os.symlink\n            except AttributeError:\n                return False\n            else:\n                return True\n\n    def supportsThreads(self) -> bool:\n        \"\"\"\n        Can threads be created?\n\n        @return: C{True} if the threads are supported on the current platform.\n        \"\"\"\n        try:\n            import threading\n\n            return threading is not None  # shh pyflakes\n        except ImportError:\n            return False\n\n    def supportsINotify(self) -> bool:\n        \"\"\"\n        Return C{True} if we can use the inotify API on this platform.\n\n        @since: 10.1\n        \"\"\"\n        try:\n            from twisted.python._inotify import INotifyError, init\n        except ImportError:\n            return False\n\n        try:\n            os.close(init())\n        except INotifyError:\n            return False\n        return True\n\n\nplatform = Platform()\nplatformType = platform.getType()\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_logfile\\test_logfile.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_logfile -*-\n\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nA rotating, browsable log file.\n\"\"\"\n\n\n# System Imports\nimport glob\nimport os\nimport stat\nimport time\nfrom typing import BinaryIO, Optional, cast\n\nfrom twisted.python import threadable\n\n\nclass BaseLogFile:\n    \"\"\"\n    The base class for a log file that can be rotated.\n    \"\"\"\n\n    synchronized = [\"write\", \"rotate\"]\n\n    def __init__(\n        self, name: str, directory: str, defaultMode: Optional[int] = None\n    ) -> None:\n        \"\"\"\n        Create a log file.\n\n        @param name: name of the file\n        @param directory: directory holding the file\n        @param defaultMode: permissions used to create the file. Default to\n        current permissions of the file if the file exists.\n        \"\"\"\n        self.directory = directory\n        self.name = name\n        self.path = os.path.join(directory, name)\n        if defaultMode is None and os.path.exists(self.path):\n            self.defaultMode: Optional[int] = stat.S_IMODE(\n                os.stat(self.path)[stat.ST_MODE]\n            )\n        else:\n            self.defaultMode = defaultMode\n        self._openFile()\n\n    @classmethod\n    def fromFullPath(cls, filename, *args, **kwargs):\n        \"\"\"\n        Construct a log file from a full file path.\n        \"\"\"\n        logPath = os.path.abspath(filename)\n        return cls(os.path.basename(logPath), os.path.dirname(logPath), *args, **kwargs)\n\n    def shouldRotate(self):\n        \"\"\"\n        Override with a method to that returns true if the log\n        should be rotated.\n        \"\"\"\n        raise NotImplementedError\n\n    def _openFile(self):\n        \"\"\"\n        Open the log file.\n\n        The log file is always opened in binary mode.\n        \"\"\"\n        self.closed = False\n        if os.path.exists(self.path):\n            self._file = cast(BinaryIO, open(self.path, \"rb+\", 0))\n            self._file.seek(0, 2)\n        else:\n            if self.defaultMode is not None:\n                # Set the lowest permissions\n                oldUmask = os.umask(0o777)\n                try:\n                    self._file = cast(BinaryIO, open(self.path, \"wb+\", 0))\n                finally:\n                    os.umask(oldUmask)\n            else:\n                self._file = cast(BinaryIO, open(self.path, \"wb+\", 0))\n        if self.defaultMode is not None:\n            try:\n                os.chmod(self.path, self.defaultMode)\n            except OSError:\n                # Probably /dev/null or something?\n                pass\n\n    def write(self, data):\n        \"\"\"\n        Write some data to the file.\n\n        @param data: The data to write.  Text will be encoded as UTF-8.\n        @type data: L{bytes} or L{unicode}\n        \"\"\"\n        if self.shouldRotate():\n            self.flush()\n            self.rotate()\n        if isinstance(data, str):\n            data = data.encode(\"utf8\")\n        self._file.write(data)\n\n    def flush(self):\n        \"\"\"\n        Flush the file.\n        \"\"\"\n        self._file.flush()\n\n    def close(self):\n        \"\"\"\n        Close the file.\n\n        The file cannot be used once it has been closed.\n        \"\"\"\n        self.closed = True\n        self._file.close()\n        del self._file\n\n    def reopen(self):\n        \"\"\"\n        Reopen the log file. This is mainly useful if you use an external log\n        rotation tool, which moves under your feet.\n\n        Note that on Windows you probably need a specific API to rename the\n        file, as it's not supported to simply use os.rename, for example.\n        \"\"\"\n        self.close()\n        self._openFile()\n\n    def getCurrentLog(self):\n        \"\"\"\n        Return a LogReader for the current log file.\n        \"\"\"\n        return LogReader(self.path)\n\n\nclass LogFile(BaseLogFile):\n    \"\"\"\n    A log file that can be rotated.\n\n    A rotateLength of None disables automatic log rotation.\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        directory,\n        rotateLength=1000000,\n        defaultMode=None,\n        maxRotatedFiles=None,\n    ):\n        \"\"\"\n        Create a log file rotating on length.\n\n        @param name: file name.\n        @type name: C{str}\n        @param directory: path of the log file.\n        @type directory: C{str}\n        @param rotateLength: size of the log file where it rotates. Default to\n            1M.\n        @type rotateLength: C{int}\n        @param defaultMode: mode used to create the file.\n        @type defaultMode: C{int}\n        @param maxRotatedFiles: if not None, max number of log files the class\n            creates. Warning: it removes all log files above this number.\n        @type maxRotatedFiles: C{int}\n        \"\"\"\n        BaseLogFile.__init__(self, name, directory, defaultMode)\n        self.rotateLength = rotateLength\n        self.maxRotatedFiles = maxRotatedFiles\n\n    def _openFile(self):\n        BaseLogFile._openFile(self)\n        self.size = self._file.tell()\n\n    def shouldRotate(self):\n        \"\"\"\n        Rotate when the log file size is larger than rotateLength.\n        \"\"\"\n        return self.rotateLength and self.size >= self.rotateLength\n\n    def getLog(self, identifier):\n        \"\"\"\n        Given an integer, return a LogReader for an old log file.\n        \"\"\"\n        filename = \"%s.%d\" % (self.path, identifier)\n        if not os.path.exists(filename):\n            raise ValueError(\"no such logfile exists\")\n        return LogReader(filename)\n\n    def write(self, data):\n        \"\"\"\n        Write some data to the file.\n        \"\"\"\n        BaseLogFile.write(self, data)\n        self.size += len(data)\n\n    def rotate(self):\n        \"\"\"\n        Rotate the file and create a new one.\n\n        If it's not possible to open new logfile, this will fail silently,\n        and continue logging to old logfile.\n        \"\"\"\n        if not (os.access(self.directory, os.W_OK) and os.access(self.path, os.W_OK)):\n            return\n        logs = self.listLogs()\n        logs.reverse()\n        for i in logs:\n            if self.maxRotatedFiles is not None and i >= self.maxRotatedFiles:\n                os.remove(\"%s.%d\" % (self.path, i))\n            else:\n                os.rename(\"%s.%d\" % (self.path, i), \"%s.%d\" % (self.path, i + 1))\n        self._file.close()\n        os.rename(self.path, \"%s.1\" % self.path)\n        self._openFile()\n\n    def listLogs(self):\n        \"\"\"\n        Return sorted list of integers - the old logs' identifiers.\n        \"\"\"\n        result = []\n        for name in glob.glob(\"%s.*\" % self.path):\n            try:\n                counter = int(name.split(\".\")[-1])\n                if counter:\n                    result.append(counter)\n            except ValueError:\n                pass\n        result.sort()\n        return result\n\n    def __getstate__(self):\n        state = BaseLogFile.__getstate__(self)\n        del state[\"size\"]\n        return state\n\n\nthreadable.synchronize(LogFile)\n\n\nclass DailyLogFile(BaseLogFile):\n    \"\"\"A log file that is rotated daily (at or after midnight localtime)\"\"\"\n\n    def _openFile(self):\n        BaseLogFile._openFile(self)\n        self.lastDate = self.toDate(os.stat(self.path)[8])\n\n    def shouldRotate(self):\n        \"\"\"Rotate when the date has changed since last write\"\"\"\n        return self.toDate() > self.lastDate\n\n    def toDate(self, *args):\n        \"\"\"Convert a unixtime to (year, month, day) localtime tuple,\n        or return the current (year, month, day) localtime tuple.\n\n        This function primarily exists so you may overload it with\n        gmtime, or some cruft to make unit testing possible.\n        \"\"\"\n        # primarily so this can be unit tested easily\n        return time.localtime(*args)[:3]\n\n    def suffix(self, tupledate):\n        \"\"\"Return the suffix given a (year, month, day) tuple or unixtime\"\"\"\n        try:\n            return \"_\".join(map(str, tupledate))\n        except BaseException:\n            # try taking a float unixtime\n            return \"_\".join(map(str, self.toDate(tupledate)))\n\n    def getLog(self, identifier):\n        \"\"\"Given a unix time, return a LogReader for an old log file.\"\"\"\n        if self.toDate(identifier) == self.lastDate:\n            return self.getCurrentLog()\n        filename = f\"{self.path}.{self.suffix(identifier)}\"\n        if not os.path.exists(filename):\n            raise ValueError(\"no such logfile exists\")\n        return LogReader(filename)\n\n    def write(self, data):\n        \"\"\"Write some data to the log file\"\"\"\n        BaseLogFile.write(self, data)\n        # Guard against a corner case where time.time()\n        # could potentially run backwards to yesterday.\n        # Primarily due to network time.\n        self.lastDate = max(self.lastDate, self.toDate())\n\n    def rotate(self):\n        \"\"\"Rotate the file and create a new one.\n\n        If it's not possible to open new logfile, this will fail silently,\n        and continue logging to old logfile.\n        \"\"\"\n        if not (os.access(self.directory, os.W_OK) and os.access(self.path, os.W_OK)):\n            return\n        newpath = f\"{self.path}.{self.suffix(self.lastDate)}\"\n        if os.path.exists(newpath):\n            return\n        self._file.close()\n        os.rename(self.path, newpath)\n        self._openFile()\n\n    def __getstate__(self):\n        state = BaseLogFile.__getstate__(self)\n        del state[\"lastDate\"]\n        return state\n\n\nthreadable.synchronize(DailyLogFile)\n\n\nclass LogReader:\n    \"\"\"Read from a log file.\"\"\"\n\n    def __init__(self, name):\n        \"\"\"\n        Open the log file for reading.\n\n        The comments about binary-mode for L{BaseLogFile._openFile} also apply\n        here.\n        \"\"\"\n        self._file = open(name)  # Optional[BinaryIO]\n\n    def readLines(self, lines=10):\n        \"\"\"Read a list of lines from the log file.\n\n        This doesn't returns all of the files lines - call it multiple times.\n        \"\"\"\n        result = []\n        for i in range(lines):\n            line = self._file.readline()\n            if not line:\n                break\n            result.append(line)\n        return result\n\n    def close(self):\n        self._file.close()\n\n### Source File Dependency Files Content\n### Dependency File: threadable.py\n# -*- test-case-name: twisted.python.test_threadable -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nA module to provide some very basic threading primitives, such as\nsynchronization.\n\"\"\"\n\n\nfrom functools import wraps\n\n\nclass DummyLock:\n    \"\"\"\n    Hack to allow locks to be unpickled on an unthreaded system.\n    \"\"\"\n\n    def __reduce__(self):\n        return (unpickle_lock, ())\n\n\ndef unpickle_lock():\n    if threadingmodule is not None:\n        return XLock()\n    else:\n        return DummyLock()\n\n\nunpickle_lock.__safe_for_unpickling__ = True  # type: ignore[attr-defined]\n\n\ndef _synchPre(self):\n    if \"_threadable_lock\" not in self.__dict__:\n        _synchLockCreator.acquire()\n        if \"_threadable_lock\" not in self.__dict__:\n            self.__dict__[\"_threadable_lock\"] = XLock()\n        _synchLockCreator.release()\n    self._threadable_lock.acquire()\n\n\ndef _synchPost(self):\n    self._threadable_lock.release()\n\n\ndef _sync(klass, function):\n    @wraps(function)\n    def sync(self, *args, **kwargs):\n        _synchPre(self)\n        try:\n            return function(self, *args, **kwargs)\n        finally:\n            _synchPost(self)\n\n    return sync\n\n\ndef synchronize(*klasses):\n    \"\"\"\n    Make all methods listed in each class' synchronized attribute synchronized.\n\n    The synchronized attribute should be a list of strings, consisting of the\n    names of methods that must be synchronized. If we are running in threaded\n    mode these methods will be wrapped with a lock.\n    \"\"\"\n    if threadingmodule is not None:\n        for klass in klasses:\n            for methodName in klass.synchronized:\n                sync = _sync(klass, klass.__dict__[methodName])\n                setattr(klass, methodName, sync)\n\n\ndef init(with_threads=1):\n    \"\"\"Initialize threading.\n\n    Don't bother calling this.  If it needs to happen, it will happen.\n    \"\"\"\n    global threaded, _synchLockCreator, XLock\n\n    if with_threads:\n        if not threaded:\n            if threadingmodule is not None:\n                threaded = True\n\n                class XLock(threadingmodule._RLock):\n                    def __reduce__(self):\n                        return (unpickle_lock, ())\n\n                _synchLockCreator = XLock()\n            else:\n                raise RuntimeError(\n                    \"Cannot initialize threading, platform lacks thread support\"\n                )\n    else:\n        if threaded:\n            raise RuntimeError(\"Cannot uninitialize threads\")\n        else:\n            pass\n\n\n_dummyID = object()\n\n\ndef getThreadID():\n    if threadingmodule is None:\n        return _dummyID\n    return threadingmodule.current_thread().ident\n\n\ndef isInIOThread():\n    \"\"\"Are we in the thread responsible for I/O requests (the event loop)?\"\"\"\n    return ioThread == getThreadID()\n\n\ndef registerAsIOThread():\n    \"\"\"Mark the current thread as responsible for I/O requests.\"\"\"\n    global ioThread\n    ioThread = getThreadID()\n\n\nioThread = None\nthreaded = False\n# Define these globals which might be overwritten in init().\n_synchLockCreator = None\nXLock = None\n\n\ntry:\n    import threading as _threadingmodule\nexcept ImportError:\n    threadingmodule = None\nelse:\n    threadingmodule = _threadingmodule\n    init(True)\n\n\n__all__ = [\"isInIOThread\", \"registerAsIOThread\", \"getThreadID\", \"XLock\"]\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_memcache\\test_memcache.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_memcache -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nMemcache client protocol. Memcached is a caching server, storing data in the\nform of pairs key/value, and memcache is the protocol to talk with it.\n\nTo connect to a server, create a factory for L{MemCacheProtocol}::\n\n    from twisted.internet import reactor, protocol\n    from twisted.protocols.memcache import MemCacheProtocol, DEFAULT_PORT\n    d = protocol.ClientCreator(reactor, MemCacheProtocol\n        ).connectTCP(\"localhost\", DEFAULT_PORT)\n    def doSomething(proto):\n        # Here you call the memcache operations\n        return proto.set(\"mykey\", \"a lot of data\")\n    d.addCallback(doSomething)\n    reactor.run()\n\nAll the operations of the memcache protocol are present, but\nL{MemCacheProtocol.set} and L{MemCacheProtocol.get} are the more important.\n\nSee U{http://code.sixapart.com/svn/memcached/trunk/server/doc/protocol.txt} for\nmore information about the protocol.\n\"\"\"\n\n\nfrom collections import deque\n\nfrom twisted.internet.defer import Deferred, TimeoutError, fail\nfrom twisted.protocols.basic import LineReceiver\nfrom twisted.protocols.policies import TimeoutMixin\nfrom twisted.python import log\nfrom twisted.python.compat import nativeString, networkString\n\nDEFAULT_PORT = 11211\n\n\nclass NoSuchCommand(Exception):\n    \"\"\"\n    Exception raised when a non existent command is called.\n    \"\"\"\n\n\nclass ClientError(Exception):\n    \"\"\"\n    Error caused by an invalid client call.\n    \"\"\"\n\n\nclass ServerError(Exception):\n    \"\"\"\n    Problem happening on the server.\n    \"\"\"\n\n\nclass Command:\n    \"\"\"\n    Wrap a client action into an object, that holds the values used in the\n    protocol.\n\n    @ivar _deferred: the L{Deferred} object that will be fired when the result\n        arrives.\n    @type _deferred: L{Deferred}\n\n    @ivar command: name of the command sent to the server.\n    @type command: L{bytes}\n    \"\"\"\n\n    def __init__(self, command, **kwargs):\n        \"\"\"\n        Create a command.\n\n        @param command: the name of the command.\n        @type command: L{bytes}\n\n        @param kwargs: this values will be stored as attributes of the object\n            for future use\n        \"\"\"\n        self.command = command\n        self._deferred = Deferred()\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\n    def success(self, value):\n        \"\"\"\n        Shortcut method to fire the underlying deferred.\n        \"\"\"\n        self._deferred.callback(value)\n\n    def fail(self, error):\n        \"\"\"\n        Make the underlying deferred fails.\n        \"\"\"\n        self._deferred.errback(error)\n\n\nclass MemCacheProtocol(LineReceiver, TimeoutMixin):\n    \"\"\"\n    MemCache protocol: connect to a memcached server to store/retrieve values.\n\n    @ivar persistentTimeOut: the timeout period used to wait for a response.\n    @type persistentTimeOut: L{int}\n\n    @ivar _current: current list of requests waiting for an answer from the\n        server.\n    @type _current: L{deque} of L{Command}\n\n    @ivar _lenExpected: amount of data expected in raw mode, when reading for\n        a value.\n    @type _lenExpected: L{int}\n\n    @ivar _getBuffer: current buffer of data, used to store temporary data\n        when reading in raw mode.\n    @type _getBuffer: L{list}\n\n    @ivar _bufferLength: the total amount of bytes in C{_getBuffer}.\n    @type _bufferLength: L{int}\n\n    @ivar _disconnected: indicate if the connectionLost has been called or not.\n    @type _disconnected: L{bool}\n    \"\"\"\n\n    MAX_KEY_LENGTH = 250\n    _disconnected = False\n\n    def __init__(self, timeOut=60):\n        \"\"\"\n        Create the protocol.\n\n        @param timeOut: the timeout to wait before detecting that the\n            connection is dead and close it. It's expressed in seconds.\n        @type timeOut: L{int}\n        \"\"\"\n        self._current = deque()\n        self._lenExpected = None\n        self._getBuffer = None\n        self._bufferLength = None\n        self.persistentTimeOut = self.timeOut = timeOut\n\n    def _cancelCommands(self, reason):\n        \"\"\"\n        Cancel all the outstanding commands, making them fail with C{reason}.\n        \"\"\"\n        while self._current:\n            cmd = self._current.popleft()\n            cmd.fail(reason)\n\n    def timeoutConnection(self):\n        \"\"\"\n        Close the connection in case of timeout.\n        \"\"\"\n        self._cancelCommands(TimeoutError(\"Connection timeout\"))\n        self.transport.loseConnection()\n\n    def connectionLost(self, reason):\n        \"\"\"\n        Cause any outstanding commands to fail.\n        \"\"\"\n        self._disconnected = True\n        self._cancelCommands(reason)\n        LineReceiver.connectionLost(self, reason)\n\n    def sendLine(self, line):\n        \"\"\"\n        Override sendLine to add a timeout to response.\n        \"\"\"\n        if not self._current:\n            self.setTimeout(self.persistentTimeOut)\n        LineReceiver.sendLine(self, line)\n\n    def rawDataReceived(self, data):\n        \"\"\"\n        Collect data for a get.\n        \"\"\"\n        self.resetTimeout()\n        self._getBuffer.append(data)\n        self._bufferLength += len(data)\n        if self._bufferLength >= self._lenExpected + 2:\n            data = b\"\".join(self._getBuffer)\n            buf = data[: self._lenExpected]\n            rem = data[self._lenExpected + 2 :]\n            val = buf\n            self._lenExpected = None\n            self._getBuffer = None\n            self._bufferLength = None\n            cmd = self._current[0]\n            if cmd.multiple:\n                flags, cas = cmd.values[cmd.currentKey]\n                cmd.values[cmd.currentKey] = (flags, cas, val)\n            else:\n                cmd.value = val\n            self.setLineMode(rem)\n\n    def cmd_STORED(self):\n        \"\"\"\n        Manage a success response to a set operation.\n        \"\"\"\n        self._current.popleft().success(True)\n\n    def cmd_NOT_STORED(self):\n        \"\"\"\n        Manage a specific 'not stored' response to a set operation: this is not\n        an error, but some condition wasn't met.\n        \"\"\"\n        self._current.popleft().success(False)\n\n    def cmd_END(self):\n        \"\"\"\n        This the end token to a get or a stat operation.\n        \"\"\"\n        cmd = self._current.popleft()\n        if cmd.command == b\"get\":\n            if cmd.multiple:\n                values = {key: val[::2] for key, val in cmd.values.items()}\n                cmd.success(values)\n            else:\n                cmd.success((cmd.flags, cmd.value))\n        elif cmd.command == b\"gets\":\n            if cmd.multiple:\n                cmd.success(cmd.values)\n            else:\n                cmd.success((cmd.flags, cmd.cas, cmd.value))\n        elif cmd.command == b\"stats\":\n            cmd.success(cmd.values)\n        else:\n            raise RuntimeError(\n                \"Unexpected END response to {} command\".format(\n                    nativeString(cmd.command)\n                )\n            )\n\n    def cmd_NOT_FOUND(self):\n        \"\"\"\n        Manage error response for incr/decr/delete.\n        \"\"\"\n        self._current.popleft().success(False)\n\n    def cmd_VALUE(self, line):\n        \"\"\"\n        Prepare the reading a value after a get.\n        \"\"\"\n        cmd = self._current[0]\n        if cmd.command == b\"get\":\n            key, flags, length = line.split()\n            cas = b\"\"\n        else:\n            key, flags, length, cas = line.split()\n        self._lenExpected = int(length)\n        self._getBuffer = []\n        self._bufferLength = 0\n        if cmd.multiple:\n            if key not in cmd.keys:\n                raise RuntimeError(\"Unexpected commands answer.\")\n            cmd.currentKey = key\n            cmd.values[key] = [int(flags), cas]\n        else:\n            if cmd.key != key:\n                raise RuntimeError(\"Unexpected commands answer.\")\n            cmd.flags = int(flags)\n            cmd.cas = cas\n        self.setRawMode()\n\n    def cmd_STAT(self, line):\n        \"\"\"\n        Reception of one stat line.\n        \"\"\"\n        cmd = self._current[0]\n        key, val = line.split(b\" \", 1)\n        cmd.values[key] = val\n\n    def cmd_VERSION(self, versionData):\n        \"\"\"\n        Read version token.\n        \"\"\"\n        self._current.popleft().success(versionData)\n\n    def cmd_ERROR(self):\n        \"\"\"\n        A non-existent command has been sent.\n        \"\"\"\n        log.err(\"Non-existent command sent.\")\n        cmd = self._current.popleft()\n        cmd.fail(NoSuchCommand())\n\n    def cmd_CLIENT_ERROR(self, errText):\n        \"\"\"\n        An invalid input as been sent.\n        \"\"\"\n        errText = repr(errText)\n        log.err(\"Invalid input: \" + errText)\n        cmd = self._current.popleft()\n        cmd.fail(ClientError(errText))\n\n    def cmd_SERVER_ERROR(self, errText):\n        \"\"\"\n        An error has happened server-side.\n        \"\"\"\n        errText = repr(errText)\n        log.err(\"Server error: \" + errText)\n        cmd = self._current.popleft()\n        cmd.fail(ServerError(errText))\n\n    def cmd_DELETED(self):\n        \"\"\"\n        A delete command has completed successfully.\n        \"\"\"\n        self._current.popleft().success(True)\n\n    def cmd_OK(self):\n        \"\"\"\n        The last command has been completed.\n        \"\"\"\n        self._current.popleft().success(True)\n\n    def cmd_EXISTS(self):\n        \"\"\"\n        A C{checkAndSet} update has failed.\n        \"\"\"\n        self._current.popleft().success(False)\n\n    def lineReceived(self, line):\n        \"\"\"\n        Receive line commands from the server.\n        \"\"\"\n        self.resetTimeout()\n        token = line.split(b\" \", 1)[0]\n        # First manage standard commands without space\n        cmd = getattr(self, \"cmd_\" + nativeString(token), None)\n        if cmd is not None:\n            args = line.split(b\" \", 1)[1:]\n            if args:\n                cmd(args[0])\n            else:\n                cmd()\n        else:\n            # Then manage commands with space in it\n            line = line.replace(b\" \", b\"_\")\n            cmd = getattr(self, \"cmd_\" + nativeString(line), None)\n            if cmd is not None:\n                cmd()\n            else:\n                # Increment/Decrement response\n                cmd = self._current.popleft()\n                val = int(line)\n                cmd.success(val)\n        if not self._current:\n            # No pending request, remove timeout\n            self.setTimeout(None)\n\n    def increment(self, key, val=1):\n        \"\"\"\n        Increment the value of C{key} by given value (default to 1).\n        C{key} must be consistent with an int. Return the new value.\n\n        @param key: the key to modify.\n        @type key: L{bytes}\n\n        @param val: the value to increment.\n        @type val: L{int}\n\n        @return: a deferred with will be called back with the new value\n            associated with the key (after the increment).\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._incrdecr(b\"incr\", key, val)\n\n    def decrement(self, key, val=1):\n        \"\"\"\n        Decrement the value of C{key} by given value (default to 1).\n        C{key} must be consistent with an int. Return the new value, coerced to\n        0 if negative.\n\n        @param key: the key to modify.\n        @type key: L{bytes}\n\n        @param val: the value to decrement.\n        @type val: L{int}\n\n        @return: a deferred with will be called back with the new value\n            associated with the key (after the decrement).\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._incrdecr(b\"decr\", key, val)\n\n    def _incrdecr(self, cmd, key, val):\n        \"\"\"\n        Internal wrapper for incr/decr.\n        \"\"\"\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        if not isinstance(key, bytes):\n            return fail(\n                ClientError(f\"Invalid type for key: {type(key)}, expecting bytes\")\n            )\n        if len(key) > self.MAX_KEY_LENGTH:\n            return fail(ClientError(\"Key too long\"))\n        fullcmd = b\" \".join([cmd, key, b\"%d\" % (int(val),)])\n        self.sendLine(fullcmd)\n        cmdObj = Command(cmd, key=key)\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n    def replace(self, key, val, flags=0, expireTime=0):\n        \"\"\"\n        Replace the given C{key}. It must already exist in the server.\n\n        @param key: the key to replace.\n        @type key: L{bytes}\n\n        @param val: the new value associated with the key.\n        @type val: L{bytes}\n\n        @param flags: the flags to store with the key.\n        @type flags: L{int}\n\n        @param expireTime: if different from 0, the relative time in seconds\n            when the key will be deleted from the store.\n        @type expireTime: L{int}\n\n        @return: a deferred that will fire with C{True} if the operation has\n            succeeded, and C{False} with the key didn't previously exist.\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._set(b\"replace\", key, val, flags, expireTime, b\"\")\n\n    def add(self, key, val, flags=0, expireTime=0):\n        \"\"\"\n        Add the given C{key}. It must not exist in the server.\n\n        @param key: the key to add.\n        @type key: L{bytes}\n\n        @param val: the value associated with the key.\n        @type val: L{bytes}\n\n        @param flags: the flags to store with the key.\n        @type flags: L{int}\n\n        @param expireTime: if different from 0, the relative time in seconds\n            when the key will be deleted from the store.\n        @type expireTime: L{int}\n\n        @return: a deferred that will fire with C{True} if the operation has\n            succeeded, and C{False} with the key already exists.\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._set(b\"add\", key, val, flags, expireTime, b\"\")\n\n    def set(self, key, val, flags=0, expireTime=0):\n        \"\"\"\n        Set the given C{key}.\n\n        @param key: the key to set.\n        @type key: L{bytes}\n\n        @param val: the value associated with the key.\n        @type val: L{bytes}\n\n        @param flags: the flags to store with the key.\n        @type flags: L{int}\n\n        @param expireTime: if different from 0, the relative time in seconds\n            when the key will be deleted from the store.\n        @type expireTime: L{int}\n\n        @return: a deferred that will fire with C{True} if the operation has\n            succeeded.\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._set(b\"set\", key, val, flags, expireTime, b\"\")\n\n    def checkAndSet(self, key, val, cas, flags=0, expireTime=0):\n        \"\"\"\n        Change the content of C{key} only if the C{cas} value matches the\n        current one associated with the key. Use this to store a value which\n        hasn't been modified since last time you fetched it.\n\n        @param key: The key to set.\n        @type key: L{bytes}\n\n        @param val: The value associated with the key.\n        @type val: L{bytes}\n\n        @param cas: Unique 64-bit value returned by previous call of C{get}.\n        @type cas: L{bytes}\n\n        @param flags: The flags to store with the key.\n        @type flags: L{int}\n\n        @param expireTime: If different from 0, the relative time in seconds\n            when the key will be deleted from the store.\n        @type expireTime: L{int}\n\n        @return: A deferred that will fire with C{True} if the operation has\n            succeeded, C{False} otherwise.\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._set(b\"cas\", key, val, flags, expireTime, cas)\n\n    def _set(self, cmd, key, val, flags, expireTime, cas):\n        \"\"\"\n        Internal wrapper for setting values.\n        \"\"\"\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        if not isinstance(key, bytes):\n            return fail(\n                ClientError(f\"Invalid type for key: {type(key)}, expecting bytes\")\n            )\n        if len(key) > self.MAX_KEY_LENGTH:\n            return fail(ClientError(\"Key too long\"))\n        if not isinstance(val, bytes):\n            return fail(\n                ClientError(f\"Invalid type for value: {type(val)}, expecting bytes\")\n            )\n        if cas:\n            cas = b\" \" + cas\n        length = len(val)\n        fullcmd = (\n            b\" \".join(\n                [cmd, key, networkString(\"%d %d %d\" % (flags, expireTime, length))]\n            )\n            + cas\n        )\n        self.sendLine(fullcmd)\n        self.sendLine(val)\n        cmdObj = Command(cmd, key=key, flags=flags, length=length)\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n    def append(self, key, val):\n        \"\"\"\n        Append given data to the value of an existing key.\n\n        @param key: The key to modify.\n        @type key: L{bytes}\n\n        @param val: The value to append to the current value associated with\n            the key.\n        @type val: L{bytes}\n\n        @return: A deferred that will fire with C{True} if the operation has\n            succeeded, C{False} otherwise.\n        @rtype: L{Deferred}\n        \"\"\"\n        # Even if flags and expTime values are ignored, we have to pass them\n        return self._set(b\"append\", key, val, 0, 0, b\"\")\n\n    def prepend(self, key, val):\n        \"\"\"\n        Prepend given data to the value of an existing key.\n\n        @param key: The key to modify.\n        @type key: L{bytes}\n\n        @param val: The value to prepend to the current value associated with\n            the key.\n        @type val: L{bytes}\n\n        @return: A deferred that will fire with C{True} if the operation has\n            succeeded, C{False} otherwise.\n        @rtype: L{Deferred}\n        \"\"\"\n        # Even if flags and expTime values are ignored, we have to pass them\n        return self._set(b\"prepend\", key, val, 0, 0, b\"\")\n\n    def get(self, key, withIdentifier=False):\n        \"\"\"\n        Get the given C{key}. It doesn't support multiple keys. If\n        C{withIdentifier} is set to C{True}, the command issued is a C{gets},\n        that will return the current identifier associated with the value. This\n        identifier has to be used when issuing C{checkAndSet} update later,\n        using the corresponding method.\n\n        @param key: The key to retrieve.\n        @type key: L{bytes}\n\n        @param withIdentifier: If set to C{True}, retrieve the current\n            identifier along with the value and the flags.\n        @type withIdentifier: L{bool}\n\n        @return: A deferred that will fire with the tuple (flags, value) if\n            C{withIdentifier} is C{False}, or (flags, cas identifier, value)\n            if C{True}.  If the server indicates there is no value\n            associated with C{key}, the returned value will be L{None} and\n            the returned flags will be C{0}.\n        @rtype: L{Deferred}\n        \"\"\"\n        return self._get([key], withIdentifier, False)\n\n    def getMultiple(self, keys, withIdentifier=False):\n        \"\"\"\n        Get the given list of C{keys}.  If C{withIdentifier} is set to C{True},\n        the command issued is a C{gets}, that will return the identifiers\n        associated with each values. This identifier has to be used when\n        issuing C{checkAndSet} update later, using the corresponding method.\n\n        @param keys: The keys to retrieve.\n        @type keys: L{list} of L{bytes}\n\n        @param withIdentifier: If set to C{True}, retrieve the identifiers\n            along with the values and the flags.\n        @type withIdentifier: L{bool}\n\n        @return: A deferred that will fire with a dictionary with the elements\n            of C{keys} as keys and the tuples (flags, value) as values if\n            C{withIdentifier} is C{False}, or (flags, cas identifier, value) if\n            C{True}.  If the server indicates there is no value associated with\n            C{key}, the returned values will be L{None} and the returned flags\n            will be C{0}.\n        @rtype: L{Deferred}\n\n        @since: 9.0\n        \"\"\"\n        return self._get(keys, withIdentifier, True)\n\n    def _get(self, keys, withIdentifier, multiple):\n        \"\"\"\n        Helper method for C{get} and C{getMultiple}.\n        \"\"\"\n        keys = list(keys)\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        for key in keys:\n            if not isinstance(key, bytes):\n                return fail(\n                    ClientError(f\"Invalid type for key: {type(key)}, expecting bytes\")\n                )\n            if len(key) > self.MAX_KEY_LENGTH:\n                return fail(ClientError(\"Key too long\"))\n        if withIdentifier:\n            cmd = b\"gets\"\n        else:\n            cmd = b\"get\"\n        fullcmd = b\" \".join([cmd] + keys)\n        self.sendLine(fullcmd)\n        if multiple:\n            values = {key: (0, b\"\", None) for key in keys}\n            cmdObj = Command(cmd, keys=keys, values=values, multiple=True)\n        else:\n            cmdObj = Command(\n                cmd, key=keys[0], value=None, flags=0, cas=b\"\", multiple=False\n            )\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n    def stats(self, arg=None):\n        \"\"\"\n        Get some stats from the server. It will be available as a dict.\n\n        @param arg: An optional additional string which will be sent along\n            with the I{stats} command.  The interpretation of this value by\n            the server is left undefined by the memcache protocol\n            specification.\n        @type arg: L{None} or L{bytes}\n\n        @return: a deferred that will fire with a L{dict} of the available\n            statistics.\n        @rtype: L{Deferred}\n        \"\"\"\n        if arg:\n            cmd = b\"stats \" + arg\n        else:\n            cmd = b\"stats\"\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        self.sendLine(cmd)\n        cmdObj = Command(b\"stats\", values={})\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n    def version(self):\n        \"\"\"\n        Get the version of the server.\n\n        @return: a deferred that will fire with the string value of the\n            version.\n        @rtype: L{Deferred}\n        \"\"\"\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        self.sendLine(b\"version\")\n        cmdObj = Command(b\"version\")\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n    def delete(self, key):\n        \"\"\"\n        Delete an existing C{key}.\n\n        @param key: the key to delete.\n        @type key: L{bytes}\n\n        @return: a deferred that will be called back with C{True} if the key\n            was successfully deleted, or C{False} if not.\n        @rtype: L{Deferred}\n        \"\"\"\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        if not isinstance(key, bytes):\n            return fail(\n                ClientError(f\"Invalid type for key: {type(key)}, expecting bytes\")\n            )\n        self.sendLine(b\"delete \" + key)\n        cmdObj = Command(b\"delete\", key=key)\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n    def flushAll(self):\n        \"\"\"\n        Flush all cached values.\n\n        @return: a deferred that will be called back with C{True} when the\n            operation has succeeded.\n        @rtype: L{Deferred}\n        \"\"\"\n        if self._disconnected:\n            return fail(RuntimeError(\"not connected\"))\n        self.sendLine(b\"flush_all\")\n        cmdObj = Command(b\"flush_all\")\n        self._current.append(cmdObj)\n        return cmdObj._deferred\n\n\n__all__ = [\n    \"MemCacheProtocol\",\n    \"DEFAULT_PORT\",\n    \"NoSuchCommand\",\n    \"ClientError\",\n    \"ServerError\",\n]\n\n### Source File Dependency Files Content\n### Dependency File: basic.py\n# -*- test-case-name: twisted.protocols.test.test_basic -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nBasic protocols, such as line-oriented, netstring, and int prefixed strings.\n\"\"\"\n\n\nimport math\n\n# System imports\nimport re\nfrom io import BytesIO\nfrom struct import calcsize, pack, unpack\n\nfrom zope.interface import implementer\n\n# Twisted imports\nfrom twisted.internet import defer, interfaces, protocol\nfrom twisted.python import log\n\n\n# Unfortunately we cannot use regular string formatting on Python 3; see\n# http://bugs.python.org/issue3982 for details.\ndef _formatNetstring(data):\n    return b\"\".join([str(len(data)).encode(\"ascii\"), b\":\", data, b\",\"])\n\n\n_formatNetstring.__doc__ = \"\"\"\nConvert some C{bytes} into netstring format.\n\n@param data: C{bytes} that will be reformatted.\n\"\"\"\n\n\nDEBUG = 0\n\n\nclass NetstringParseError(ValueError):\n    \"\"\"\n    The incoming data is not in valid Netstring format.\n    \"\"\"\n\n\nclass IncompleteNetstring(Exception):\n    \"\"\"\n    Not enough data to complete a netstring.\n    \"\"\"\n\n\nclass NetstringReceiver(protocol.Protocol):\n    \"\"\"\n    A protocol that sends and receives netstrings.\n\n    See U{http://cr.yp.to/proto/netstrings.txt} for the specification of\n    netstrings. Every netstring starts with digits that specify the length\n    of the data. This length specification is separated from the data by\n    a colon. The data is terminated with a comma.\n\n    Override L{stringReceived} to handle received netstrings. This\n    method is called with the netstring payload as a single argument\n    whenever a complete netstring is received.\n\n    Security features:\n        1. Messages are limited in size, useful if you don't want\n           someone sending you a 500MB netstring (change C{self.MAX_LENGTH}\n           to the maximum length you wish to accept).\n        2. The connection is lost if an illegal message is received.\n\n    @ivar MAX_LENGTH: Defines the maximum length of netstrings that can be\n        received.\n    @type MAX_LENGTH: C{int}\n\n    @ivar _LENGTH: A pattern describing all strings that contain a netstring\n        length specification. Examples for length specifications are C{b'0:'},\n        C{b'12:'}, and C{b'179:'}. C{b'007:'} is not a valid length\n        specification, since leading zeros are not allowed.\n    @type _LENGTH: C{re.Match}\n\n    @ivar _LENGTH_PREFIX: A pattern describing all strings that contain\n        the first part of a netstring length specification (without the\n        trailing comma). Examples are '0', '12', and '179'. '007' does not\n        start a netstring length specification, since leading zeros are\n        not allowed.\n    @type _LENGTH_PREFIX: C{re.Match}\n\n    @ivar _PARSING_LENGTH: Indicates that the C{NetstringReceiver} is in\n        the state of parsing the length portion of a netstring.\n    @type _PARSING_LENGTH: C{int}\n\n    @ivar _PARSING_PAYLOAD: Indicates that the C{NetstringReceiver} is in\n        the state of parsing the payload portion (data and trailing comma)\n        of a netstring.\n    @type _PARSING_PAYLOAD: C{int}\n\n    @ivar brokenPeer: Indicates if the connection is still functional\n    @type brokenPeer: C{int}\n\n    @ivar _state: Indicates if the protocol is consuming the length portion\n        (C{PARSING_LENGTH}) or the payload (C{PARSING_PAYLOAD}) of a netstring\n    @type _state: C{int}\n\n    @ivar _remainingData: Holds the chunk of data that has not yet been consumed\n    @type _remainingData: C{string}\n\n    @ivar _payload: Holds the payload portion of a netstring including the\n        trailing comma\n    @type _payload: C{BytesIO}\n\n    @ivar _expectedPayloadSize: Holds the payload size plus one for the trailing\n        comma.\n    @type _expectedPayloadSize: C{int}\n    \"\"\"\n\n    MAX_LENGTH = 99999\n    _LENGTH = re.compile(rb\"(0|[1-9]\\d*)(:)\")\n\n    _LENGTH_PREFIX = re.compile(rb\"(0|[1-9]\\d*)$\")\n\n    # Some error information for NetstringParseError instances.\n    _MISSING_LENGTH = (\n        \"The received netstring does not start with a \" \"length specification.\"\n    )\n    _OVERFLOW = (\n        \"The length specification of the received netstring \"\n        \"cannot be represented in Python - it causes an \"\n        \"OverflowError!\"\n    )\n    _TOO_LONG = (\n        \"The received netstring is longer than the maximum %s \"\n        \"specified by self.MAX_LENGTH\"\n    )\n    _MISSING_COMMA = \"The received netstring is not terminated by a comma.\"\n\n    # The following constants are used for determining if the NetstringReceiver\n    # is parsing the length portion of a netstring, or the payload.\n    _PARSING_LENGTH, _PARSING_PAYLOAD = range(2)\n\n    def makeConnection(self, transport):\n        \"\"\"\n        Initializes the protocol.\n        \"\"\"\n        protocol.Protocol.makeConnection(self, transport)\n        self._remainingData = b\"\"\n        self._currentPayloadSize = 0\n        self._payload = BytesIO()\n        self._state = self._PARSING_LENGTH\n        self._expectedPayloadSize = 0\n        self.brokenPeer = 0\n\n    def sendString(self, string):\n        \"\"\"\n        Sends a netstring.\n\n        Wraps up C{string} by adding length information and a\n        trailing comma; writes the result to the transport.\n\n        @param string: The string to send.  The necessary framing (length\n            prefix, etc) will be added.\n        @type string: C{bytes}\n        \"\"\"\n        self.transport.write(_formatNetstring(string))\n\n    def dataReceived(self, data):\n        \"\"\"\n        Receives some characters of a netstring.\n\n        Whenever a complete netstring is received, this method extracts\n        its payload and calls L{stringReceived} to process it.\n\n        @param data: A chunk of data representing a (possibly partial)\n            netstring\n        @type data: C{bytes}\n        \"\"\"\n        self._remainingData += data\n        while self._remainingData:\n            try:\n                self._consumeData()\n            except IncompleteNetstring:\n                break\n            except NetstringParseError:\n                self._handleParseError()\n                break\n\n    def stringReceived(self, string):\n        \"\"\"\n        Override this for notification when each complete string is received.\n\n        @param string: The complete string which was received with all\n            framing (length prefix, etc) removed.\n        @type string: C{bytes}\n\n        @raise NotImplementedError: because the method has to be implemented\n            by the child class.\n        \"\"\"\n        raise NotImplementedError()\n\n    def _maxLengthSize(self):\n        \"\"\"\n        Calculate and return the string size of C{self.MAX_LENGTH}.\n\n        @return: The size of the string representation for C{self.MAX_LENGTH}\n        @rtype: C{float}\n        \"\"\"\n        return math.ceil(math.log10(self.MAX_LENGTH)) + 1\n\n    def _consumeData(self):\n        \"\"\"\n        Consumes the content of C{self._remainingData}.\n\n        @raise IncompleteNetstring: if C{self._remainingData} does not\n            contain enough data to complete the current netstring.\n        @raise NetstringParseError: if the received data do not\n            form a valid netstring.\n        \"\"\"\n        if self._state == self._PARSING_LENGTH:\n            self._consumeLength()\n            self._prepareForPayloadConsumption()\n        if self._state == self._PARSING_PAYLOAD:\n            self._consumePayload()\n\n    def _consumeLength(self):\n        \"\"\"\n        Consumes the length portion of C{self._remainingData}.\n\n        @raise IncompleteNetstring: if C{self._remainingData} contains\n            a partial length specification (digits without trailing\n            comma).\n        @raise NetstringParseError: if the received data do not form a valid\n            netstring.\n        \"\"\"\n        lengthMatch = self._LENGTH.match(self._remainingData)\n        if not lengthMatch:\n            self._checkPartialLengthSpecification()\n            raise IncompleteNetstring()\n        self._processLength(lengthMatch)\n\n    def _checkPartialLengthSpecification(self):\n        \"\"\"\n        Makes sure that the received data represents a valid number.\n\n        Checks if C{self._remainingData} represents a number smaller or\n        equal to C{self.MAX_LENGTH}.\n\n        @raise NetstringParseError: if C{self._remainingData} is no\n            number or is too big (checked by L{_extractLength}).\n        \"\"\"\n        partialLengthMatch = self._LENGTH_PREFIX.match(self._remainingData)\n        if not partialLengthMatch:\n            raise NetstringParseError(self._MISSING_LENGTH)\n        lengthSpecification = partialLengthMatch.group(1)\n        self._extractLength(lengthSpecification)\n\n    def _processLength(self, lengthMatch):\n        \"\"\"\n        Processes the length definition of a netstring.\n\n        Extracts and stores in C{self._expectedPayloadSize} the number\n        representing the netstring size.  Removes the prefix\n        representing the length specification from\n        C{self._remainingData}.\n\n        @raise NetstringParseError: if the received netstring does not\n            start with a number or the number is bigger than\n            C{self.MAX_LENGTH}.\n        @param lengthMatch: A regular expression match object matching\n            a netstring length specification\n        @type lengthMatch: C{re.Match}\n        \"\"\"\n        endOfNumber = lengthMatch.end(1)\n        startOfData = lengthMatch.end(2)\n        lengthString = self._remainingData[:endOfNumber]\n        # Expect payload plus trailing comma:\n        self._expectedPayloadSize = self._extractLength(lengthString) + 1\n        self._remainingData = self._remainingData[startOfData:]\n\n    def _extractLength(self, lengthAsString):\n        \"\"\"\n        Attempts to extract the length information of a netstring.\n\n        @raise NetstringParseError: if the number is bigger than\n            C{self.MAX_LENGTH}.\n        @param lengthAsString: A chunk of data starting with a length\n            specification\n        @type lengthAsString: C{bytes}\n        @return: The length of the netstring\n        @rtype: C{int}\n        \"\"\"\n        self._checkStringSize(lengthAsString)\n        length = int(lengthAsString)\n        if length > self.MAX_LENGTH:\n            raise NetstringParseError(self._TOO_LONG % (self.MAX_LENGTH,))\n        return length\n\n    def _checkStringSize(self, lengthAsString):\n        \"\"\"\n        Checks the sanity of lengthAsString.\n\n        Checks if the size of the length specification exceeds the\n        size of the string representing self.MAX_LENGTH. If this is\n        not the case, the number represented by lengthAsString is\n        certainly bigger than self.MAX_LENGTH, and a\n        NetstringParseError can be raised.\n\n        This method should make sure that netstrings with extremely\n        long length specifications are refused before even attempting\n        to convert them to an integer (which might trigger a\n        MemoryError).\n        \"\"\"\n        if len(lengthAsString) > self._maxLengthSize():\n            raise NetstringParseError(self._TOO_LONG % (self.MAX_LENGTH,))\n\n    def _prepareForPayloadConsumption(self):\n        \"\"\"\n        Sets up variables necessary for consuming the payload of a netstring.\n        \"\"\"\n        self._state = self._PARSING_PAYLOAD\n        self._currentPayloadSize = 0\n        self._payload.seek(0)\n        self._payload.truncate()\n\n    def _consumePayload(self):\n        \"\"\"\n        Consumes the payload portion of C{self._remainingData}.\n\n        If the payload is complete, checks for the trailing comma and\n        processes the payload. If not, raises an L{IncompleteNetstring}\n        exception.\n\n        @raise IncompleteNetstring: if the payload received so far\n            contains fewer characters than expected.\n        @raise NetstringParseError: if the payload does not end with a\n        comma.\n        \"\"\"\n        self._extractPayload()\n        if self._currentPayloadSize < self._expectedPayloadSize:\n            raise IncompleteNetstring()\n        self._checkForTrailingComma()\n        self._state = self._PARSING_LENGTH\n        self._processPayload()\n\n    def _extractPayload(self):\n        \"\"\"\n        Extracts payload information from C{self._remainingData}.\n\n        Splits C{self._remainingData} at the end of the netstring.  The\n        first part becomes C{self._payload}, the second part is stored\n        in C{self._remainingData}.\n\n        If the netstring is not yet complete, the whole content of\n        C{self._remainingData} is moved to C{self._payload}.\n        \"\"\"\n        if self._payloadComplete():\n            remainingPayloadSize = self._expectedPayloadSize - self._currentPayloadSize\n            self._payload.write(self._remainingData[:remainingPayloadSize])\n            self._remainingData = self._remainingData[remainingPayloadSize:]\n            self._currentPayloadSize = self._expectedPayloadSize\n        else:\n            self._payload.write(self._remainingData)\n            self._currentPayloadSize += len(self._remainingData)\n            self._remainingData = b\"\"\n\n    def _payloadComplete(self):\n        \"\"\"\n        Checks if enough data have been received to complete the netstring.\n\n        @return: C{True} iff the received data contain at least as many\n            characters as specified in the length section of the\n            netstring\n        @rtype: C{bool}\n        \"\"\"\n        return (\n            len(self._remainingData) + self._currentPayloadSize\n            >= self._expectedPayloadSize\n        )\n\n    def _processPayload(self):\n        \"\"\"\n        Processes the actual payload with L{stringReceived}.\n\n        Strips C{self._payload} of the trailing comma and calls\n        L{stringReceived} with the result.\n        \"\"\"\n        self.stringReceived(self._payload.getvalue()[:-1])\n\n    def _checkForTrailingComma(self):\n        \"\"\"\n        Checks if the netstring has a trailing comma at the expected position.\n\n        @raise NetstringParseError: if the last payload character is\n            anything but a comma.\n        \"\"\"\n        if self._payload.getvalue()[-1:] != b\",\":\n            raise NetstringParseError(self._MISSING_COMMA)\n\n    def _handleParseError(self):\n        \"\"\"\n        Terminates the connection and sets the flag C{self.brokenPeer}.\n        \"\"\"\n        self.transport.loseConnection()\n        self.brokenPeer = 1\n\n\nclass LineOnlyReceiver(protocol.Protocol):\n    \"\"\"\n    A protocol that receives only lines.\n\n    This is purely a speed optimisation over LineReceiver, for the\n    cases that raw mode is known to be unnecessary.\n\n    @cvar delimiter: The line-ending delimiter to use. By default this is\n                     C{b'\\\\r\\\\n'}.\n    @cvar MAX_LENGTH: The maximum length of a line to allow (If a\n                      sent line is longer than this, the connection is dropped).\n                      Default is 16384.\n    \"\"\"\n\n    _buffer = b\"\"\n    delimiter = b\"\\r\\n\"\n    MAX_LENGTH = 16384\n\n    def dataReceived(self, data):\n        \"\"\"\n        Translates bytes into lines, and calls lineReceived.\n        \"\"\"\n        lines = (self._buffer + data).split(self.delimiter)\n        self._buffer = lines.pop(-1)\n        for line in lines:\n            if self.transport.disconnecting:\n                # this is necessary because the transport may be told to lose\n                # the connection by a line within a larger packet, and it is\n                # important to disregard all the lines in that packet following\n                # the one that told it to close.\n                return\n            if len(line) > self.MAX_LENGTH:\n                return self.lineLengthExceeded(line)\n            else:\n                self.lineReceived(line)\n        if len(self._buffer) > self.MAX_LENGTH:\n            return self.lineLengthExceeded(self._buffer)\n\n    def lineReceived(self, line):\n        \"\"\"\n        Override this for when each line is received.\n\n        @param line: The line which was received with the delimiter removed.\n        @type line: C{bytes}\n        \"\"\"\n        raise NotImplementedError\n\n    def sendLine(self, line):\n        \"\"\"\n        Sends a line to the other end of the connection.\n\n        @param line: The line to send, not including the delimiter.\n        @type line: C{bytes}\n        \"\"\"\n        return self.transport.writeSequence((line, self.delimiter))\n\n    def lineLengthExceeded(self, line):\n        \"\"\"\n        Called when the maximum line length has been reached.\n        Override if it needs to be dealt with in some special way.\n        \"\"\"\n        return self.transport.loseConnection()\n\n\nclass _PauseableMixin:\n    paused = False\n\n    def pauseProducing(self):\n        self.paused = True\n        self.transport.pauseProducing()\n\n    def resumeProducing(self):\n        self.paused = False\n        self.transport.resumeProducing()\n        self.dataReceived(b\"\")\n\n    def stopProducing(self):\n        self.paused = True\n        self.transport.stopProducing()\n\n\nclass LineReceiver(protocol.Protocol, _PauseableMixin):\n    \"\"\"\n    A protocol that receives lines and/or raw data, depending on mode.\n\n    In line mode, each line that's received becomes a callback to\n    L{lineReceived}.  In raw data mode, each chunk of raw data becomes a\n    callback to L{LineReceiver.rawDataReceived}.\n    The L{setLineMode} and L{setRawMode} methods switch between the two modes.\n\n    This is useful for line-oriented protocols such as IRC, HTTP, POP, etc.\n\n    @cvar delimiter: The line-ending delimiter to use. By default this is\n                     C{b'\\\\r\\\\n'}.\n    @cvar MAX_LENGTH: The maximum length of a line to allow (If a\n                      sent line is longer than this, the connection is dropped).\n                      Default is 16384.\n    \"\"\"\n\n    line_mode = 1\n    _buffer = b\"\"\n    _busyReceiving = False\n    delimiter = b\"\\r\\n\"\n    MAX_LENGTH = 16384\n\n    def clearLineBuffer(self):\n        \"\"\"\n        Clear buffered data.\n\n        @return: All of the cleared buffered data.\n        @rtype: C{bytes}\n        \"\"\"\n        b, self._buffer = self._buffer, b\"\"\n        return b\n\n    def dataReceived(self, data):\n        \"\"\"\n        Protocol.dataReceived.\n        Translates bytes into lines, and calls lineReceived (or\n        rawDataReceived, depending on mode.)\n        \"\"\"\n        if self._busyReceiving:\n            self._buffer += data\n            return\n\n        try:\n            self._busyReceiving = True\n            self._buffer += data\n            while self._buffer and not self.paused:\n                if self.line_mode:\n                    try:\n                        line, self._buffer = self._buffer.split(self.delimiter, 1)\n                    except ValueError:\n                        if len(self._buffer) >= (self.MAX_LENGTH + len(self.delimiter)):\n                            line, self._buffer = self._buffer, b\"\"\n                            return self.lineLengthExceeded(line)\n                        return\n                    else:\n                        lineLength = len(line)\n                        if lineLength > self.MAX_LENGTH:\n                            exceeded = line + self.delimiter + self._buffer\n                            self._buffer = b\"\"\n                            return self.lineLengthExceeded(exceeded)\n                        why = self.lineReceived(line)\n                        if why or self.transport and self.transport.disconnecting:\n                            return why\n                else:\n                    data = self._buffer\n                    self._buffer = b\"\"\n                    why = self.rawDataReceived(data)\n                    if why:\n                        return why\n        finally:\n            self._busyReceiving = False\n\n    def setLineMode(self, extra=b\"\"):\n        \"\"\"\n        Sets the line-mode of this receiver.\n\n        If you are calling this from a rawDataReceived callback,\n        you can pass in extra unhandled data, and that data will\n        be parsed for lines.  Further data received will be sent\n        to lineReceived rather than rawDataReceived.\n\n        Do not pass extra data if calling this function from\n        within a lineReceived callback.\n        \"\"\"\n        self.line_mode = 1\n        if extra:\n            return self.dataReceived(extra)\n\n    def setRawMode(self):\n        \"\"\"\n        Sets the raw mode of this receiver.\n        Further data received will be sent to rawDataReceived rather\n        than lineReceived.\n        \"\"\"\n        self.line_mode = 0\n\n    def rawDataReceived(self, data):\n        \"\"\"\n        Override this for when raw data is received.\n        \"\"\"\n        raise NotImplementedError\n\n    def lineReceived(self, line):\n        \"\"\"\n        Override this for when each line is received.\n\n        @param line: The line which was received with the delimiter removed.\n        @type line: C{bytes}\n        \"\"\"\n        raise NotImplementedError\n\n    def sendLine(self, line):\n        \"\"\"\n        Sends a line to the other end of the connection.\n\n        @param line: The line to send, not including the delimiter.\n        @type line: C{bytes}\n        \"\"\"\n        return self.transport.write(line + self.delimiter)\n\n    def lineLengthExceeded(self, line):\n        \"\"\"\n        Called when the maximum line length has been reached.\n        Override if it needs to be dealt with in some special way.\n\n        The argument 'line' contains the remainder of the buffer, starting\n        with (at least some part) of the line which is too long. This may\n        be more than one line, or may be only the initial portion of the\n        line.\n        \"\"\"\n        return self.transport.loseConnection()\n\n\nclass StringTooLongError(AssertionError):\n    \"\"\"\n    Raised when trying to send a string too long for a length prefixed\n    protocol.\n    \"\"\"\n\n\nclass _RecvdCompatHack:\n    \"\"\"\n    Emulates the to-be-deprecated C{IntNStringReceiver.recvd} attribute.\n\n    The C{recvd} attribute was where the working buffer for buffering and\n    parsing netstrings was kept.  It was updated each time new data arrived and\n    each time some of that data was parsed and delivered to application code.\n    The piecemeal updates to its string value were expensive and have been\n    removed from C{IntNStringReceiver} in the normal case.  However, for\n    applications directly reading this attribute, this descriptor restores that\n    behavior.  It only copies the working buffer when necessary (ie, when\n    accessed).  This avoids the cost for applications not using the data.\n\n    This is a custom descriptor rather than a property, because we still need\n    the default __set__ behavior in both new-style and old-style subclasses.\n    \"\"\"\n\n    def __get__(self, oself, type=None):\n        return oself._unprocessed[oself._compatibilityOffset :]\n\n\nclass IntNStringReceiver(protocol.Protocol, _PauseableMixin):\n    \"\"\"\n    Generic class for length prefixed protocols.\n\n    @ivar _unprocessed: bytes received, but not yet broken up into messages /\n        sent to stringReceived.  _compatibilityOffset must be updated when this\n        value is updated so that the C{recvd} attribute can be generated\n        correctly.\n    @type _unprocessed: C{bytes}\n\n    @ivar structFormat: format used for struct packing/unpacking. Define it in\n        subclass.\n    @type structFormat: C{str}\n\n    @ivar prefixLength: length of the prefix, in bytes. Define it in subclass,\n        using C{struct.calcsize(structFormat)}\n    @type prefixLength: C{int}\n\n    @ivar _compatibilityOffset: the offset within C{_unprocessed} to the next\n        message to be parsed. (used to generate the recvd attribute)\n    @type _compatibilityOffset: C{int}\n    \"\"\"\n\n    MAX_LENGTH = 99999\n    _unprocessed = b\"\"\n    _compatibilityOffset = 0\n\n    # Backwards compatibility support for applications which directly touch the\n    # \"internal\" parse buffer.\n    recvd = _RecvdCompatHack()\n\n    def stringReceived(self, string):\n        \"\"\"\n        Override this for notification when each complete string is received.\n\n        @param string: The complete string which was received with all\n            framing (length prefix, etc) removed.\n        @type string: C{bytes}\n        \"\"\"\n        raise NotImplementedError\n\n    def lengthLimitExceeded(self, length):\n        \"\"\"\n        Callback invoked when a length prefix greater than C{MAX_LENGTH} is\n        received.  The default implementation disconnects the transport.\n        Override this.\n\n        @param length: The length prefix which was received.\n        @type length: C{int}\n        \"\"\"\n        self.transport.loseConnection()\n\n    def dataReceived(self, data):\n        \"\"\"\n        Convert int prefixed strings into calls to stringReceived.\n        \"\"\"\n        # Try to minimize string copying (via slices) by keeping one buffer\n        # containing all the data we have so far and a separate offset into that\n        # buffer.\n        alldata = self._unprocessed + data\n        currentOffset = 0\n        prefixLength = self.prefixLength\n        fmt = self.structFormat\n        self._unprocessed = alldata\n\n        while len(alldata) >= (currentOffset + prefixLength) and not self.paused:\n            messageStart = currentOffset + prefixLength\n            (length,) = unpack(fmt, alldata[currentOffset:messageStart])\n            if length > self.MAX_LENGTH:\n                self._unprocessed = alldata\n                self._compatibilityOffset = currentOffset\n                self.lengthLimitExceeded(length)\n                return\n            messageEnd = messageStart + length\n            if len(alldata) < messageEnd:\n                break\n\n            # Here we have to slice the working buffer so we can send just the\n            # netstring into the stringReceived callback.\n            packet = alldata[messageStart:messageEnd]\n            currentOffset = messageEnd\n            self._compatibilityOffset = currentOffset\n            self.stringReceived(packet)\n\n            # Check to see if the backwards compat \"recvd\" attribute got written\n            # to by application code.  If so, drop the current data buffer and\n            # switch to the new buffer given by that attribute's value.\n            if \"recvd\" in self.__dict__:\n                alldata = self.__dict__.pop(\"recvd\")\n                self._unprocessed = alldata\n                self._compatibilityOffset = currentOffset = 0\n                if alldata:\n                    continue\n                return\n\n        # Slice off all the data that has been processed, avoiding holding onto\n        # memory to store it, and update the compatibility attributes to reflect\n        # that change.\n        self._unprocessed = alldata[currentOffset:]\n        self._compatibilityOffset = 0\n\n    def sendString(self, string):\n        \"\"\"\n        Send a prefixed string to the other end of the connection.\n\n        @param string: The string to send.  The necessary framing (length\n            prefix, etc) will be added.\n        @type string: C{bytes}\n        \"\"\"\n        if len(string) >= 2 ** (8 * self.prefixLength):\n            raise StringTooLongError(\n                \"Try to send %s bytes whereas maximum is %s\"\n                % (len(string), 2 ** (8 * self.prefixLength))\n            )\n        self.transport.write(pack(self.structFormat, len(string)) + string)\n\n\nclass Int32StringReceiver(IntNStringReceiver):\n    \"\"\"\n    A receiver for int32-prefixed strings.\n\n    An int32 string is a string prefixed by 4 bytes, the 32-bit length of\n    the string encoded in network byte order.\n\n    This class publishes the same interface as NetstringReceiver.\n    \"\"\"\n\n    structFormat = \"!I\"\n    prefixLength = calcsize(structFormat)\n\n\nclass Int16StringReceiver(IntNStringReceiver):\n    \"\"\"\n    A receiver for int16-prefixed strings.\n\n    An int16 string is a string prefixed by 2 bytes, the 16-bit length of\n    the string encoded in network byte order.\n\n    This class publishes the same interface as NetstringReceiver.\n    \"\"\"\n\n    structFormat = \"!H\"\n    prefixLength = calcsize(structFormat)\n\n\nclass Int8StringReceiver(IntNStringReceiver):\n    \"\"\"\n    A receiver for int8-prefixed strings.\n\n    An int8 string is a string prefixed by 1 byte, the 8-bit length of\n    the string.\n\n    This class publishes the same interface as NetstringReceiver.\n    \"\"\"\n\n    structFormat = \"!B\"\n    prefixLength = calcsize(structFormat)\n\n\nclass StatefulStringProtocol:\n    \"\"\"\n    A stateful string protocol.\n\n    This is a mixin for string protocols (L{Int32StringReceiver},\n    L{NetstringReceiver}) which translates L{stringReceived} into a callback\n    (prefixed with C{'proto_'}) depending on state.\n\n    The state C{'done'} is special; if a C{proto_*} method returns it, the\n    connection will be closed immediately.\n\n    @ivar state: Current state of the protocol. Defaults to C{'init'}.\n    @type state: C{str}\n    \"\"\"\n\n    state = \"init\"\n\n    def stringReceived(self, string):\n        \"\"\"\n        Choose a protocol phase function and call it.\n\n        Call back to the appropriate protocol phase; this begins with\n        the function C{proto_init} and moves on to C{proto_*} depending on\n        what each C{proto_*} function returns.  (For example, if\n        C{self.proto_init} returns 'foo', then C{self.proto_foo} will be the\n        next function called when a protocol message is received.\n        \"\"\"\n        try:\n            pto = \"proto_\" + self.state\n            statehandler = getattr(self, pto)\n        except AttributeError:\n            log.msg(\"callback\", self.state, \"not found\")\n        else:\n            self.state = statehandler(string)\n            if self.state == \"done\":\n                self.transport.loseConnection()\n\n\n@implementer(interfaces.IProducer)\nclass FileSender:\n    \"\"\"\n    A producer that sends the contents of a file to a consumer.\n\n    This is a helper for protocols that, at some point, will take a\n    file-like object, read its contents, and write them out to the network,\n    optionally performing some transformation on the bytes in between.\n    \"\"\"\n\n    CHUNK_SIZE = 2**14\n\n    lastSent = \"\"\n    deferred = None\n\n    def beginFileTransfer(self, file, consumer, transform=None):\n        \"\"\"\n        Begin transferring a file\n\n        @type file: Any file-like object\n        @param file: The file object to read data from\n\n        @type consumer: Any implementor of IConsumer\n        @param consumer: The object to write data to\n\n        @param transform: A callable taking one string argument and returning\n        the same.  All bytes read from the file are passed through this before\n        being written to the consumer.\n\n        @rtype: C{Deferred}\n        @return: A deferred whose callback will be invoked when the file has\n        been completely written to the consumer. The last byte written to the\n        consumer is passed to the callback.\n        \"\"\"\n        self.file = file\n        self.consumer = consumer\n        self.transform = transform\n\n        self.deferred = deferred = defer.Deferred()\n        self.consumer.registerProducer(self, False)\n        return deferred\n\n    def resumeProducing(self):\n        chunk = \"\"\n        if self.file:\n            chunk = self.file.read(self.CHUNK_SIZE)\n        if not chunk:\n            self.file = None\n            self.consumer.unregisterProducer()\n            if self.deferred:\n                self.deferred.callback(self.lastSent)\n                self.deferred = None\n            return\n\n        if self.transform:\n            chunk = self.transform(chunk)\n        self.consumer.write(chunk)\n        self.lastSent = chunk[-1:]\n\n    def pauseProducing(self):\n        pass\n\n    def stopProducing(self):\n        if self.deferred:\n            self.deferred.errback(Exception(\"Consumer asked us to stop producing\"))\n            self.deferred = None\n\n\n### Dependency File: compat.py\n# -*- test-case-name: twisted.test.test_compat -*-\n#\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nCompatibility module to provide backwards compatibility for useful Python\nfeatures.\n\nThis is mainly for use of internal Twisted code. We encourage you to use\nthe latest version of Python directly from your code, if possible.\n\n@var unicode: The type of Unicode strings, C{unicode} on Python 2 and C{str}\n    on Python 3.\n\n@var NativeStringIO: An in-memory file-like object that operates on the native\n    string type (bytes in Python 2, unicode in Python 3).\n\n@var urllib_parse: a URL-parsing module (urlparse on Python 2, urllib.parse on\n    Python 3)\n\"\"\"\n\n\nimport inspect\nimport os\nimport platform\nimport socket\nimport urllib.parse as urllib_parse\nfrom collections.abc import Sequence\nfrom functools import reduce\nfrom html import escape\nfrom http import cookiejar as cookielib\nfrom io import IOBase, StringIO as NativeStringIO, TextIOBase\nfrom sys import intern\nfrom types import FrameType, MethodType as _MethodType\nfrom typing import Any, AnyStr, cast\nfrom urllib.parse import quote as urlquote, unquote as urlunquote\n\nfrom incremental import Version\n\nfrom twisted.python.deprecate import deprecated, deprecatedModuleAttribute\n\nif platform.python_implementation() == \"PyPy\":\n    _PYPY = True\nelse:\n    _PYPY = False\n\nFileType = IOBase\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for io.IOBase\",\n    __name__,\n    \"FileType\",\n)\n\nfrozenset = frozenset\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for frozenset builtin type\",\n    __name__,\n    \"frozenset\",\n)\n\nInstanceType = object\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Old-style classes don't exist in Python 3\",\n    __name__,\n    \"InstanceType\",\n)\n\nizip = zip\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for zip() builtin\",\n    __name__,\n    \"izip\",\n)\n\nlong = int\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for int builtin type\",\n    __name__,\n    \"long\",\n)\n\nrange = range\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for range() builtin\",\n    __name__,\n    \"range\",\n)\n\nraw_input = input\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for input() builtin\",\n    __name__,\n    \"raw_input\",\n)\n\nset = set\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for set builtin type\",\n    __name__,\n    \"set\",\n)\n\nStringType = str\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for str builtin type\",\n    __name__,\n    \"StringType\",\n)\n\nunichr = chr\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for chr() builtin\",\n    __name__,\n    \"unichr\",\n)\n\nunicode = str\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for str builtin type\",\n    __name__,\n    \"unicode\",\n)\n\nxrange = range\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for range() builtin\",\n    __name__,\n    \"xrange\",\n)\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"d.items()\")\ndef iteritems(d):\n    \"\"\"\n    Return an iterable of the items of C{d}.\n\n    @type d: L{dict}\n    @rtype: iterable\n    \"\"\"\n    return d.items()\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"d.values()\")\ndef itervalues(d):\n    \"\"\"\n    Return an iterable of the values of C{d}.\n\n    @type d: L{dict}\n    @rtype: iterable\n    \"\"\"\n    return d.values()\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"list(d.items())\")\ndef items(d):\n    \"\"\"\n    Return a list of the items of C{d}.\n\n    @type d: L{dict}\n    @rtype: L{list}\n    \"\"\"\n    return list(d.items())\n\n\ndef currentframe(n: int = 0) -> FrameType:\n    \"\"\"\n    In Python 3, L{inspect.currentframe} does not take a stack-level argument.\n    Restore that functionality from Python 2 so we don't have to re-implement\n    the C{f_back}-walking loop in places where it's called.\n\n    @param n: The number of stack levels above the caller to walk.\n\n    @return: a frame, n levels up the stack from the caller.\n    \"\"\"\n    f = inspect.currentframe()\n    for x in range(n + 1):\n        assert f is not None\n        f = f.f_back\n    assert f is not None\n    return f\n\n\ndef execfile(filename, globals, locals=None):\n    \"\"\"\n    Execute a Python script in the given namespaces.\n\n    Similar to the execfile builtin, but a namespace is mandatory, partly\n    because that's a sensible thing to require, and because otherwise we'd\n    have to do some frame hacking.\n\n    This is a compatibility implementation for Python 3 porting, to avoid the\n    use of the deprecated builtin C{execfile} function.\n    \"\"\"\n    if locals is None:\n        locals = globals\n    with open(filename, \"rb\") as fin:\n        source = fin.read()\n    code = compile(source, filename, \"exec\")\n    exec(code, globals, locals)\n\n\n# type note: Can't find a Comparable type, despite\n# https://github.com/python/typing/issues/59\ndef cmp(a: object, b: object) -> int:\n    \"\"\"\n    Compare two objects.\n\n    Returns a negative number if C{a < b}, zero if they are equal, and a\n    positive number if C{a > b}.\n    \"\"\"\n    if a < b:  # type: ignore[operator]\n        return -1\n    elif a == b:\n        return 0\n    else:\n        return 1\n\n\ndef comparable(klass):\n    \"\"\"\n    Class decorator that ensures support for the special C{__cmp__} method.\n\n    C{__eq__}, C{__lt__}, etc. methods are added to the class, relying on\n    C{__cmp__} to implement their comparisons.\n    \"\"\"\n\n    def __eq__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c == 0\n\n    def __ne__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c != 0\n\n    def __lt__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c < 0\n\n    def __le__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c <= 0\n\n    def __gt__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c > 0\n\n    def __ge__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c >= 0\n\n    klass.__lt__ = __lt__\n    klass.__gt__ = __gt__\n    klass.__le__ = __le__\n    klass.__ge__ = __ge__\n    klass.__eq__ = __eq__\n    klass.__ne__ = __ne__\n    return klass\n\n\ndef ioType(fileIshObject, default=str):\n    \"\"\"\n    Determine the type which will be returned from the given file object's\n    read() and accepted by its write() method as an argument.\n\n    In other words, determine whether the given file is 'opened in text mode'.\n\n    @param fileIshObject: Any object, but ideally one which resembles a file.\n    @type fileIshObject: L{object}\n\n    @param default: A default value to return when the type of C{fileIshObject}\n        cannot be determined.\n    @type default: L{type}\n\n    @return: There are 3 possible return values:\n\n            1. L{str}, if the file is unambiguously opened in text mode.\n\n            2. L{bytes}, if the file is unambiguously opened in binary mode.\n\n            3. The C{default} parameter, if the given type is not understood.\n\n    @rtype: L{type}\n    \"\"\"\n    if isinstance(fileIshObject, TextIOBase):\n        # If it's for text I/O, then it's for text I/O.\n        return str\n    if isinstance(fileIshObject, IOBase):\n        # If it's for I/O but it's _not_ for text I/O, it's for bytes I/O.\n        return bytes\n    encoding = getattr(fileIshObject, \"encoding\", None)\n    import codecs\n\n    if isinstance(fileIshObject, (codecs.StreamReader, codecs.StreamWriter)):\n        # On StreamReaderWriter, the 'encoding' attribute has special meaning;\n        # it is unambiguously text.\n        if encoding:\n            return str\n        else:\n            return bytes\n    return default\n\n\ndef nativeString(s: AnyStr) -> str:\n    \"\"\"\n    Convert C{bytes} or C{str} to C{str} type, using ASCII encoding if\n    conversion is necessary.\n\n    @raise UnicodeError: The input string is not ASCII encodable/decodable.\n    @raise TypeError: The input is neither C{bytes} nor C{str}.\n    \"\"\"\n    if not isinstance(s, (bytes, str)):\n        raise TypeError(\"%r is neither bytes nor str\" % s)\n    if isinstance(s, bytes):\n        return s.decode(\"ascii\")\n    else:\n        # Ensure we're limited to ASCII subset:\n        s.encode(\"ascii\")\n    return s\n\n\ndef _matchingString(constantString, inputString):\n    \"\"\"\n    Some functions, such as C{os.path.join}, operate on string arguments which\n    may be bytes or text, and wish to return a value of the same type.  In\n    those cases you may wish to have a string constant (in the case of\n    C{os.path.join}, that constant would be C{os.path.sep}) involved in the\n    parsing or processing, that must be of a matching type in order to use\n    string operations on it.  L{_matchingString} will take a constant string\n    (either L{bytes} or L{str}) and convert it to the same type as the\n    input string.  C{constantString} should contain only characters from ASCII;\n    to ensure this, it will be encoded or decoded regardless.\n\n    @param constantString: A string literal used in processing.\n    @type constantString: L{str} or L{bytes}\n\n    @param inputString: A byte string or text string provided by the user.\n    @type inputString: L{str} or L{bytes}\n\n    @return: C{constantString} converted into the same type as C{inputString}\n    @rtype: the type of C{inputString}\n    \"\"\"\n    if isinstance(constantString, bytes):\n        otherType = constantString.decode(\"ascii\")\n    else:\n        otherType = constantString.encode(\"ascii\")\n    if type(constantString) == type(inputString):\n        return constantString\n    else:\n        return otherType\n\n\n@deprecated(\n    Version(\"Twisted\", 21, 2, 0),\n    replacement=\"raise exception.with_traceback(traceback)\",\n)\ndef reraise(exception, traceback):\n    \"\"\"\n    Re-raise an exception, with an optional traceback.\n\n    Re-raised exceptions will be mutated, with their C{__traceback__} attribute\n    being set.\n\n    @param exception: The exception instance.\n    @param traceback: The traceback to use, or L{None} indicating a new\n    traceback.\n    \"\"\"\n    raise exception.with_traceback(traceback)\n\n\ndef iterbytes(originalBytes):\n    \"\"\"\n    Return an iterable wrapper for a C{bytes} object that provides the behavior\n    of iterating over C{bytes} on Python 2.\n\n    In particular, the results of iteration are the individual bytes (rather\n    than integers as on Python 3).\n\n    @param originalBytes: A C{bytes} object that will be wrapped.\n    \"\"\"\n    for i in range(len(originalBytes)):\n        yield originalBytes[i : i + 1]\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"b'%d'\")\ndef intToBytes(i: int) -> bytes:\n    \"\"\"\n    Convert the given integer into C{bytes}, as ASCII-encoded Arab numeral.\n\n    @param i: The C{int} to convert to C{bytes}.\n    @rtype: C{bytes}\n    \"\"\"\n    return b\"%d\" % (i,)\n\n\ndef lazyByteSlice(object, offset=0, size=None):\n    \"\"\"\n    Return a memory view of the given bytes-like object.\n\n    If an offset is given, the view starts at that offset. If a size is\n    given, the view will only be of that length.\n\n    @param object: C{bytes} to be sliced.\n\n    @param offset: C{int}, starting index of view.\n\n    @param size: Optional, if an C{int} is given limit the length of the view\n        to this size.\n    \"\"\"\n    view = memoryview(object)\n    if size is None:\n        return view[offset:]\n    else:\n        return view[offset : (offset + size)]\n\n\ndef networkString(s: str) -> bytes:\n    \"\"\"\n    Convert a string to L{bytes} using ASCII encoding.\n\n    This is useful for sending text-like bytes that are constructed using\n    string interpolation.  For example::\n\n        networkString(\"Hello %d\" % (n,))\n\n    @param s: A string to convert to bytes.\n    @type s: L{str}\n\n    @raise UnicodeError: The input string is not ASCII encodable.\n    @raise TypeError: The input is not L{str}.\n\n    @rtype: L{bytes}\n    \"\"\"\n    if not isinstance(s, str):\n        raise TypeError(\"Can only convert strings to bytes\")\n    return s.encode(\"ascii\")\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"os.environb\")\ndef bytesEnviron():\n    \"\"\"\n    Return a L{dict} of L{os.environ} where all text-strings are encoded into\n    L{bytes}.\n\n    This function is POSIX only; environment variables are always text strings\n    on Windows.\n    \"\"\"\n    encodekey = os.environ.encodekey\n    encodevalue = os.environ.encodevalue\n\n    return {encodekey(x): encodevalue(y) for x, y in os.environ.items()}\n\n\ndef _constructMethod(cls, name, self):\n    \"\"\"\n    Construct a bound method.\n\n    @param cls: The class that the method should be bound to.\n    @type cls: L{type}\n\n    @param name: The name of the method.\n    @type name: native L{str}\n\n    @param self: The object that the method is bound to.\n    @type self: any object\n\n    @return: a bound method\n    @rtype: L{_MethodType}\n    \"\"\"\n    func = cls.__dict__[name]\n    return _MethodType(func, self)\n\n\ndef _pypy3BlockingHack():\n    \"\"\"\n    Work around U{https://foss.heptapod.net/pypy/pypy/-/issues/3051}\n    by replacing C{socket.fromfd} with a more conservative version.\n    \"\"\"\n    try:\n        from fcntl import F_GETFL, F_SETFL, fcntl\n    except ImportError:\n        return\n    if not _PYPY:\n        return\n\n    def fromFDWithoutModifyingFlags(fd, family, type, proto=None):\n        passproto = [proto] * (proto is not None)\n        flags = fcntl(fd, F_GETFL)\n        try:\n            return realFromFD(fd, family, type, *passproto)\n        finally:\n            fcntl(fd, F_SETFL, flags)\n\n    realFromFD = socket.fromfd\n    if realFromFD.__name__ == fromFDWithoutModifyingFlags.__name__:\n        return\n    socket.fromfd = fromFDWithoutModifyingFlags\n\n\n_pypy3BlockingHack()\n\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use functools.reduce() directly\",\n    __name__,\n    \"reduce\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use io.StringIO directly\",\n    __name__,\n    \"NativeStringIO\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Import urllib.parse directly\",\n    __name__,\n    \"urllib_parse\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0), \"Use html.escape directly\", __name__, \"escape\"\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use urllib.parse.quote() directly\",\n    __name__,\n    \"urlquote\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use urllib.parse.unquote() directly\",\n    __name__,\n    \"urlunquote\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use http.cookiejar directly\",\n    __name__,\n    \"cookielib\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0), \"Use sys.intern() directly\", __name__, \"intern\"\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use collections.abc.Sequence directly\",\n    __name__,\n    \"Sequence\",\n)\n\n\n__all__ = [\n    \"reraise\",\n    \"execfile\",\n    \"frozenset\",\n    \"reduce\",\n    \"set\",\n    \"cmp\",\n    \"comparable\",\n    \"nativeString\",\n    \"NativeStringIO\",\n    \"networkString\",\n    \"unicode\",\n    \"iterbytes\",\n    \"intToBytes\",\n    \"lazyByteSlice\",\n    \"StringType\",\n    \"InstanceType\",\n    \"FileType\",\n    \"items\",\n    \"iteritems\",\n    \"itervalues\",\n    \"range\",\n    \"xrange\",\n    \"urllib_parse\",\n    \"bytesEnviron\",\n    \"escape\",\n    \"urlquote\",\n    \"urlunquote\",\n    \"cookielib\",\n    \"intern\",\n    \"unichr\",\n    \"raw_input\",\n    \"Sequence\",\n]\n\n\n### Dependency File: defer.py\n# -*- test-case-name: twisted.test.test_defer -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nSupport for results that aren't immediately available.\n\nMaintainer: Glyph Lefkowitz\n\"\"\"\nfrom __future__ import annotations\n\nimport inspect\nimport traceback\nimport warnings\nfrom abc import ABC, abstractmethod\nfrom asyncio import AbstractEventLoop, Future, iscoroutine\nfrom contextvars import Context as _Context, copy_context as _copy_context\nfrom enum import Enum\nfrom functools import wraps\nfrom sys import exc_info, implementation\nfrom types import CoroutineType, GeneratorType, MappingProxyType, TracebackType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Awaitable,\n    Callable,\n    Coroutine,\n    Generator,\n    Generic,\n    Iterable,\n    List,\n    Mapping,\n    NoReturn,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n    cast,\n    overload,\n)\n\nimport attr\nfrom incremental import Version\nfrom typing_extensions import Concatenate, Literal, ParamSpec, Self\n\nfrom twisted.internet.interfaces import IDelayedCall, IReactorTime\nfrom twisted.logger import Logger\nfrom twisted.python import lockfile\nfrom twisted.python.compat import _PYPY, cmp, comparable\nfrom twisted.python.deprecate import deprecated, deprecatedProperty, warnAboutFunction\nfrom twisted.python.failure import Failure, _extraneous\n\nlog = Logger()\n\n\n_T = TypeVar(\"_T\")\n_P = ParamSpec(\"_P\")\n\n# See use in _inlineCallbacks for explanation and removal timeline.\n_oldPypyStack = _PYPY and implementation.version < (7, 3, 14)\n\n\nclass AlreadyCalledError(Exception):\n    \"\"\"\n    This error is raised when one of L{Deferred.callback} or L{Deferred.errback}\n    is called after one of the two had already been called.\n    \"\"\"\n\n\nclass CancelledError(Exception):\n    \"\"\"\n    This error is raised by default when a L{Deferred} is cancelled.\n    \"\"\"\n\n\nclass TimeoutError(Exception):\n    \"\"\"\n    This error is raised by default when a L{Deferred} times out.\n    \"\"\"\n\n\nclass NotACoroutineError(TypeError):\n    \"\"\"\n    This error is raised when a coroutine is expected and something else is\n    encountered.\n    \"\"\"\n\n\ndef logError(err: Failure) -> Failure:\n    \"\"\"\n    Log and return failure.\n\n    This method can be used as an errback that passes the failure on to the\n    next errback unmodified. Note that if this is the last errback, and the\n    deferred gets garbage collected after being this errback has been called,\n    the clean up code logs it again.\n    \"\"\"\n    log.failure(\"\", err)\n    return err\n\n\ndef succeed(result: _T) -> \"Deferred[_T]\":\n    \"\"\"\n    Return a L{Deferred} that has already had C{.callback(result)} called.\n\n    This is useful when you're writing synchronous code to an\n    asynchronous interface: i.e., some code is calling you expecting a\n    L{Deferred} result, but you don't actually need to do anything\n    asynchronous. Just return C{defer.succeed(theResult)}.\n\n    See L{fail} for a version of this function that uses a failing\n    L{Deferred} rather than a successful one.\n\n    @param result: The result to give to the Deferred's 'callback'\n           method.\n    \"\"\"\n    d: Deferred[_T] = Deferred()\n    # This violate abstraction boundaries, so code that is not internal to\n    # Twisted shouldn't do it, but it's a significant performance optimization:\n    d.result = result\n    d.called = True\n    d._chainedTo = None\n    return d\n\n\ndef fail(result: Optional[Union[Failure, BaseException]] = None) -> \"Deferred[Any]\":\n    \"\"\"\n    Return a L{Deferred} that has already had C{.errback(result)} called.\n\n    See L{succeed}'s docstring for rationale.\n\n    @param result: The same argument that L{Deferred.errback} takes.\n\n    @raise NoCurrentExceptionError: If C{result} is L{None} but there is no\n        current exception state.\n    \"\"\"\n    d: Deferred[Any] = Deferred()\n    d.errback(result)\n    return d\n\n\ndef execute(\n    callable: Callable[_P, _T], *args: _P.args, **kwargs: _P.kwargs\n) -> \"Deferred[_T]\":\n    \"\"\"\n    Create a L{Deferred} from a callable and arguments.\n\n    Call the given function with the given arguments.  Return a L{Deferred}\n    which has been fired with its callback as the result of that invocation\n    or its C{errback} with a L{Failure} for the exception thrown.\n    \"\"\"\n    try:\n        result = callable(*args, **kwargs)\n    except BaseException:\n        return fail()\n    else:\n        return succeed(result)\n\n\n@overload\ndef maybeDeferred(\n    f: Callable[_P, Deferred[_T]], *args: _P.args, **kwargs: _P.kwargs\n) -> \"Deferred[_T]\":\n    ...\n\n\n@overload\ndef maybeDeferred(\n    f: Callable[_P, Coroutine[Deferred[Any], Any, _T]],\n    *args: _P.args,\n    **kwargs: _P.kwargs,\n) -> \"Deferred[_T]\":\n    ...\n\n\n@overload\ndef maybeDeferred(\n    f: Callable[_P, _T], *args: _P.args, **kwargs: _P.kwargs\n) -> \"Deferred[_T]\":\n    ...\n\n\ndef maybeDeferred(\n    f: Callable[_P, Union[Deferred[_T], Coroutine[Deferred[Any], Any, _T], _T]],\n    *args: _P.args,\n    **kwargs: _P.kwargs,\n) -> \"Deferred[_T]\":\n    \"\"\"\n    Invoke a function that may or may not return a L{Deferred} or coroutine.\n\n    Call the given function with the given arguments.  Then:\n\n      - If the returned object is a L{Deferred}, return it.\n\n      - If the returned object is a L{Failure}, wrap it with L{fail} and\n        return it.\n\n      - If the returned object is a L{types.CoroutineType}, wrap it with\n        L{Deferred.fromCoroutine} and return it.\n\n      - Otherwise, wrap it in L{succeed} and return it.\n\n      - If an exception is raised, convert it to a L{Failure}, wrap it in\n        L{fail}, and then return it.\n\n    @param f: The callable to invoke\n    @param args: The arguments to pass to C{f}\n    @param kwargs: The keyword arguments to pass to C{f}\n\n    @return: The result of the function call, wrapped in a L{Deferred} if\n    necessary.\n    \"\"\"\n    try:\n        result = f(*args, **kwargs)\n    except BaseException:\n        return fail(Failure(captureVars=Deferred.debug))\n\n    if type(result) in _DEFERRED_SUBCLASSES:\n        return result  # type: ignore[return-value]\n    elif isinstance(result, Failure):\n        return fail(result)\n    elif type(result) is CoroutineType:\n        # A note on how we identify this case ...\n        #\n        # inspect.iscoroutinefunction(f) should be the simplest and easiest\n        # way to determine if we want to apply coroutine handling.  However,\n        # the value may be returned by a regular function that calls a\n        # coroutine function and returns its result.  It would be confusing if\n        # cases like this led to different handling of the coroutine (even\n        # though it is a mistake to have a regular function call a coroutine\n        # function to return its result - doing so immediately destroys a\n        # large part of the value of coroutine functions: that they can only\n        # have a coroutine result).\n        #\n        # There are many ways we could inspect ``result`` to determine if it\n        # is a \"coroutine\" but most of these are mistakes.  The goal is only\n        # to determine whether the value came from ``async def`` or not\n        # because these are the only values we're trying to handle with this\n        # case.  Such values always have exactly one type: CoroutineType.\n        return Deferred.fromCoroutine(result)\n    else:\n        returned: _T = result  # type: ignore\n        return succeed(returned)\n\n\n@deprecated(\n    Version(\"Twisted\", 17, 1, 0),\n    replacement=\"twisted.internet.defer.Deferred.addTimeout\",\n)\ndef timeout(deferred: \"Deferred[object]\") -> None:\n    deferred.errback(Failure(TimeoutError(\"Callback timed out\")))\n\n\ndef passthru(arg: _T) -> _T:\n    return arg\n\n\ndef _failthru(arg: Failure) -> Failure:\n    return arg\n\n\ndef setDebugging(on: bool) -> None:\n    \"\"\"\n    Enable or disable L{Deferred} debugging.\n\n    When debugging is on, the call stacks from creation and invocation are\n    recorded, and added to any L{AlreadyCalledError}s we raise.\n    \"\"\"\n    Deferred.debug = bool(on)\n\n\ndef getDebugging() -> bool:\n    \"\"\"\n    Determine whether L{Deferred} debugging is enabled.\n    \"\"\"\n    return Deferred.debug\n\n\ndef _cancelledToTimedOutError(value: _T, timeout: float) -> _T:\n    \"\"\"\n    A default translation function that translates L{Failure}s that are\n    L{CancelledError}s to L{TimeoutError}s.\n\n    @param value: Anything\n    @param timeout: The timeout\n\n    @raise TimeoutError: If C{value} is a L{Failure} that is a L{CancelledError}.\n    @raise Exception: If C{value} is a L{Failure} that is not a L{CancelledError},\n        it is re-raised.\n\n    @since: 16.5\n    \"\"\"\n    if isinstance(value, Failure):\n        value.trap(CancelledError)\n        raise TimeoutError(timeout, \"Deferred\")\n    return value\n\n\nclass _Sentinel(Enum):\n    \"\"\"\n    @cvar _NO_RESULT:\n        The result used to represent the fact that there is no result.\n        B{Never ever ever use this as an actual result for a Deferred}.\n        You have been warned.\n    @cvar _CONTINUE:\n        A marker left in L{Deferred.callback}s to indicate a Deferred chain.\n        Always accompanied by a Deferred instance in the args tuple pointing at\n        the Deferred which is chained to the Deferred which has this marker.\n    \"\"\"\n\n    _NO_RESULT = object()\n    _CONTINUE = object()\n\n\n# Cache these values for use without the extra lookup in deferred hot code paths\n_NO_RESULT = _Sentinel._NO_RESULT\n_CONTINUE = _Sentinel._CONTINUE\n\n\n# type note: this should be Callable[[object, ...], object] but mypy doesn't allow.\n#     Callable[[object], object] is next best, but disallows valid callback signatures\nDeferredCallback = Callable[..., object]\n# type note: this should be Callable[[Failure, ...], object] but mypy doesn't allow.\n#     Callable[[Failure], object] is next best, but disallows valid callback signatures\nDeferredErrback = Callable[..., object]\n\n_CallbackOrderedArguments = Tuple[object, ...]\n_CallbackKeywordArguments = Mapping[str, object]\n_CallbackChain = Tuple[\n    Tuple[\n        Union[DeferredCallback, Literal[_Sentinel._CONTINUE]],\n        _CallbackOrderedArguments,\n        _CallbackKeywordArguments,\n    ],\n    Tuple[\n        Union[DeferredErrback, DeferredCallback, Literal[_Sentinel._CONTINUE]],\n        _CallbackOrderedArguments,\n        _CallbackKeywordArguments,\n    ],\n]\n\n_NONE_KWARGS: _CallbackKeywordArguments = MappingProxyType({})\n\n\n_SelfResultT = TypeVar(\"_SelfResultT\")\n_NextResultT = TypeVar(\"_NextResultT\")\n\n\nclass DebugInfo:\n    \"\"\"\n    Deferred debug helper.\n    \"\"\"\n\n    failResult: Optional[Failure] = None\n    creator: Optional[List[str]] = None\n    invoker: Optional[List[str]] = None\n\n    def _getDebugTracebacks(self) -> str:\n        info = \"\"\n        if self.creator is not None:\n            info += \" C: Deferred was created:\\n C:\"\n            info += \"\".join(self.creator).rstrip().replace(\"\\n\", \"\\n C:\")\n            info += \"\\n\"\n        if self.invoker is not None:\n            info += \" I: First Invoker was:\\n I:\"\n            info += \"\".join(self.invoker).rstrip().replace(\"\\n\", \"\\n I:\")\n            info += \"\\n\"\n        return info\n\n    def __del__(self) -> None:\n        \"\"\"\n        Print tracebacks and die.\n\n        If the *last* (and I do mean *last*) callback leaves me in an error\n        state, print a traceback (if said errback is a L{Failure}).\n        \"\"\"\n        if self.failResult is not None:\n            # Note: this is two separate messages for compatibility with\n            # earlier tests; arguably it should be a single error message.\n            log.critical(\"Unhandled error in Deferred:\", isError=True)\n\n            debugInfo = self._getDebugTracebacks()\n            if debugInfo:\n                format = \"(debug: {debugInfo})\"\n            else:\n                format = \"\"\n\n            log.failure(format, self.failResult, debugInfo=debugInfo)\n\n\nclass Deferred(Awaitable[_SelfResultT]):\n    \"\"\"\n    This is a callback which will be put off until later.\n\n    Why do we want this? Well, in cases where a function in a threaded\n    program would block until it gets a result, for Twisted it should\n    not block. Instead, it should return a L{Deferred}.\n\n    This can be implemented for protocols that run over the network by\n    writing an asynchronous protocol for L{twisted.internet}. For methods\n    that come from outside packages that are not under our control, we use\n    threads (see for example L{twisted.enterprise.adbapi}).\n\n    For more information about Deferreds, see doc/core/howto/defer.html or\n    U{http://twistedmatrix.com/documents/current/core/howto/defer.html}\n\n    When creating a Deferred, you may provide a canceller function, which\n    will be called by d.cancel() to let you do any clean-up necessary if the\n    user decides not to wait for the deferred to complete.\n\n    @ivar called: A flag which is C{False} until either C{callback} or\n        C{errback} is called and afterwards always C{True}.\n    @ivar paused: A counter of how many unmatched C{pause} calls have been made\n        on this instance.\n    @ivar _suppressAlreadyCalled: A flag used by the cancellation mechanism\n        which is C{True} if the Deferred has no canceller and has been\n        cancelled, C{False} otherwise.  If C{True}, it can be expected that\n        C{callback} or C{errback} will eventually be called and the result\n        should be silently discarded.\n    @ivar _runningCallbacks: A flag which is C{True} while this instance is\n        executing its callback chain, used to stop recursive execution of\n        L{_runCallbacks}\n    @ivar _chainedTo: If this L{Deferred} is waiting for the result of another\n        L{Deferred}, this is a reference to the other Deferred.  Otherwise,\n        L{None}.\n    \"\"\"\n\n    called = False\n    paused = 0\n    _debugInfo: Optional[DebugInfo] = None\n    _suppressAlreadyCalled = False\n\n    # Are we currently running a user-installed callback?  Meant to prevent\n    # recursive running of callbacks when a reentrant call to add a callback is\n    # used.\n    _runningCallbacks = False\n\n    # Keep this class attribute for now, for compatibility with code that\n    # sets it directly.\n    debug = False\n\n    _chainedTo: \"Optional[Deferred[Any]]\" = None\n\n    def __init__(\n        self, canceller: Optional[Callable[[\"Deferred[Any]\"], None]] = None\n    ) -> None:\n        \"\"\"\n        Initialize a L{Deferred}.\n\n        @param canceller: a callable used to stop the pending operation\n            scheduled by this L{Deferred} when L{Deferred.cancel} is invoked.\n            The canceller will be passed the deferred whose cancellation is\n            requested (i.e., C{self}).\n\n            If a canceller is not given, or does not invoke its argument's\n            C{callback} or C{errback} method, L{Deferred.cancel} will\n            invoke L{Deferred.errback} with a L{CancelledError}.\n\n            Note that if a canceller is not given, C{callback} or\n            C{errback} may still be invoked exactly once, even though\n            defer.py will have already invoked C{errback}, as described\n            above.  This allows clients of code which returns a L{Deferred}\n            to cancel it without requiring the L{Deferred} instantiator to\n            provide any specific implementation support for cancellation.\n            New in 10.1.\n\n        @type canceller: a 1-argument callable which takes a L{Deferred}. The\n            return result is ignored.\n        \"\"\"\n        self._callbacks: List[_CallbackChain] = []\n        self._canceller = canceller\n        if self.debug:\n            self._debugInfo = DebugInfo()\n            self._debugInfo.creator = traceback.format_stack()[:-1]\n\n    @deprecatedProperty(Version(\"Twisted\", \"NEXT\", 0, 0))\n    def callbacks(self) -> List[_CallbackChain]:\n        return self._callbacks\n\n    def addCallbacks(\n        self,\n        callback: Union[\n            Callable[..., _NextResultT],\n            Callable[..., Deferred[_NextResultT]],\n            Callable[..., Failure],\n            Callable[\n                ...,\n                Union[_NextResultT, Deferred[_NextResultT], Failure],\n            ],\n        ],\n        errback: Union[\n            Callable[..., _NextResultT],\n            Callable[..., Deferred[_NextResultT]],\n            Callable[..., Failure],\n            Callable[\n                ...,\n                Union[_NextResultT, Deferred[_NextResultT], Failure],\n            ],\n            None,\n        ] = None,\n        callbackArgs: Tuple[Any, ...] = (),\n        callbackKeywords: Mapping[str, Any] = _NONE_KWARGS,\n        errbackArgs: _CallbackOrderedArguments = (),\n        errbackKeywords: _CallbackKeywordArguments = _NONE_KWARGS,\n    ) -> \"Deferred[_NextResultT]\":\n        \"\"\"\n        Add a pair of callbacks (success and error) to this L{Deferred}.\n\n        These will be executed when the 'master' callback is run.\n\n        @note: The signature of this function was designed many years before\n            PEP 612; ParamSpec provides no mechanism to annotate parameters\n            like C{callbackArgs}; this is therefore inherently less type-safe\n            than calling C{addCallback} and C{addErrback} separately.\n\n        @return: C{self}.\n        \"\"\"\n        if errback is None:\n            errback = _failthru\n\n        # Default value used to be None and callers may be using None\n        if callbackArgs is None:\n            callbackArgs = ()  # type: ignore[unreachable]\n        if callbackKeywords is None:\n            callbackKeywords = {}  # type: ignore[unreachable]\n        if errbackArgs is None:\n            errbackArgs = ()  # type: ignore[unreachable]\n        if errbackKeywords is None:\n            errbackKeywords = {}  # type: ignore[unreachable]\n\n        # Note that this logic is duplicated in addCallbac/addErrback/addBoth\n        # for performance reasons.\n        self._callbacks.append(\n            (\n                (callback, callbackArgs, callbackKeywords),\n                (errback, errbackArgs, errbackKeywords),\n            )\n        )\n\n        if self.called:\n            self._runCallbacks()\n\n        # type note: The Deferred's type has changed here, but *idiomatically*\n        #     the caller should treat the result as the new type, consistently.\n        return self  # type:ignore[return-value]\n\n    # BEGIN way too many @overload-s for addCallback, addErrback, and addBoth:\n    # these must be accomplished with @overloads, rather than a big Union on\n    # the result type as you might expect, because the fact that\n    # _NextResultT has no bound makes mypy get confused and require the\n    # return types of functions to be combinations of Deferred and Failure\n    # rather than the actual return type.  I'm not entirely sure what about the\n    # semantics of <nothing> create this overzealousness on the part of trying\n    # to assign a type; there *might* be a mypy bug in there somewhere.\n    # Possibly https://github.com/python/typing/issues/548 is implicated here\n    # because TypeVar for the *callable* with a variadic bound might express to\n    # Mypy the actual constraint that we want on its type.\n\n    @overload\n    def addCallback(\n        self,\n        callback: Callable[Concatenate[_SelfResultT, _P], Failure],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addCallback(\n        self,\n        callback: Callable[\n            Concatenate[_SelfResultT, _P],\n            Union[Failure, Deferred[_NextResultT]],\n        ],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addCallback(\n        self,\n        callback: Callable[Concatenate[_SelfResultT, _P], Union[Failure, _NextResultT]],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addCallback(\n        self,\n        callback: Callable[Concatenate[_SelfResultT, _P], Deferred[_NextResultT]],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addCallback(\n        self,\n        callback: Callable[\n            Concatenate[_SelfResultT, _P],\n            Union[Deferred[_NextResultT], _NextResultT],\n        ],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addCallback(\n        self,\n        callback: Callable[Concatenate[_SelfResultT, _P], _NextResultT],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    def addCallback(self, callback: Any, *args: Any, **kwargs: Any) -> \"Deferred[Any]\":\n        \"\"\"\n        Convenience method for adding just a callback.\n\n        See L{addCallbacks}.\n        \"\"\"\n        # This could be implemented as a call to addCallbacks, but doing it\n        # directly is faster.\n        self._callbacks.append(((callback, args, kwargs), (_failthru, (), {})))\n\n        if self.called:\n            self._runCallbacks()\n\n        return self\n\n    @overload\n    def addErrback(\n        self,\n        errback: Callable[Concatenate[Failure, _P], Deferred[_NextResultT]],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> \"Deferred[Union[_SelfResultT, _NextResultT]]\":\n        ...\n\n    @overload\n    def addErrback(\n        self,\n        errback: Callable[Concatenate[Failure, _P], Failure],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> \"Deferred[Union[_SelfResultT]]\":\n        ...\n\n    @overload\n    def addErrback(\n        self,\n        errback: Callable[Concatenate[Failure, _P], _NextResultT],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> \"Deferred[Union[_SelfResultT, _NextResultT]]\":\n        ...\n\n    def addErrback(self, errback: Any, *args: Any, **kwargs: Any) -> \"Deferred[Any]\":\n        \"\"\"\n        Convenience method for adding just an errback.\n\n        See L{addCallbacks}.\n        \"\"\"\n        # This could be implemented as a call to addCallbacks, but doing it\n        # directly is faster.\n        self._callbacks.append(((passthru, (), {}), (errback, args, kwargs)))\n\n        if self.called:\n            self._runCallbacks()\n\n        return self\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[Concatenate[Union[_SelfResultT, Failure], _P], Failure],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[\n            Concatenate[Union[_SelfResultT, Failure], _P],\n            Union[Failure, Deferred[_NextResultT]],\n        ],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[\n            Concatenate[Union[_SelfResultT, Failure], _P], Union[Failure, _NextResultT]\n        ],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[\n            Concatenate[Union[_SelfResultT, Failure], _P], Deferred[_NextResultT]\n        ],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[\n            Concatenate[Union[_SelfResultT, Failure], _P],\n            Union[Deferred[_NextResultT], _NextResultT],\n        ],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[Concatenate[Union[_SelfResultT, Failure], _P], _NextResultT],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_NextResultT]:\n        ...\n\n    @overload\n    def addBoth(\n        self,\n        callback: Callable[Concatenate[_T, _P], _T],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_SelfResultT]:\n        ...\n\n    def addBoth(self, callback: Any, *args: Any, **kwargs: Any) -> \"Deferred[Any]\":\n        \"\"\"\n        Convenience method for adding a single callable as both a callback\n        and an errback.\n\n        See L{addCallbacks}.\n        \"\"\"\n        # This could be implemented as a call to addCallbacks, but doing it\n        # directly is faster.\n        call = (callback, args, kwargs)\n        self._callbacks.append((call, call))\n\n        if self.called:\n            self._runCallbacks()\n\n        return self\n\n    # END way too many overloads\n\n    def addTimeout(\n        self,\n        timeout: float,\n        clock: IReactorTime,\n        onTimeoutCancel: Optional[\n            Callable[\n                [Union[_SelfResultT, Failure], float],\n                Union[_NextResultT, Failure],\n            ]\n        ] = None,\n    ) -> \"Deferred[Union[_SelfResultT, _NextResultT]]\":\n        \"\"\"\n        Time out this L{Deferred} by scheduling it to be cancelled after\n        C{timeout} seconds.\n\n        The timeout encompasses all the callbacks and errbacks added to this\n        L{defer.Deferred} before the call to L{addTimeout}, and none added\n        after the call.\n\n        If this L{Deferred} gets timed out, it errbacks with a L{TimeoutError},\n        unless a cancelable function was passed to its initialization or unless\n        a different C{onTimeoutCancel} callable is provided.\n\n        @param timeout: number of seconds to wait before timing out this\n            L{Deferred}\n        @param clock: The object which will be used to schedule the timeout.\n        @param onTimeoutCancel: A callable which is called immediately after\n            this L{Deferred} times out, and not if this L{Deferred} is\n            otherwise cancelled before the timeout. It takes an arbitrary\n            value, which is the value of this L{Deferred} at that exact point\n            in time (probably a L{CancelledError} L{Failure}), and the\n            C{timeout}.  The default callable (if C{None} is provided) will\n            translate a L{CancelledError} L{Failure} into a L{TimeoutError}.\n\n        @return: C{self}.\n\n        @since: 16.5\n        \"\"\"\n\n        timedOut = [False]\n\n        def timeItOut() -> None:\n            timedOut[0] = True\n            self.cancel()\n\n        delayedCall = clock.callLater(timeout, timeItOut)\n\n        def convertCancelled(\n            result: Union[_SelfResultT, Failure],\n        ) -> Union[_SelfResultT, _NextResultT, Failure]:\n            # if C{deferred} was timed out, call the translation function,\n            # if provided, otherwise just use L{cancelledToTimedOutError}\n            if timedOut[0]:\n                toCall = onTimeoutCancel or _cancelledToTimedOutError\n                return toCall(result, timeout)\n            return result\n\n        def cancelTimeout(result: _T) -> _T:\n            # stop the pending call to cancel the deferred if it's been fired\n            if delayedCall.active():\n                delayedCall.cancel()\n            return result\n\n        # Note: Mypy cannot infer this type, apparently thanks to the ambiguity\n        # of _SelfResultT / _NextResultT both being unbound.  Explicitly\n        # annotating it seems to do the trick though.\n        converted: Deferred[Union[_SelfResultT, _NextResultT]] = self.addBoth(\n            convertCancelled\n        )\n        return converted.addBoth(cancelTimeout)\n\n    def chainDeferred(self, d: \"Deferred[_SelfResultT]\") -> \"Deferred[None]\":\n        \"\"\"\n        Chain another L{Deferred} to this L{Deferred}.\n\n        This method adds callbacks to this L{Deferred} to call C{d}'s callback\n        or errback, as appropriate. It is merely a shorthand way of performing\n        the following::\n\n            d1.addCallbacks(d2.callback, d2.errback)\n\n        When you chain a deferred C{d2} to another deferred C{d1} with\n        C{d1.chainDeferred(d2)}, you are making C{d2} participate in the\n        callback chain of C{d1}.\n        Thus any event that fires C{d1} will also fire C{d2}.\n        However, the converse is B{not} true; if C{d2} is fired, C{d1} will not\n        be affected.\n\n        Note that unlike the case where chaining is caused by a L{Deferred}\n        being returned from a callback, it is possible to cause the call\n        stack size limit to be exceeded by chaining many L{Deferred}s\n        together with C{chainDeferred}.\n\n        @return: C{self}.\n        \"\"\"\n        d._chainedTo = self\n        return self.addCallbacks(d.callback, d.errback)\n\n    def callback(self, result: Union[_SelfResultT, Failure]) -> None:\n        \"\"\"\n        Run all success callbacks that have been added to this L{Deferred}.\n\n        Each callback will have its result passed as the first argument to\n        the next; this way, the callbacks act as a 'processing chain'.  If\n        the success-callback returns a L{Failure} or raises an L{Exception},\n        processing will continue on the *error* callback chain.  If a\n        callback (or errback) returns another L{Deferred}, this L{Deferred}\n        will be chained to it (and further callbacks will not run until that\n        L{Deferred} has a result).\n\n        An instance of L{Deferred} may only have either L{callback} or\n        L{errback} called on it, and only once.\n\n        @param result: The object which will be passed to the first callback\n            added to this L{Deferred} (via L{addCallback}), unless C{result} is\n            a L{Failure}, in which case the behavior is the same as calling\n            C{errback(result)}.\n\n        @raise AlreadyCalledError: If L{callback} or L{errback} has already been\n            called on this L{Deferred}.\n        \"\"\"\n        self._startRunCallbacks(result)\n\n    def errback(self, fail: Optional[Union[Failure, BaseException]] = None) -> None:\n        \"\"\"\n        Run all error callbacks that have been added to this L{Deferred}.\n\n        Each callback will have its result passed as the first\n        argument to the next; this way, the callbacks act as a\n        'processing chain'. Also, if the error-callback returns a non-Failure\n        or doesn't raise an L{Exception}, processing will continue on the\n        *success*-callback chain.\n\n        If the argument that's passed to me is not a L{Failure} instance,\n        it will be embedded in one. If no argument is passed, a\n        L{Failure} instance will be created based on the current\n        traceback stack.\n\n        Passing a string as `fail' is deprecated, and will be punished with\n        a warning message.\n\n        An instance of L{Deferred} may only have either L{callback} or\n        L{errback} called on it, and only once.\n\n        @param fail: The L{Failure} object which will be passed to the first\n            errback added to this L{Deferred} (via L{addErrback}).\n            Alternatively, a L{Exception} instance from which a L{Failure} will\n            be constructed (with no traceback) or L{None} to create a L{Failure}\n            instance from the current exception state (with a traceback).\n\n        @raise AlreadyCalledError: If L{callback} or L{errback} has already been\n            called on this L{Deferred}.\n        @raise NoCurrentExceptionError: If C{fail} is L{None} but there is\n            no current exception state.\n        \"\"\"\n        if fail is None:\n            fail = Failure(captureVars=self.debug)\n        elif not isinstance(fail, Failure):\n            fail = Failure(fail)\n\n        self._startRunCallbacks(fail)\n\n    def pause(self) -> None:\n        \"\"\"\n        Stop processing on a L{Deferred} until L{unpause}() is called.\n        \"\"\"\n        self.paused += 1\n\n    def unpause(self) -> None:\n        \"\"\"\n        Process all callbacks made since L{pause}() was called.\n        \"\"\"\n        self.paused -= 1\n        if self.paused:\n            return\n        if self.called:\n            self._runCallbacks()\n\n    def cancel(self) -> None:\n        \"\"\"\n        Cancel this L{Deferred}.\n\n        If the L{Deferred} has not yet had its C{errback} or C{callback} method\n        invoked, call the canceller function provided to the constructor. If\n        that function does not invoke C{callback} or C{errback}, or if no\n        canceller function was provided, errback with L{CancelledError}.\n\n        If this L{Deferred} is waiting on another L{Deferred}, forward the\n        cancellation to the other L{Deferred}.\n        \"\"\"\n        if not self.called:\n            canceller = self._canceller\n            if canceller:\n                canceller(self)\n            else:\n                # Arrange to eat the callback that will eventually be fired\n                # since there was no real canceller.\n                self._suppressAlreadyCalled = True\n            if not self.called:\n                # There was no canceller, or the canceller didn't call\n                # callback or errback.\n                self.errback(Failure(CancelledError()))\n        elif isinstance(self.result, Deferred):\n            # Waiting for another deferred -- cancel it instead.\n            self.result.cancel()\n\n    def _startRunCallbacks(self, result: object) -> None:\n        if self.called:\n            if self._suppressAlreadyCalled:\n                self._suppressAlreadyCalled = False\n                return\n            if self.debug:\n                if self._debugInfo is None:\n                    self._debugInfo = DebugInfo()\n                extra = \"\\n\" + self._debugInfo._getDebugTracebacks()\n                raise AlreadyCalledError(extra)\n            raise AlreadyCalledError\n        if self.debug:\n            if self._debugInfo is None:\n                self._debugInfo = DebugInfo()\n            self._debugInfo.invoker = traceback.format_stack()[:-2]\n        self.called = True\n\n        # Clear the canceller to avoid any circular references. This is safe to\n        # do as the canceller does not get called after the deferred has fired\n        self._canceller = None\n\n        self.result = result\n        self._runCallbacks()\n\n    def _continuation(self) -> _CallbackChain:\n        \"\"\"\n        Build a tuple of callback and errback with L{_Sentinel._CONTINUE}.\n        \"\"\"\n        triple = (_CONTINUE, (self,), _NONE_KWARGS)\n        return (triple, triple)  # type: ignore[return-value]\n\n    def _runCallbacks(self) -> None:\n        \"\"\"\n        Run the chain of callbacks once a result is available.\n\n        This consists of a simple loop over all of the callbacks, calling each\n        with the current result and making the current result equal to the\n        return value (or raised exception) of that call.\n\n        If L{_runningCallbacks} is true, this loop won't run at all, since\n        it is already running above us on the call stack.  If C{self.paused} is\n        true, the loop also won't run, because that's what it means to be\n        paused.\n\n        The loop will terminate before processing all of the callbacks if a\n        L{Deferred} without a result is encountered.\n\n        If a L{Deferred} I{with} a result is encountered, that result is taken\n        and the loop proceeds.\n\n        @note: The implementation is complicated slightly by the fact that\n            chaining (associating two L{Deferred}s with each other such that one\n            will wait for the result of the other, as happens when a Deferred is\n            returned from a callback on another L{Deferred}) is supported\n            iteratively rather than recursively, to avoid running out of stack\n            frames when processing long chains.\n        \"\"\"\n        if self._runningCallbacks:\n            # Don't recursively run callbacks\n            return\n\n        # Keep track of all the Deferreds encountered while propagating results\n        # up a chain.  The way a Deferred gets onto this stack is by having\n        # added its _continuation() to the callbacks list of a second Deferred\n        # and then that second Deferred being fired.  ie, if ever had _chainedTo\n        # set to something other than None, you might end up on this stack.\n        chain: List[Deferred[Any]] = [self]\n\n        while chain:\n            current = chain[-1]\n\n            if current.paused:\n                # This Deferred isn't going to produce a result at all.  All the\n                # Deferreds up the chain waiting on it will just have to...\n                # wait.\n                return\n\n            finished = True\n            current._chainedTo = None\n            while current._callbacks:\n                item = current._callbacks.pop(0)\n                if not isinstance(current.result, Failure):\n                    callback, args, kwargs = item[0]\n                else:\n                    # type note: Callback signature also works for Errbacks in\n                    #     this context.\n                    callback, args, kwargs = item[1]\n\n                # Avoid recursion if we can.\n                if callback is _CONTINUE:\n                    # Give the waiting Deferred our current result and then\n                    # forget about that result ourselves.\n\n                    # We don't use cast() for performance reasons:\n                    chainee: Deferred[object] = args[0]  # type: ignore[assignment]\n                    chainee.result = current.result\n                    current.result = None\n                    # Making sure to update _debugInfo\n                    if current._debugInfo is not None:\n                        current._debugInfo.failResult = None\n                    chainee.paused -= 1\n                    chain.append(chainee)\n                    # Delay cleaning this Deferred and popping it from the chain\n                    # until after we've dealt with chainee.\n                    finished = False\n                    break\n\n                try:\n                    current._runningCallbacks = True\n                    try:\n                        # type note: mypy sees `callback is _CONTINUE` above and\n                        #    then decides that `callback` is not callable.\n                        #    This goes away when we use `_Sentinel._CONTINUE`\n                        #    instead, but we don't want to do that attribute\n                        #    lookup in this hot code path, so we ignore the mypy\n                        #    complaint here.\n                        current.result = callback(  # type: ignore[misc]\n                            current.result, *args, **kwargs\n                        )\n\n                        if current.result is current:\n                            warnAboutFunction(\n                                callback,\n                                \"Callback returned the Deferred \"\n                                \"it was attached to; this breaks the \"\n                                \"callback chain and will raise an \"\n                                \"exception in the future.\",\n                            )\n                    finally:\n                        current._runningCallbacks = False\n                except BaseException:\n                    # Including full frame information in the Failure is quite\n                    # expensive, so we avoid it unless self.debug is set.\n                    current.result = Failure(captureVars=self.debug)\n                else:\n                    # isinstance() with Awaitable subclass is expensive:\n                    if type(current.result) in _DEFERRED_SUBCLASSES:\n                        # Can't use cast() cause it's in the performance hot path:\n                        currentResult: Deferred[_SelfResultT] = current.result  # type: ignore[assignment]\n                        # The result is another Deferred.  If it has a result,\n                        # we can take it and keep going.\n                        resultResult = getattr(currentResult, \"result\", _NO_RESULT)\n                        if (\n                            resultResult is _NO_RESULT\n                            or type(resultResult) in _DEFERRED_SUBCLASSES\n                            or currentResult.paused\n                        ):\n                            # Nope, it didn't.  Pause and chain.\n                            current.pause()\n                            current._chainedTo = currentResult\n                            # Note: current.result has no result, so it's not\n                            # running its callbacks right now.  Therefore we can\n                            # append to the callbacks list directly instead of\n                            # using addCallbacks.\n                            currentResult._callbacks.append(current._continuation())\n                            break\n                        else:\n                            # Yep, it did.  Steal it.\n                            currentResult.result = None\n                            # Make sure _debugInfo's failure state is updated.\n                            if currentResult._debugInfo is not None:\n                                currentResult._debugInfo.failResult = None\n                            current.result = resultResult\n\n            if finished:\n                # As much of the callback chain - perhaps all of it - as can be\n                # processed right now has been.  The current Deferred is waiting on\n                # another Deferred or for more callbacks.  Before finishing with it,\n                # make sure its _debugInfo is in the proper state.\n                if isinstance(current.result, Failure):\n                    # Stash the Failure in the _debugInfo for unhandled error\n                    # reporting.\n                    if current._debugInfo is None:\n                        current._debugInfo = DebugInfo()\n                    current._debugInfo.failResult = current.result\n                else:\n                    # Clear out any Failure in the _debugInfo, since the result\n                    # is no longer a Failure.\n                    if current._debugInfo is not None:\n                        current._debugInfo.failResult = None\n\n                # This Deferred is done, pop it from the chain and move back up\n                # to the Deferred which supplied us with our result.\n                chain.pop()\n\n    def __str__(self) -> str:\n        \"\"\"\n        Return a string representation of this L{Deferred}.\n        \"\"\"\n        cname = self.__class__.__name__\n        result = getattr(self, \"result\", _NO_RESULT)\n        myID = id(self)\n        if self._chainedTo is not None:\n            result = f\" waiting on Deferred at 0x{id(self._chainedTo):x}\"\n        elif result is _NO_RESULT:\n            result = \"\"\n        else:\n            result = f\" current result: {result!r}\"\n        return f\"<{cname} at 0x{myID:x}{result}>\"\n\n    __repr__ = __str__\n\n    def __iter__(self) -> Generator[Deferred[_SelfResultT], None, _SelfResultT]:\n        while True:\n            if self.paused:\n                # If we're paused, we have no result to give\n                yield self\n                continue\n\n            result = getattr(self, \"result\", _NO_RESULT)\n            if result is _NO_RESULT:\n                yield self\n                continue\n\n            if isinstance(result, Failure):\n                # Clear the failure on debugInfo so it doesn't raise \"unhandled\n                # exception\"\n                assert self._debugInfo is not None\n                self._debugInfo.failResult = None\n                result.raiseException()\n            else:\n                return result  # type: ignore[return-value]\n\n    __await__ = __iter__\n\n    def asFuture(self, loop: AbstractEventLoop) -> \"Future[_SelfResultT]\":\n        \"\"\"\n        Adapt this L{Deferred} into a L{Future} which is bound to C{loop}.\n\n        @note: converting a L{Deferred} to an L{Future} consumes both\n            its result and its errors, so this method implicitly converts\n            C{self} into a L{Deferred} firing with L{None}, regardless of what\n            its result previously would have been.\n\n        @since: Twisted 17.5.0\n\n        @param loop: The L{asyncio} event loop to bind the L{Future} to.\n\n        @return: A L{Future} which will fire when the L{Deferred} fires.\n        \"\"\"\n        future = loop.create_future()\n\n        def checkCancel(futureAgain: \"Future[_SelfResultT]\") -> None:\n            if futureAgain.cancelled():\n                self.cancel()\n\n        def maybeFail(failure: Failure) -> None:\n            if not future.cancelled():\n                future.set_exception(failure.value)\n\n        def maybeSucceed(result: object) -> None:\n            if not future.cancelled():\n                future.set_result(result)\n\n        self.addCallbacks(maybeSucceed, maybeFail)\n        future.add_done_callback(checkCancel)\n\n        return future\n\n    @classmethod\n    def fromFuture(cls, future: \"Future[_SelfResultT]\") -> \"Deferred[_SelfResultT]\":\n        \"\"\"\n        Adapt a L{Future} to a L{Deferred}.\n\n        @note: This creates a L{Deferred} from a L{Future}, I{not} from\n            a C{coroutine}; in other words, you will need to call\n            L{asyncio.ensure_future}, L{asyncio.loop.create_task} or create an\n            L{asyncio.Task} yourself to get from a C{coroutine} to a\n            L{Future} if what you have is an awaitable coroutine and\n            not a L{Future}.  (The length of this list of techniques is\n            exactly why we have left it to the caller!)\n\n        @since: Twisted 17.5.0\n\n        @param future: The L{Future} to adapt.\n\n        @return: A L{Deferred} which will fire when the L{Future} fires.\n        \"\"\"\n\n        def adapt(result: Future[_SelfResultT]) -> None:\n            try:\n                extracted: _SelfResultT | Failure = result.result()\n            except BaseException:\n                extracted = Failure()\n            actual.callback(extracted)\n\n        futureCancel = object()\n\n        def cancel(reself: Deferred[object]) -> None:\n            future.cancel()\n            reself.callback(futureCancel)\n\n        self = cls(cancel)\n        actual = self\n\n        def uncancel(\n            result: _SelfResultT,\n        ) -> Union[_SelfResultT, Deferred[_SelfResultT]]:\n            if result is futureCancel:\n                nonlocal actual\n                actual = Deferred()\n                return actual\n            return result\n\n        self.addCallback(uncancel)\n        future.add_done_callback(adapt)\n\n        return self\n\n    @classmethod\n    def fromCoroutine(\n        cls,\n        coro: Union[\n            Coroutine[Deferred[Any], Any, _T],\n            Generator[Deferred[Any], Any, _T],\n        ],\n    ) -> \"Deferred[_T]\":\n        \"\"\"\n        Schedule the execution of a coroutine that awaits on L{Deferred}s,\n        wrapping it in a L{Deferred} that will fire on success/failure of the\n        coroutine.\n\n        Coroutine functions return a coroutine object, similar to how\n        generators work. This function turns that coroutine into a Deferred,\n        meaning that it can be used in regular Twisted code. For example::\n\n            import treq\n            from twisted.internet.defer import Deferred\n            from twisted.internet.task import react\n\n            async def crawl(pages):\n                results = {}\n                for page in pages:\n                    results[page] = await treq.content(await treq.get(page))\n                return results\n\n            def main(reactor):\n                pages = [\n                    \"http://localhost:8080\"\n                ]\n                d = Deferred.fromCoroutine(crawl(pages))\n                d.addCallback(print)\n                return d\n\n            react(main)\n\n        @since: Twisted 21.2.0\n\n        @param coro: The coroutine object to schedule.\n\n        @raise ValueError: If C{coro} is not a coroutine or generator.\n        \"\"\"\n        # asyncio.iscoroutine <3.12 identifies generators as coroutines, too.\n        # for >=3.12 we need to check isgenerator also\n        # see https://github.com/python/cpython/issues/102748\n        if iscoroutine(coro) or inspect.isgenerator(coro):\n            return _cancellableInlineCallbacks(coro)\n        raise NotACoroutineError(f\"{coro!r} is not a coroutine\")\n\n    def __init_subclass__(cls: Type[Deferred[Any]], **kwargs: Any):\n        # Whenever a subclass is created, record it in L{_DEFERRED_SUBCLASSES}\n        # so we can emulate C{isinstance()} more efficiently.\n        _DEFERRED_SUBCLASSES.append(cls)\n\n\n_DEFERRED_SUBCLASSES = [Deferred]\n\n\ndef ensureDeferred(\n    coro: Union[\n        Coroutine[Deferred[Any], Any, _T],\n        Generator[Deferred[Any], Any, _T],\n        Deferred[_T],\n    ]\n) -> Deferred[_T]:\n    \"\"\"\n    Schedule the execution of a coroutine that awaits/yields from L{Deferred}s,\n    wrapping it in a L{Deferred} that will fire on success/failure of the\n    coroutine. If a Deferred is passed to this function, it will be returned\n    directly (mimicking the L{asyncio.ensure_future} function).\n\n    See L{Deferred.fromCoroutine} for examples of coroutines.\n\n    @param coro: The coroutine object to schedule, or a L{Deferred}.\n    \"\"\"\n    if type(coro) in _DEFERRED_SUBCLASSES:\n        return coro  # type: ignore[return-value]\n    else:\n        try:\n            return Deferred.fromCoroutine(coro)  # type: ignore[arg-type]\n        except NotACoroutineError:\n            # It's not a coroutine. Raise an exception, but say that it's also\n            # not a Deferred so the error makes sense.\n            raise NotACoroutineError(f\"{coro!r} is not a coroutine or a Deferred\")\n\n\n@comparable\nclass FirstError(Exception):\n    \"\"\"\n    First error to occur in a L{DeferredList} if C{fireOnOneErrback} is set.\n\n    @ivar subFailure: The L{Failure} that occurred.\n    @ivar index: The index of the L{Deferred} in the L{DeferredList} where\n        it happened.\n    \"\"\"\n\n    def __init__(self, failure: Failure, index: int) -> None:\n        Exception.__init__(self, failure, index)\n        self.subFailure = failure\n        self.index = index\n\n    def __repr__(self) -> str:\n        \"\"\"\n        The I{repr} of L{FirstError} instances includes the repr of the\n        wrapped failure's exception and the index of the L{FirstError}.\n        \"\"\"\n        return \"FirstError[#%d, %r]\" % (self.index, self.subFailure.value)\n\n    def __str__(self) -> str:\n        \"\"\"\n        The I{str} of L{FirstError} instances includes the I{str} of the\n        entire wrapped failure (including its traceback and exception) and\n        the index of the L{FirstError}.\n        \"\"\"\n        return \"FirstError[#%d, %s]\" % (self.index, self.subFailure)\n\n    def __cmp__(self, other: object) -> int:\n        \"\"\"\n        Comparison between L{FirstError} and other L{FirstError} instances\n        is defined as the comparison of the index and sub-failure of each\n        instance.  L{FirstError} instances don't compare equal to anything\n        that isn't a L{FirstError} instance.\n\n        @since: 8.2\n        \"\"\"\n        if isinstance(other, FirstError):\n            return cmp((self.index, self.subFailure), (other.index, other.subFailure))\n        return -1\n\n\n_DeferredListSingleResultT = Tuple[_SelfResultT, int]\n_DeferredListResultItemT = Tuple[bool, _SelfResultT]\n_DeferredListResultListT = List[_DeferredListResultItemT[_SelfResultT]]\n\nif TYPE_CHECKING:\n    # The result type is different depending on whether fireOnOneCallback\n    # is True or False.  The type system is not flexible enough to handle\n    # that in a class definition, so instead we pretend that DeferredList\n    # is a function that returns a Deferred.\n\n    @overload\n    def _DeferredList(\n        deferredList: Iterable[Deferred[_SelfResultT]],\n        fireOnOneCallback: Literal[True],\n        fireOnOneErrback: bool = False,\n        consumeErrors: bool = False,\n    ) -> Deferred[_DeferredListSingleResultT[_SelfResultT]]:\n        ...\n\n    @overload\n    def _DeferredList(\n        deferredList: Iterable[Deferred[_SelfResultT]],\n        fireOnOneCallback: Literal[False] = False,\n        fireOnOneErrback: bool = False,\n        consumeErrors: bool = False,\n    ) -> Deferred[_DeferredListResultListT[_SelfResultT]]:\n        ...\n\n    def _DeferredList(\n        deferredList: Iterable[Deferred[_SelfResultT]],\n        fireOnOneCallback: bool = False,\n        fireOnOneErrback: bool = False,\n        consumeErrors: bool = False,\n    ) -> Union[\n        Deferred[_DeferredListSingleResultT[_SelfResultT]],\n        Deferred[_DeferredListResultListT[_SelfResultT]],\n    ]:\n        ...\n\n    DeferredList = _DeferredList\n\n\nclass DeferredList(  # type: ignore[no-redef] # noqa:F811\n    Deferred[_DeferredListResultListT[Any]]\n):\n    \"\"\"\n    L{DeferredList} is a tool for collecting the results of several Deferreds.\n\n    This tracks a list of L{Deferred}s for their results, and makes a single\n    callback when they have all completed.  By default, the ultimate result is a\n    list of (success, result) tuples, 'success' being a boolean.\n    L{DeferredList} exposes the same API that L{Deferred} does, so callbacks and\n    errbacks can be added to it in the same way.\n\n    L{DeferredList} is implemented by adding callbacks and errbacks to each\n    L{Deferred} in the list passed to it.  This means callbacks and errbacks\n    added to the Deferreds before they are passed to L{DeferredList} will change\n    the result that L{DeferredList} sees (i.e., L{DeferredList} is not special).\n    Callbacks and errbacks can also be added to the Deferreds after they are\n    passed to L{DeferredList} and L{DeferredList} may change the result that\n    they see.\n\n    See the documentation for the C{__init__} arguments for more information.\n\n    @ivar _deferredList: The L{list} of L{Deferred}s to track.\n    \"\"\"\n\n    fireOnOneCallback = False\n    fireOnOneErrback = False\n\n    def __init__(\n        self,\n        deferredList: Iterable[Deferred[_SelfResultT]],\n        fireOnOneCallback: bool = False,\n        fireOnOneErrback: bool = False,\n        consumeErrors: bool = False,\n    ):\n        \"\"\"\n        Initialize a DeferredList.\n\n        @param deferredList: The deferreds to track.\n        @param fireOnOneCallback: (keyword param) a flag indicating that this\n            L{DeferredList} will fire when the first L{Deferred} in\n            C{deferredList} fires with a non-failure result without waiting for\n            any of the other Deferreds.  When this flag is set, the DeferredList\n            will fire with a two-tuple: the first element is the result of the\n            Deferred which fired; the second element is the index in\n            C{deferredList} of that Deferred.\n        @param fireOnOneErrback: (keyword param) a flag indicating that this\n            L{DeferredList} will fire when the first L{Deferred} in\n            C{deferredList} fires with a failure result without waiting for any\n            of the other Deferreds.  When this flag is set, if a Deferred in the\n            list errbacks, the DeferredList will errback with a L{FirstError}\n            failure wrapping the failure of that Deferred.\n        @param consumeErrors: (keyword param) a flag indicating that failures in\n            any of the included L{Deferred}s should not be propagated to\n            errbacks added to the individual L{Deferred}s after this\n            L{DeferredList} is constructed.  After constructing the\n            L{DeferredList}, any errors in the individual L{Deferred}s will be\n            converted to a callback result of L{None}.  This is useful to\n            prevent spurious 'Unhandled error in Deferred' messages from being\n            logged.  This does not prevent C{fireOnOneErrback} from working.\n        \"\"\"\n        self._deferredList = list(deferredList)\n\n        # Note this contains optional result values as the DeferredList is\n        # processing its results, even though the callback result will not,\n        # which is why we aren't using _DeferredListResultListT here.\n        self.resultList: List[Optional[_DeferredListResultItemT[Any]]] = [None] * len(\n            self._deferredList\n        )\n        \"\"\"\n        The final result, in progress.\n        Each item in the list corresponds to the L{Deferred} at the same\n        position in L{_deferredList}. It will be L{None} if the L{Deferred}\n        did not complete yet, or a C{(success, result)} pair if it did.\n        \"\"\"\n\n        Deferred.__init__(self)\n        if len(self._deferredList) == 0 and not fireOnOneCallback:\n            self.callback([])\n\n        # These flags need to be set *before* attaching callbacks to the\n        # deferreds, because the callbacks use these flags, and will run\n        # synchronously if any of the deferreds are already fired.\n        self.fireOnOneCallback = fireOnOneCallback\n        self.fireOnOneErrback = fireOnOneErrback\n        self.consumeErrors = consumeErrors\n        self.finishedCount = 0\n\n        index = 0\n        for deferred in self._deferredList:\n            deferred.addCallbacks(\n                self._cbDeferred,\n                self._cbDeferred,\n                callbackArgs=(index, SUCCESS),\n                errbackArgs=(index, FAILURE),\n            )\n            index = index + 1\n\n    def _cbDeferred(\n        self, result: _SelfResultT, index: int, succeeded: bool\n    ) -> Optional[_SelfResultT]:\n        \"\"\"\n        (internal) Callback for when one of my deferreds fires.\n        \"\"\"\n        self.resultList[index] = (succeeded, result)\n\n        self.finishedCount += 1\n        if not self.called:\n            if succeeded == SUCCESS and self.fireOnOneCallback:\n                self.callback((result, index))  # type: ignore[arg-type]\n            elif succeeded == FAILURE and self.fireOnOneErrback:\n                assert isinstance(result, Failure)\n                self.errback(Failure(FirstError(result, index)))\n            elif self.finishedCount == len(self.resultList):\n                # At this point, None values in self.resultList have been\n                # replaced by result values, so we cast it to\n                # _DeferredListResultListT to match the callback result type.\n                self.callback(cast(_DeferredListResultListT[Any], self.resultList))\n\n        if succeeded == FAILURE and self.consumeErrors:\n            return None\n\n        return result\n\n    def cancel(self) -> None:\n        \"\"\"\n        Cancel this L{DeferredList}.\n\n        If the L{DeferredList} hasn't fired yet, cancel every L{Deferred} in\n        the list.\n\n        If the L{DeferredList} has fired, including the case where the\n        C{fireOnOneCallback}/C{fireOnOneErrback} flag is set and the\n        L{DeferredList} fires because one L{Deferred} in the list fires with a\n        non-failure/failure result, do nothing in the C{cancel} method.\n        \"\"\"\n        if not self.called:\n            for deferred in self._deferredList:\n                try:\n                    deferred.cancel()\n                except BaseException:\n                    log.failure(\"Exception raised from user supplied canceller\")\n\n\ndef _parseDeferredListResult(\n    resultList: List[_DeferredListResultItemT[_T]], fireOnOneErrback: bool = False, /\n) -> List[_T]:\n    if __debug__:\n        for result in resultList:\n            assert result is not None\n            success, value = result\n            assert success\n    return [x[1] for x in resultList]\n\n\ndef gatherResults(\n    deferredList: Iterable[Deferred[_T]], consumeErrors: bool = False\n) -> Deferred[List[_T]]:\n    \"\"\"\n    Returns, via a L{Deferred}, a list with the results of the given\n    L{Deferred}s - in effect, a \"join\" of multiple deferred operations.\n\n    The returned L{Deferred} will fire when I{all} of the provided L{Deferred}s\n    have fired, or when any one of them has failed.\n\n    This method can be cancelled by calling the C{cancel} method of the\n    L{Deferred}, all the L{Deferred}s in the list will be cancelled.\n\n    This differs from L{DeferredList} in that you don't need to parse\n    the result for success/failure.\n\n    @param consumeErrors: (keyword param) a flag, defaulting to False,\n        indicating that failures in any of the given L{Deferred}s should not be\n        propagated to errbacks added to the individual L{Deferred}s after this\n        L{gatherResults} invocation.  Any such errors in the individual\n        L{Deferred}s will be converted to a callback result of L{None}.  This\n        is useful to prevent spurious 'Unhandled error in Deferred' messages\n        from being logged.  This parameter is available since 11.1.0.\n    \"\"\"\n    return DeferredList(\n        deferredList, fireOnOneErrback=True, consumeErrors=consumeErrors\n    ).addCallback(_parseDeferredListResult)\n\n\nclass FailureGroup(Exception):\n    \"\"\"\n    More than one failure occurred.\n    \"\"\"\n\n    def __init__(self, failures: Sequence[Failure]) -> None:\n        super(FailureGroup, self).__init__()\n        self.failures = failures\n\n\ndef race(ds: Sequence[Deferred[_T]]) -> Deferred[tuple[int, _T]]:\n    \"\"\"\n    Select the first available result from the sequence of Deferreds and\n    cancel the rest.\n\n    @return: A cancellable L{Deferred} that fires with the index and output of\n        the element of C{ds} to have a success result first, or that fires\n        with L{FailureGroup} holding a list of their failures if they all\n        fail.\n    \"\"\"\n    # Keep track of the Deferred for the action which completed first.  When\n    # it completes, all of the other Deferreds will get cancelled but this one\n    # shouldn't be.  Even though it \"completed\" it isn't really done - the\n    # caller will still be using it for something.  If we cancelled it,\n    # cancellation could propagate down to them.\n    winner: Optional[Deferred[_T]] = None\n\n    # The cancellation function for the Deferred this function returns.\n    def cancel(result: Deferred[_T]) -> None:\n        # If it is cancelled then we cancel all of the Deferreds for the\n        # individual actions because there is no longer the possibility of\n        # delivering any of their results anywhere.  We don't have to fire\n        # `result` because the Deferred will do that for us.\n        for d in to_cancel:\n            d.cancel()\n\n    # The Deferred that this function will return.  It will fire with the\n    # index and output of the action that completes first, or errback if all\n    # of the actions fail.  If it is cancelled, all of the actions will be\n    # cancelled.\n    final_result: Deferred[tuple[int, _T]] = Deferred(canceller=cancel)\n\n    # A callback for an individual action.\n    def succeeded(this_output: _T, this_index: int) -> None:\n        # If it is the first action to succeed then it becomes the \"winner\",\n        # its index/output become the externally visible result, and the rest\n        # of the action Deferreds get cancelled.  If it is not the first\n        # action to succeed (because some action did not support\n        # cancellation), just ignore the result.  It is uncommon for this\n        # callback to be entered twice.  The only way it can happen is if one\n        # of the input Deferreds has a cancellation function that fires the\n        # Deferred with a success result.\n        nonlocal winner\n        if winner is None:\n            # This is the first success.  Act on it.\n            winner = to_cancel[this_index]\n\n            # Cancel the rest.\n            for d in to_cancel:\n                if d is not winner:\n                    d.cancel()\n\n            # Fire our Deferred\n            final_result.callback((this_index, this_output))\n\n    # Keep track of how many actions have failed.  If they all fail we need to\n    # deliver failure notification on our externally visible result.\n    failure_state = []\n\n    def failed(failure: Failure, this_index: int) -> None:\n        failure_state.append((this_index, failure))\n        if len(failure_state) == len(to_cancel):\n            # Every operation failed.\n            failure_state.sort()\n            failures = [f for (ignored, f) in failure_state]\n            final_result.errback(FailureGroup(failures))\n\n    # Copy the sequence of Deferreds so we know it doesn't get mutated out\n    # from under us.\n    to_cancel = list(ds)\n    for index, d in enumerate(ds):\n        # Propagate the position of this action as well as the argument to f\n        # to the success callback so we can cancel the right Deferreds and\n        # propagate the result outwards.\n        d.addCallbacks(succeeded, failed, callbackArgs=(index,), errbackArgs=(index,))\n\n    return final_result\n\n\n# Constants for use with DeferredList\nSUCCESS = True\nFAILURE = False\n\n\n## inlineCallbacks\n\n\nclass _DefGen_Return(BaseException):\n    def __init__(self, value: object) -> None:\n        self.value = value\n\n\n@deprecated(\n    Version(\"Twisted\", 24, 7, 0),\n    replacement=\"standard return statement\",\n)\ndef returnValue(val: object) -> NoReturn:\n    \"\"\"\n    Return val from a L{inlineCallbacks} generator.\n\n    Note: this is currently implemented by raising an exception\n    derived from L{BaseException}.  You might want to change any\n    'except:' clauses to an 'except Exception:' clause so as not to\n    catch this exception.\n\n    Also: while this function currently will work when called from\n    within arbitrary functions called from within the generator, do\n    not rely upon this behavior.\n    \"\"\"\n    raise _DefGen_Return(val)\n\n\n@attr.s(auto_attribs=True)\nclass _CancellationStatus(Generic[_SelfResultT]):\n    \"\"\"\n    Cancellation status of an L{inlineCallbacks} invocation.\n\n    @ivar deferred: the L{Deferred} to callback or errback when the generator\n        invocation has finished.\n    @ivar waitingOn: the L{Deferred} being waited upon (which\n        L{_inlineCallbacks} must fill out before returning)\n    \"\"\"\n\n    deferred: Deferred[_SelfResultT]\n    waitingOn: Optional[Deferred[_SelfResultT]] = None\n\n\ndef _gotResultInlineCallbacks(\n    r: object,\n    waiting: List[Any],\n    gen: Union[\n        Generator[Deferred[Any], Any, _T],\n        Coroutine[Deferred[Any], Any, _T],\n    ],\n    status: _CancellationStatus[_T],\n    context: _Context,\n) -> None:\n    \"\"\"\n    Helper for L{_inlineCallbacks} to handle a nested L{Deferred} firing.\n\n    @param r: The result of the L{Deferred}\n    @param waiting: Whether the L{_inlineCallbacks} was waiting, and the result.\n    @param gen: a generator object returned by calling a function or method\n        decorated with C{@}L{inlineCallbacks}\n    @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n    @param context: the contextvars context to run `gen` in\n    \"\"\"\n    if waiting[0]:\n        waiting[0] = False\n        waiting[1] = r\n    else:\n        _inlineCallbacks(r, gen, status, context)\n\n\n@_extraneous\ndef _inlineCallbacks(\n    result: object,\n    gen: Union[\n        Generator[Deferred[Any], Any, _T],\n        Coroutine[Deferred[Any], Any, _T],\n    ],\n    status: _CancellationStatus[_T],\n    context: _Context,\n) -> None:\n    \"\"\"\n    Carry out the work of L{inlineCallbacks}.\n\n    Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n    function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n    that generator, until a L{Deferred} is yielded, at which point a callback\n    is added to that L{Deferred} to call this function again.\n\n    @param result: The last result seen by this generator.  Note that this is\n        never a L{Deferred} - by the time this function is invoked, the\n        L{Deferred} has been called back and this will be a particular result\n        at a point in its callback chain.\n\n    @param gen: a generator object returned by calling a function or method\n        decorated with C{@}L{inlineCallbacks}\n\n    @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n\n    @param context: the contextvars context to run `gen` in\n    \"\"\"\n    # This function is complicated by the need to prevent unbounded recursion\n    # arising from repeatedly yielding immediately ready deferreds.  This while\n    # loop and the waiting variable solve that by manually unfolding the\n    # recursion.\n\n    # waiting for result?  # result\n    waiting: List[Any] = [True, None]\n\n    stopIteration: bool = False\n    callbackValue: Any = None\n\n    while 1:\n        try:\n            # Send the last result back as the result of the yield expression.\n            isFailure = isinstance(result, Failure)\n\n            if isFailure:\n                result = context.run(\n                    cast(Failure, result).throwExceptionIntoGenerator, gen\n                )\n            else:\n                result = context.run(gen.send, result)\n        except StopIteration as e:\n            # fell off the end, or \"return\" statement\n            stopIteration = True\n            callbackValue = getattr(e, \"value\", None)\n\n        except _DefGen_Return as e:\n            # returnValue() was called; time to give a result to the original\n            # Deferred.  First though, let's try to identify the potentially\n            # confusing situation which results when returnValue() is\n            # accidentally invoked from a different function, one that wasn't\n            # decorated with @inlineCallbacks.\n\n            # The traceback starts in this frame (the one for\n            # _inlineCallbacks); the next one down should be the application\n            # code.\n            excInfo = exc_info()\n            assert excInfo is not None\n\n            traceback = excInfo[2]\n            assert traceback is not None\n\n            appCodeTrace = traceback.tb_next\n            assert appCodeTrace is not None\n\n            if _oldPypyStack:\n                # PyPy versions through 7.3.13 add an extra frame; 7.3.14 fixed\n                # this discrepancy with CPython.  This code can be removed once\n                # we no longer need to support PyPy 7.3.13 or older.\n                appCodeTrace = appCodeTrace.tb_next\n                assert appCodeTrace is not None\n\n            if isFailure:\n                # If we invoked this generator frame by throwing an exception\n                # into it, then throwExceptionIntoGenerator will consume an\n                # additional stack frame itself, so we need to skip that too.\n                appCodeTrace = appCodeTrace.tb_next\n                assert appCodeTrace is not None\n\n            # Now that we've identified the frame being exited by the\n            # exception, let's figure out if returnValue was called from it\n            # directly.  returnValue itself consumes a stack frame, so the\n            # application code will have a tb_next, but it will *not* have a\n            # second tb_next.\n            #\n            # Note that there's one additional level due to returnValue being\n            # deprecated\n            assert appCodeTrace.tb_next is not None\n            assert appCodeTrace.tb_next.tb_next is not None\n            if appCodeTrace.tb_next.tb_next.tb_next:\n                # If returnValue was invoked non-local to the frame which it is\n                # exiting, identify the frame that ultimately invoked\n                # returnValue so that we can warn the user, as this behavior is\n                # confusing.\n                #\n                # Note that there's one additional level due to returnValue being\n                # deprecated\n                ultimateTrace = appCodeTrace\n\n                assert ultimateTrace is not None\n                assert ultimateTrace.tb_next is not None\n\n                # Note that there's one additional level due to returnValue being\n                # deprecated\n                assert ultimateTrace.tb_next.tb_next is not None\n                while ultimateTrace.tb_next.tb_next.tb_next:\n                    ultimateTrace = ultimateTrace.tb_next\n                    assert ultimateTrace is not None\n\n                filename = ultimateTrace.tb_frame.f_code.co_filename\n                lineno = ultimateTrace.tb_lineno\n\n                assert ultimateTrace.tb_frame is not None\n                assert appCodeTrace.tb_frame is not None\n                warnings.warn_explicit(\n                    \"returnValue() in %r causing %r to exit: \"\n                    \"returnValue should only be invoked by functions decorated \"\n                    \"with inlineCallbacks\"\n                    % (\n                        ultimateTrace.tb_frame.f_code.co_name,\n                        appCodeTrace.tb_frame.f_code.co_name,\n                    ),\n                    DeprecationWarning,\n                    filename,\n                    lineno,\n                )\n\n            stopIteration = True\n            callbackValue = e.value\n\n        except BaseException:\n            status.deferred.errback()\n            return\n\n        if stopIteration:\n            # Call the callback outside of the exception handler to avoid inappropriate/confusing\n            # \"During handling of the above exception, another exception occurred:\" if the callback\n            # itself throws an exception.\n            status.deferred.callback(callbackValue)\n            return\n\n        isDeferred = type(result) in _DEFERRED_SUBCLASSES\n        # iscoroutine() is pretty expensive in this context, so avoid calling\n        # it unnecessarily:\n        if not isDeferred and (iscoroutine(result) or inspect.isgenerator(result)):\n            result = _cancellableInlineCallbacks(result)\n            isDeferred = True\n\n        if isDeferred:\n            # We don't cast() to Deferred because that does more work in the hot path\n\n            # a deferred was yielded, get the result.\n            result.addBoth(_gotResultInlineCallbacks, waiting, gen, status, context)  # type: ignore[attr-defined]\n            if waiting[0]:\n                # Haven't called back yet, set flag so that we get reinvoked\n                # and return from the loop\n                waiting[0] = False\n                status.waitingOn = result  # type: ignore[assignment]\n                return\n\n            result = waiting[1]\n            # Reset waiting to initial values for next loop.  gotResult uses\n            # waiting, but this isn't a problem because gotResult is only\n            # executed once, and if it hasn't been executed yet, the return\n            # branch above would have been taken.\n\n            waiting[0] = True\n            waiting[1] = None\n\n\ndef _addCancelCallbackToDeferred(\n    it: Deferred[_T], status: _CancellationStatus[_T]\n) -> None:\n    \"\"\"\n    Helper for L{_cancellableInlineCallbacks} to add\n    L{_handleCancelInlineCallbacks} as the first errback.\n\n    @param it: The L{Deferred} to add the errback to.\n    @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n    \"\"\"\n    it._callbacks, tmp = [], it._callbacks\n    it = it.addErrback(_handleCancelInlineCallbacks, status)\n    it._callbacks.extend(tmp)\n    it.errback(_InternalInlineCallbacksCancelledError())\n\n\ndef _handleCancelInlineCallbacks(\n    result: Failure, status: _CancellationStatus[_T], /\n) -> Deferred[_T]:\n    \"\"\"\n    Propagate the cancellation of an C{@}L{inlineCallbacks} to the\n    L{Deferred} it is waiting on.\n\n    @param result: An L{_InternalInlineCallbacksCancelledError} from\n        C{cancel()}.\n    @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n    @return: A new L{Deferred} that the C{@}L{inlineCallbacks} generator\n        can callback or errback through.\n    \"\"\"\n    result.trap(_InternalInlineCallbacksCancelledError)\n    status.deferred = Deferred(lambda d: _addCancelCallbackToDeferred(d, status))\n\n    # We would only end up here if the inlineCallback is waiting on\n    # another Deferred.  It needs to be cancelled.\n    awaited = status.waitingOn\n    assert awaited is not None\n    awaited.cancel()\n\n    return status.deferred\n\n\ndef _cancellableInlineCallbacks(\n    gen: Union[\n        Generator[Deferred[Any], object, _T],\n        Coroutine[Deferred[Any], object, _T],\n    ]\n) -> Deferred[_T]:\n    \"\"\"\n    Make an C{@}L{inlineCallbacks} cancellable.\n\n    @param gen: a generator object returned by calling a function or method\n        decorated with C{@}L{inlineCallbacks}\n\n    @return: L{Deferred} for the C{@}L{inlineCallbacks} that is cancellable.\n    \"\"\"\n\n    deferred: Deferred[_T] = Deferred(lambda d: _addCancelCallbackToDeferred(d, status))\n    status = _CancellationStatus(deferred)\n\n    _inlineCallbacks(None, gen, status, _copy_context())\n\n    return deferred\n\n\nclass _InternalInlineCallbacksCancelledError(Exception):\n    \"\"\"\n    A unique exception used only in L{_cancellableInlineCallbacks} to verify\n    that an L{inlineCallbacks} is being cancelled as expected.\n    \"\"\"\n\n\ndef inlineCallbacks(\n    f: Callable[_P, Generator[Deferred[Any], Any, _T]]\n) -> Callable[_P, Deferred[_T]]:\n    \"\"\"\n    L{inlineCallbacks} helps you write L{Deferred}-using code that looks like a\n    regular sequential function. For example::\n\n        @inlineCallbacks\n        def thingummy():\n            thing = yield makeSomeRequestResultingInDeferred()\n            print(thing)  # the result! hoorj!\n\n    When you call anything that results in a L{Deferred}, you can simply yield it;\n    your generator will automatically be resumed when the Deferred's result is\n    available. The generator will be sent the result of the L{Deferred} with the\n    'send' method on generators, or if the result was a failure, 'throw'.\n\n    Things that are not L{Deferred}s may also be yielded, and your generator\n    will be resumed with the same object sent back. This means C{yield}\n    performs an operation roughly equivalent to L{maybeDeferred}.\n\n    Your inlineCallbacks-enabled generator will return a L{Deferred} object, which\n    will result in the return value of the generator (or will fail with a\n    failure object if your generator raises an unhandled exception). Inside\n    the generator simply use C{return result} to return a value.\n\n    Be aware that generator must not return a L{Deferred}.\n    If you believe the thing you'd like to return could be a L{Deferred}, do\n    this::\n\n        result = yield result\n        return result\n\n    The L{Deferred} returned from your deferred generator may errback if your\n    generator raised an exception::\n\n        @inlineCallbacks\n        def thingummy():\n            thing = yield makeSomeRequestResultingInDeferred()\n            if thing == 'I love Twisted':\n                # will become the result of the Deferred\n                return 'TWISTED IS GREAT!'\n            else:\n                # will trigger an errback\n                raise Exception('DESTROY ALL LIFE')\n\n    You can cancel the L{Deferred} returned from your L{inlineCallbacks}\n    generator before it is fired by your generator completing (either by\n    reaching its end, a C{return} statement, or by calling L{returnValue}).\n    A C{CancelledError} will be raised from the C{yield}ed L{Deferred} that\n    has been cancelled if that C{Deferred} does not otherwise suppress it.\n\n    C{inlineCallbacks} behaves very similarly to coroutines. Since Twisted 24.7.0\n    it is possible to rewrite functions using C{inlineCallbacks} to C{async def}\n    in piecewise manner and be mostly compatible to existing code.\n\n    The rewrite process is simply replacing C{inlineCallbacks} decorator with\n    C{async def} and all C{yield} occurrences in the function body with C{await}.\n    The function will no longer return a C{Deferred} but a awaitable coroutine.\n    This return value will obviously not have C{Deferred} methods such as\n    C{addCallback}, but it will be possible to C{yield} it in other code based\n    on C{inlineCallbacks}.\n    \"\"\"\n\n    @wraps(f)\n    def unwindGenerator(*args: _P.args, **kwargs: _P.kwargs) -> Deferred[_T]:\n        try:\n            gen = f(*args, **kwargs)\n        except _DefGen_Return:\n            raise TypeError(\n                \"inlineCallbacks requires %r to produce a generator; instead\"\n                \"caught returnValue being used in a non-generator\" % (f,)\n            )\n        if not isinstance(gen, GeneratorType):\n            raise TypeError(\n                \"inlineCallbacks requires %r to produce a generator; \"\n                \"instead got %r\" % (f, gen)\n            )\n        return _cancellableInlineCallbacks(gen)\n\n    return unwindGenerator\n\n\n## DeferredLock/DeferredQueue\n\n\nclass _ConcurrencyPrimitive(ABC):\n    def __init__(self: Self) -> None:\n        self.waiting: List[Deferred[Self]] = []\n\n    def _releaseAndReturn(self, r: _T) -> _T:\n        self.release()\n        return r\n\n    @overload\n    def run(\n        self: Self,\n        /,\n        f: Callable[_P, Deferred[_T]],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_T]:\n        ...\n\n    @overload\n    def run(\n        self: Self,\n        /,\n        f: Callable[_P, Coroutine[Deferred[Any], Any, _T]],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_T]:\n        ...\n\n    @overload\n    def run(\n        self: Self, /, f: Callable[_P, _T], *args: _P.args, **kwargs: _P.kwargs\n    ) -> Deferred[_T]:\n        ...\n\n    def run(\n        self: Self,\n        /,\n        f: Callable[_P, Union[Deferred[_T], Coroutine[Deferred[Any], Any, _T], _T]],\n        *args: _P.args,\n        **kwargs: _P.kwargs,\n    ) -> Deferred[_T]:\n        \"\"\"\n        Acquire, run, release.\n\n        This method takes a callable as its first argument and any\n        number of other positional and keyword arguments.  When the\n        lock or semaphore is acquired, the callable will be invoked\n        with those arguments.\n\n        The callable may return a L{Deferred}; if it does, the lock or\n        semaphore won't be released until that L{Deferred} fires.\n\n        @return: L{Deferred} of function result.\n        \"\"\"\n\n        def execute(ignoredResult: object) -> Deferred[_T]:\n            # maybeDeferred arg type requires one of the possible union members\n            # and won't accept all possible union members\n            return maybeDeferred(f, *args, **kwargs).addBoth(\n                self._releaseAndReturn\n            )  # type: ignore[return-value]\n\n        return self.acquire().addCallback(execute)\n\n    def __aenter__(self: Self) -> Deferred[Self]:\n        \"\"\"\n        We can be used as an asynchronous context manager.\n        \"\"\"\n        return self.acquire()\n\n    def __aexit__(\n        self,\n        __exc_type: Optional[Type[BaseException]],\n        __exc_value: Optional[BaseException],\n        __traceback: Optional[TracebackType],\n    ) -> Deferred[Literal[False]]:\n        self.release()\n        # We return False to indicate that we have not consumed the\n        # exception, if any.\n        return succeed(False)\n\n    @abstractmethod\n    def acquire(self: Self) -> Deferred[Self]:\n        pass\n\n    @abstractmethod\n    def release(self) -> None:\n        pass\n\n\nclass DeferredLock(_ConcurrencyPrimitive):\n    \"\"\"\n    A lock for event driven systems.\n\n    @ivar locked: C{True} when this Lock has been acquired, false at all other\n        times.  Do not change this value, but it is useful to examine for the\n        equivalent of a \"non-blocking\" acquisition.\n    \"\"\"\n\n    locked = False\n\n    def _cancelAcquire(self: Self, d: Deferred[Self]) -> None:\n        \"\"\"\n        Remove a deferred d from our waiting list, as the deferred has been\n        canceled.\n\n        Note: We do not need to wrap this in a try/except to catch d not\n        being in self.waiting because this canceller will not be called if\n        d has fired. release() pops a deferred out of self.waiting and\n        calls it, so the canceller will no longer be called.\n\n        @param d: The deferred that has been canceled.\n        \"\"\"\n        self.waiting.remove(d)\n\n    def acquire(self: Self) -> Deferred[Self]:\n        \"\"\"\n        Attempt to acquire the lock.  Returns a L{Deferred} that fires on\n        lock acquisition with the L{DeferredLock} as the value.  If the lock\n        is locked, then the Deferred is placed at the end of a waiting list.\n\n        @return: a L{Deferred} which fires on lock acquisition.\n        @rtype: a L{Deferred}\n        \"\"\"\n        d: Deferred[Self] = Deferred(canceller=self._cancelAcquire)\n        if self.locked:\n            self.waiting.append(d)\n        else:\n            self.locked = True\n            d.callback(self)\n        return d\n\n    def release(self: Self) -> None:\n        \"\"\"\n        Release the lock.  If there is a waiting list, then the first\n        L{Deferred} in that waiting list will be called back.\n\n        Should be called by whomever did the L{acquire}() when the shared\n        resource is free.\n        \"\"\"\n        assert self.locked, \"Tried to release an unlocked lock\"\n        self.locked = False\n        if self.waiting:\n            # someone is waiting to acquire lock\n            self.locked = True\n            d = self.waiting.pop(0)\n            d.callback(self)\n\n\nclass DeferredSemaphore(_ConcurrencyPrimitive):\n    \"\"\"\n    A semaphore for event driven systems.\n\n    If you are looking into this as a means of limiting parallelism, you might\n    find L{twisted.internet.task.Cooperator} more useful.\n\n    @ivar limit: At most this many users may acquire this semaphore at\n        once.\n    @ivar tokens: The difference between C{limit} and the number of users\n        which have currently acquired this semaphore.\n    \"\"\"\n\n    def __init__(self, tokens: int) -> None:\n        \"\"\"\n        @param tokens: initial value of L{tokens} and L{limit}\n        @type tokens: L{int}\n        \"\"\"\n        _ConcurrencyPrimitive.__init__(self)\n        if tokens < 1:\n            raise ValueError(\"DeferredSemaphore requires tokens >= 1\")\n        self.tokens = tokens\n        self.limit = tokens\n\n    def _cancelAcquire(self: Self, d: Deferred[Self]) -> None:\n        \"\"\"\n        Remove a deferred d from our waiting list, as the deferred has been\n        canceled.\n\n        Note: We do not need to wrap this in a try/except to catch d not\n        being in self.waiting because this canceller will not be called if\n        d has fired. release() pops a deferred out of self.waiting and\n        calls it, so the canceller will no longer be called.\n\n        @param d: The deferred that has been canceled.\n        \"\"\"\n        self.waiting.remove(d)\n\n    def acquire(self: Self) -> Deferred[Self]:\n        \"\"\"\n        Attempt to acquire the token.\n\n        @return: a L{Deferred} which fires on token acquisition.\n        \"\"\"\n        assert (\n            self.tokens >= 0\n        ), \"Internal inconsistency??  tokens should never be negative\"\n        d: Deferred[Self] = Deferred(canceller=self._cancelAcquire)\n        if not self.tokens:\n            self.waiting.append(d)\n        else:\n            self.tokens = self.tokens - 1\n            d.callback(self)\n        return d\n\n    def release(self: Self) -> None:\n        \"\"\"\n        Release the token.\n\n        Should be called by whoever did the L{acquire}() when the shared\n        resource is free.\n        \"\"\"\n        assert (\n            self.tokens < self.limit\n        ), \"Someone released me too many times: too many tokens!\"\n        self.tokens = self.tokens + 1\n        if self.waiting:\n            # someone is waiting to acquire token\n            self.tokens = self.tokens - 1\n            d = self.waiting.pop(0)\n            d.callback(self)\n\n\nclass QueueOverflow(Exception):\n    pass\n\n\nclass QueueUnderflow(Exception):\n    pass\n\n\nclass DeferredQueue(Generic[_T]):\n    \"\"\"\n    An event driven queue.\n\n    Objects may be added as usual to this queue.  When an attempt is\n    made to retrieve an object when the queue is empty, a L{Deferred} is\n    returned which will fire when an object becomes available.\n\n    @ivar size: The maximum number of objects to allow into the queue\n        at a time.  When an attempt to add a new object would exceed this\n        limit, L{QueueOverflow} is raised synchronously.  L{None} for no limit.\n    @ivar backlog: The maximum number of L{Deferred} gets to allow at\n        one time.  When an attempt is made to get an object which would\n        exceed this limit, L{QueueUnderflow} is raised synchronously.  L{None}\n        for no limit.\n    \"\"\"\n\n    def __init__(\n        self, size: Optional[int] = None, backlog: Optional[int] = None\n    ) -> None:\n        self.waiting: List[Deferred[_T]] = []\n        self.pending: List[_T] = []\n        self.size = size\n        self.backlog = backlog\n\n    def _cancelGet(self, d: Deferred[_T]) -> None:\n        \"\"\"\n        Remove a deferred d from our waiting list, as the deferred has been\n        canceled.\n\n        Note: We do not need to wrap this in a try/except to catch d not\n        being in self.waiting because this canceller will not be called if\n        d has fired. put() pops a deferred out of self.waiting and calls\n        it, so the canceller will no longer be called.\n\n        @param d: The deferred that has been canceled.\n        \"\"\"\n        self.waiting.remove(d)\n\n    def put(self, obj: _T) -> None:\n        \"\"\"\n        Add an object to this queue.\n\n        @raise QueueOverflow: Too many objects are in this queue.\n        \"\"\"\n        if self.waiting:\n            self.waiting.pop(0).callback(obj)\n        elif self.size is None or len(self.pending) < self.size:\n            self.pending.append(obj)\n        else:\n            raise QueueOverflow()\n\n    def get(self) -> Deferred[_T]:\n        \"\"\"\n        Attempt to retrieve and remove an object from the queue.\n\n        @return: a L{Deferred} which fires with the next object available in\n        the queue.\n\n        @raise QueueUnderflow: Too many (more than C{backlog})\n        L{Deferred}s are already waiting for an object from this queue.\n        \"\"\"\n        if self.pending:\n            return succeed(self.pending.pop(0))\n        elif self.backlog is None or len(self.waiting) < self.backlog:\n            d: Deferred[_T] = Deferred(canceller=self._cancelGet)\n            self.waiting.append(d)\n            return d\n        else:\n            raise QueueUnderflow()\n\n\nclass AlreadyTryingToLockError(Exception):\n    \"\"\"\n    Raised when L{DeferredFilesystemLock.deferUntilLocked} is called twice on a\n    single L{DeferredFilesystemLock}.\n    \"\"\"\n\n\nclass DeferredFilesystemLock(lockfile.FilesystemLock):\n    \"\"\"\n    A L{FilesystemLock} that allows for a L{Deferred} to be fired when the lock is\n    acquired.\n\n    @ivar _scheduler: The object in charge of scheduling retries. In this\n        implementation this is parameterized for testing.\n    @ivar _interval: The retry interval for an L{IReactorTime} based scheduler.\n    @ivar _tryLockCall: An L{IDelayedCall} based on C{_interval} that will manage\n        the next retry for acquiring the lock.\n    @ivar _timeoutCall: An L{IDelayedCall} based on C{deferUntilLocked}'s timeout\n        argument.  This is in charge of timing out our attempt to acquire the\n        lock.\n    \"\"\"\n\n    _interval = 1\n    _tryLockCall: Optional[IDelayedCall] = None\n    _timeoutCall: Optional[IDelayedCall] = None\n\n    def __init__(self, name: str, scheduler: Optional[IReactorTime] = None) -> None:\n        \"\"\"\n        @param name: The name of the lock to acquire\n        @param scheduler: An object which provides L{IReactorTime}\n        \"\"\"\n        lockfile.FilesystemLock.__init__(self, name)\n\n        if scheduler is None:\n            from twisted.internet import reactor\n\n            scheduler = cast(IReactorTime, reactor)\n\n        self._scheduler = scheduler\n\n    def deferUntilLocked(self, timeout: Optional[float] = None) -> Deferred[None]:\n        \"\"\"\n        Wait until we acquire this lock.  This method is not safe for\n        concurrent use.\n\n        @param timeout: the number of seconds after which to time out if the\n            lock has not been acquired.\n\n        @return: a L{Deferred} which will callback when the lock is acquired, or\n            errback with a L{TimeoutError} after timing out or an\n            L{AlreadyTryingToLockError} if the L{deferUntilLocked} has already\n            been called and not successfully locked the file.\n        \"\"\"\n        if self._tryLockCall is not None:\n            return fail(\n                AlreadyTryingToLockError(\n                    \"deferUntilLocked isn't safe for concurrent use.\"\n                )\n            )\n\n        def _cancelLock(reason: Union[Failure, Exception]) -> None:\n            \"\"\"\n            Cancel a L{DeferredFilesystemLock.deferUntilLocked} call.\n\n            @type reason: L{Failure}\n            @param reason: The reason why the call is cancelled.\n            \"\"\"\n            assert self._tryLockCall is not None\n            self._tryLockCall.cancel()\n            self._tryLockCall = None\n            if self._timeoutCall is not None and self._timeoutCall.active():\n                self._timeoutCall.cancel()\n                self._timeoutCall = None\n\n            if self.lock():\n                d.callback(None)\n            else:\n                d.errback(reason)\n\n        d: Deferred[None] = Deferred(lambda deferred: _cancelLock(CancelledError()))\n\n        def _tryLock() -> None:\n            if self.lock():\n                if self._timeoutCall is not None:\n                    self._timeoutCall.cancel()\n                    self._timeoutCall = None\n\n                self._tryLockCall = None\n\n                d.callback(None)\n            else:\n                if timeout is not None and self._timeoutCall is None:\n                    reason = Failure(\n                        TimeoutError(\n                            \"Timed out acquiring lock: %s after %fs\"\n                            % (self.name, timeout)\n                        )\n                    )\n                    self._timeoutCall = self._scheduler.callLater(\n                        timeout, _cancelLock, reason\n                    )\n\n                self._tryLockCall = self._scheduler.callLater(self._interval, _tryLock)\n\n        _tryLock()\n\n        return d\n\n\n__all__ = [\n    \"Deferred\",\n    \"DeferredList\",\n    \"succeed\",\n    \"fail\",\n    \"FAILURE\",\n    \"SUCCESS\",\n    \"AlreadyCalledError\",\n    \"TimeoutError\",\n    \"gatherResults\",\n    \"maybeDeferred\",\n    \"ensureDeferred\",\n    \"inlineCallbacks\",\n    \"returnValue\",\n    \"DeferredLock\",\n    \"DeferredSemaphore\",\n    \"DeferredQueue\",\n    \"DeferredFilesystemLock\",\n    \"AlreadyTryingToLockError\",\n    \"CancelledError\",\n]\n\n\n### Dependency File: policies.py\n# -*- test-case-name: twisted.test.test_policies -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nResource limiting policies.\n\n@seealso: See also L{twisted.protocols.htb} for rate limiting.\n\"\"\"\n\n\n# system imports\nimport sys\nfrom typing import Optional, Type\n\nfrom zope.interface import directlyProvides, providedBy\n\nfrom twisted.internet import error, interfaces\nfrom twisted.internet.interfaces import ILoggingContext\n\n# twisted imports\nfrom twisted.internet.protocol import ClientFactory, Protocol, ServerFactory\nfrom twisted.python import log\n\n\ndef _wrappedLogPrefix(wrapper, wrapped):\n    \"\"\"\n    Compute a log prefix for a wrapper and the object it wraps.\n\n    @rtype: C{str}\n    \"\"\"\n    if ILoggingContext.providedBy(wrapped):\n        logPrefix = wrapped.logPrefix()\n    else:\n        logPrefix = wrapped.__class__.__name__\n    return f\"{logPrefix} ({wrapper.__class__.__name__})\"\n\n\nclass ProtocolWrapper(Protocol):\n    \"\"\"\n    Wraps protocol instances and acts as their transport as well.\n\n    @ivar wrappedProtocol: An L{IProtocol<twisted.internet.interfaces.IProtocol>}\n        provider to which L{IProtocol<twisted.internet.interfaces.IProtocol>}\n        method calls onto this L{ProtocolWrapper} will be proxied.\n\n    @ivar factory: The L{WrappingFactory} which created this\n        L{ProtocolWrapper}.\n    \"\"\"\n\n    disconnecting = 0\n\n    def __init__(\n        self, factory: \"WrappingFactory\", wrappedProtocol: interfaces.IProtocol\n    ):\n        self.wrappedProtocol = wrappedProtocol\n        self.factory = factory\n\n    def logPrefix(self):\n        \"\"\"\n        Use a customized log prefix mentioning both the wrapped protocol and\n        the current one.\n        \"\"\"\n        return _wrappedLogPrefix(self, self.wrappedProtocol)\n\n    def makeConnection(self, transport):\n        \"\"\"\n        When a connection is made, register this wrapper with its factory,\n        save the real transport, and connect the wrapped protocol to this\n        L{ProtocolWrapper} to intercept any transport calls it makes.\n        \"\"\"\n        directlyProvides(self, providedBy(transport))\n        Protocol.makeConnection(self, transport)\n        self.factory.registerProtocol(self)\n        self.wrappedProtocol.makeConnection(self)\n\n    # Transport relaying\n\n    def write(self, data):\n        self.transport.write(data)\n\n    def writeSequence(self, data):\n        self.transport.writeSequence(data)\n\n    def loseConnection(self):\n        self.disconnecting = 1\n        self.transport.loseConnection()\n\n    def getPeer(self):\n        return self.transport.getPeer()\n\n    def getHost(self):\n        return self.transport.getHost()\n\n    def registerProducer(self, producer, streaming):\n        self.transport.registerProducer(producer, streaming)\n\n    def unregisterProducer(self):\n        self.transport.unregisterProducer()\n\n    def stopConsuming(self):\n        self.transport.stopConsuming()\n\n    def __getattr__(self, name):\n        return getattr(self.transport, name)\n\n    # Protocol relaying\n\n    def dataReceived(self, data):\n        self.wrappedProtocol.dataReceived(data)\n\n    def connectionLost(self, reason):\n        self.factory.unregisterProtocol(self)\n        self.wrappedProtocol.connectionLost(reason)\n\n        # Breaking reference cycle between self and wrappedProtocol.\n        self.wrappedProtocol = None\n\n\nclass WrappingFactory(ClientFactory):\n    \"\"\"\n    Wraps a factory and its protocols, and keeps track of them.\n    \"\"\"\n\n    protocol: Type[Protocol] = ProtocolWrapper\n\n    def __init__(self, wrappedFactory):\n        self.wrappedFactory = wrappedFactory\n        self.protocols = {}\n\n    def logPrefix(self):\n        \"\"\"\n        Generate a log prefix mentioning both the wrapped factory and this one.\n        \"\"\"\n        return _wrappedLogPrefix(self, self.wrappedFactory)\n\n    def doStart(self):\n        self.wrappedFactory.doStart()\n        ClientFactory.doStart(self)\n\n    def doStop(self):\n        self.wrappedFactory.doStop()\n        ClientFactory.doStop(self)\n\n    def startedConnecting(self, connector):\n        self.wrappedFactory.startedConnecting(connector)\n\n    def clientConnectionFailed(self, connector, reason):\n        self.wrappedFactory.clientConnectionFailed(connector, reason)\n\n    def clientConnectionLost(self, connector, reason):\n        self.wrappedFactory.clientConnectionLost(connector, reason)\n\n    def buildProtocol(self, addr):\n        return self.protocol(self, self.wrappedFactory.buildProtocol(addr))\n\n    def registerProtocol(self, p):\n        \"\"\"\n        Called by protocol to register itself.\n        \"\"\"\n        self.protocols[p] = 1\n\n    def unregisterProtocol(self, p):\n        \"\"\"\n        Called by protocols when they go away.\n        \"\"\"\n        del self.protocols[p]\n\n\nclass ThrottlingProtocol(ProtocolWrapper):\n    \"\"\"\n    Protocol for L{ThrottlingFactory}.\n    \"\"\"\n\n    # wrap API for tracking bandwidth\n\n    def write(self, data):\n        self.factory.registerWritten(len(data))\n        ProtocolWrapper.write(self, data)\n\n    def writeSequence(self, seq):\n        self.factory.registerWritten(sum(map(len, seq)))\n        ProtocolWrapper.writeSequence(self, seq)\n\n    def dataReceived(self, data):\n        self.factory.registerRead(len(data))\n        ProtocolWrapper.dataReceived(self, data)\n\n    def registerProducer(self, producer, streaming):\n        self.producer = producer\n        ProtocolWrapper.registerProducer(self, producer, streaming)\n\n    def unregisterProducer(self):\n        del self.producer\n        ProtocolWrapper.unregisterProducer(self)\n\n    def throttleReads(self):\n        self.transport.pauseProducing()\n\n    def unthrottleReads(self):\n        self.transport.resumeProducing()\n\n    def throttleWrites(self):\n        if hasattr(self, \"producer\"):\n            self.producer.pauseProducing()\n\n    def unthrottleWrites(self):\n        if hasattr(self, \"producer\"):\n            self.producer.resumeProducing()\n\n\nclass ThrottlingFactory(WrappingFactory):\n    \"\"\"\n    Throttles bandwidth and number of connections.\n\n    Write bandwidth will only be throttled if there is a producer\n    registered.\n    \"\"\"\n\n    protocol = ThrottlingProtocol\n\n    def __init__(\n        self,\n        wrappedFactory,\n        maxConnectionCount=sys.maxsize,\n        readLimit=None,\n        writeLimit=None,\n    ):\n        WrappingFactory.__init__(self, wrappedFactory)\n        self.connectionCount = 0\n        self.maxConnectionCount = maxConnectionCount\n        self.readLimit = readLimit  # max bytes we should read per second\n        self.writeLimit = writeLimit  # max bytes we should write per second\n        self.readThisSecond = 0\n        self.writtenThisSecond = 0\n        self.unthrottleReadsID = None\n        self.checkReadBandwidthID = None\n        self.unthrottleWritesID = None\n        self.checkWriteBandwidthID = None\n\n    def callLater(self, period, func):\n        \"\"\"\n        Wrapper around\n        L{reactor.callLater<twisted.internet.interfaces.IReactorTime.callLater>}\n        for test purpose.\n        \"\"\"\n        from twisted.internet import reactor\n\n        return reactor.callLater(period, func)\n\n    def registerWritten(self, length):\n        \"\"\"\n        Called by protocol to tell us more bytes were written.\n        \"\"\"\n        self.writtenThisSecond += length\n\n    def registerRead(self, length):\n        \"\"\"\n        Called by protocol to tell us more bytes were read.\n        \"\"\"\n        self.readThisSecond += length\n\n    def checkReadBandwidth(self):\n        \"\"\"\n        Checks if we've passed bandwidth limits.\n        \"\"\"\n        if self.readThisSecond > self.readLimit:\n            self.throttleReads()\n            throttleTime = (float(self.readThisSecond) / self.readLimit) - 1.0\n            self.unthrottleReadsID = self.callLater(throttleTime, self.unthrottleReads)\n        self.readThisSecond = 0\n        self.checkReadBandwidthID = self.callLater(1, self.checkReadBandwidth)\n\n    def checkWriteBandwidth(self):\n        if self.writtenThisSecond > self.writeLimit:\n            self.throttleWrites()\n            throttleTime = (float(self.writtenThisSecond) / self.writeLimit) - 1.0\n            self.unthrottleWritesID = self.callLater(\n                throttleTime, self.unthrottleWrites\n            )\n        # reset for next round\n        self.writtenThisSecond = 0\n        self.checkWriteBandwidthID = self.callLater(1, self.checkWriteBandwidth)\n\n    def throttleReads(self):\n        \"\"\"\n        Throttle reads on all protocols.\n        \"\"\"\n        log.msg(\"Throttling reads on %s\" % self)\n        for p in self.protocols.keys():\n            p.throttleReads()\n\n    def unthrottleReads(self):\n        \"\"\"\n        Stop throttling reads on all protocols.\n        \"\"\"\n        self.unthrottleReadsID = None\n        log.msg(\"Stopped throttling reads on %s\" % self)\n        for p in self.protocols.keys():\n            p.unthrottleReads()\n\n    def throttleWrites(self):\n        \"\"\"\n        Throttle writes on all protocols.\n        \"\"\"\n        log.msg(\"Throttling writes on %s\" % self)\n        for p in self.protocols.keys():\n            p.throttleWrites()\n\n    def unthrottleWrites(self):\n        \"\"\"\n        Stop throttling writes on all protocols.\n        \"\"\"\n        self.unthrottleWritesID = None\n        log.msg(\"Stopped throttling writes on %s\" % self)\n        for p in self.protocols.keys():\n            p.unthrottleWrites()\n\n    def buildProtocol(self, addr):\n        if self.connectionCount == 0:\n            if self.readLimit is not None:\n                self.checkReadBandwidth()\n            if self.writeLimit is not None:\n                self.checkWriteBandwidth()\n\n        if self.connectionCount < self.maxConnectionCount:\n            self.connectionCount += 1\n            return WrappingFactory.buildProtocol(self, addr)\n        else:\n            log.msg(\"Max connection count reached!\")\n            return None\n\n    def unregisterProtocol(self, p):\n        WrappingFactory.unregisterProtocol(self, p)\n        self.connectionCount -= 1\n        if self.connectionCount == 0:\n            if self.unthrottleReadsID is not None:\n                self.unthrottleReadsID.cancel()\n            if self.checkReadBandwidthID is not None:\n                self.checkReadBandwidthID.cancel()\n            if self.unthrottleWritesID is not None:\n                self.unthrottleWritesID.cancel()\n            if self.checkWriteBandwidthID is not None:\n                self.checkWriteBandwidthID.cancel()\n\n\nclass SpewingProtocol(ProtocolWrapper):\n    def dataReceived(self, data):\n        log.msg(\"Received: %r\" % data)\n        ProtocolWrapper.dataReceived(self, data)\n\n    def write(self, data):\n        log.msg(\"Sending: %r\" % data)\n        ProtocolWrapper.write(self, data)\n\n\nclass SpewingFactory(WrappingFactory):\n    protocol = SpewingProtocol\n\n\nclass LimitConnectionsByPeer(WrappingFactory):\n    maxConnectionsPerPeer = 5\n\n    def startFactory(self):\n        self.peerConnections = {}\n\n    def buildProtocol(self, addr):\n        peerHost = addr[0]\n        connectionCount = self.peerConnections.get(peerHost, 0)\n        if connectionCount >= self.maxConnectionsPerPeer:\n            return None\n        self.peerConnections[peerHost] = connectionCount + 1\n        return WrappingFactory.buildProtocol(self, addr)\n\n    def unregisterProtocol(self, p):\n        peerHost = p.getPeer()[1]\n        self.peerConnections[peerHost] -= 1\n        if self.peerConnections[peerHost] == 0:\n            del self.peerConnections[peerHost]\n\n\nclass LimitTotalConnectionsFactory(ServerFactory):\n    \"\"\"\n    Factory that limits the number of simultaneous connections.\n\n    @type connectionCount: C{int}\n    @ivar connectionCount: number of current connections.\n    @type connectionLimit: C{int} or L{None}\n    @cvar connectionLimit: maximum number of connections.\n    @type overflowProtocol: L{Protocol} or L{None}\n    @cvar overflowProtocol: Protocol to use for new connections when\n        connectionLimit is exceeded.  If L{None} (the default value), excess\n        connections will be closed immediately.\n    \"\"\"\n\n    connectionCount = 0\n    connectionLimit = None\n    overflowProtocol: Optional[Type[Protocol]] = None\n\n    def buildProtocol(self, addr):\n        if self.connectionLimit is None or self.connectionCount < self.connectionLimit:\n            # Build the normal protocol\n            wrappedProtocol = self.protocol()\n        elif self.overflowProtocol is None:\n            # Just drop the connection\n            return None\n        else:\n            # Too many connections, so build the overflow protocol\n            wrappedProtocol = self.overflowProtocol()\n\n        wrappedProtocol.factory = self\n        protocol = ProtocolWrapper(self, wrappedProtocol)\n        self.connectionCount += 1\n        return protocol\n\n    def registerProtocol(self, p):\n        pass\n\n    def unregisterProtocol(self, p):\n        self.connectionCount -= 1\n\n\nclass TimeoutProtocol(ProtocolWrapper):\n    \"\"\"\n    Protocol that automatically disconnects when the connection is idle.\n    \"\"\"\n\n    def __init__(self, factory, wrappedProtocol, timeoutPeriod):\n        \"\"\"\n        Constructor.\n\n        @param factory: An L{TimeoutFactory}.\n        @param wrappedProtocol: A L{Protocol} to wrapp.\n        @param timeoutPeriod: Number of seconds to wait for activity before\n            timing out.\n        \"\"\"\n        ProtocolWrapper.__init__(self, factory, wrappedProtocol)\n        self.timeoutCall = None\n        self.timeoutPeriod = None\n        self.setTimeout(timeoutPeriod)\n\n    def setTimeout(self, timeoutPeriod=None):\n        \"\"\"\n        Set a timeout.\n\n        This will cancel any existing timeouts.\n\n        @param timeoutPeriod: If not L{None}, change the timeout period.\n            Otherwise, use the existing value.\n        \"\"\"\n        self.cancelTimeout()\n        self.timeoutPeriod = timeoutPeriod\n        if timeoutPeriod is not None:\n            self.timeoutCall = self.factory.callLater(\n                self.timeoutPeriod, self.timeoutFunc\n            )\n\n    def cancelTimeout(self):\n        \"\"\"\n        Cancel the timeout.\n\n        If the timeout was already cancelled, this does nothing.\n        \"\"\"\n        self.timeoutPeriod = None\n        if self.timeoutCall:\n            try:\n                self.timeoutCall.cancel()\n            except (error.AlreadyCalled, error.AlreadyCancelled):\n                pass\n            self.timeoutCall = None\n\n    def resetTimeout(self):\n        \"\"\"\n        Reset the timeout, usually because some activity just happened.\n        \"\"\"\n        if self.timeoutCall:\n            self.timeoutCall.reset(self.timeoutPeriod)\n\n    def write(self, data):\n        self.resetTimeout()\n        ProtocolWrapper.write(self, data)\n\n    def writeSequence(self, seq):\n        self.resetTimeout()\n        ProtocolWrapper.writeSequence(self, seq)\n\n    def dataReceived(self, data):\n        self.resetTimeout()\n        ProtocolWrapper.dataReceived(self, data)\n\n    def connectionLost(self, reason):\n        self.cancelTimeout()\n        ProtocolWrapper.connectionLost(self, reason)\n\n    def timeoutFunc(self):\n        \"\"\"\n        This method is called when the timeout is triggered.\n\n        By default it calls I{loseConnection}.  Override this if you want\n        something else to happen.\n        \"\"\"\n        self.loseConnection()\n\n\nclass TimeoutFactory(WrappingFactory):\n    \"\"\"\n    Factory for TimeoutWrapper.\n    \"\"\"\n\n    protocol = TimeoutProtocol\n\n    def __init__(self, wrappedFactory, timeoutPeriod=30 * 60):\n        self.timeoutPeriod = timeoutPeriod\n        WrappingFactory.__init__(self, wrappedFactory)\n\n    def buildProtocol(self, addr):\n        return self.protocol(\n            self,\n            self.wrappedFactory.buildProtocol(addr),\n            timeoutPeriod=self.timeoutPeriod,\n        )\n\n    def callLater(self, period, func):\n        \"\"\"\n        Wrapper around\n        L{reactor.callLater<twisted.internet.interfaces.IReactorTime.callLater>}\n        for test purpose.\n        \"\"\"\n        from twisted.internet import reactor\n\n        return reactor.callLater(period, func)\n\n\nclass TrafficLoggingProtocol(ProtocolWrapper):\n    def __init__(self, factory, wrappedProtocol, logfile, lengthLimit=None, number=0):\n        \"\"\"\n        @param factory: factory which created this protocol.\n        @type factory: L{protocol.Factory}.\n        @param wrappedProtocol: the underlying protocol.\n        @type wrappedProtocol: C{protocol.Protocol}.\n        @param logfile: file opened for writing used to write log messages.\n        @type logfile: C{file}\n        @param lengthLimit: maximum size of the datareceived logged.\n        @type lengthLimit: C{int}\n        @param number: identifier of the connection.\n        @type number: C{int}.\n        \"\"\"\n        ProtocolWrapper.__init__(self, factory, wrappedProtocol)\n        self.logfile = logfile\n        self.lengthLimit = lengthLimit\n        self._number = number\n\n    def _log(self, line):\n        self.logfile.write(line + \"\\n\")\n        self.logfile.flush()\n\n    def _mungeData(self, data):\n        if self.lengthLimit and len(data) > self.lengthLimit:\n            data = data[: self.lengthLimit - 12] + \"<... elided>\"\n        return data\n\n    # IProtocol\n    def connectionMade(self):\n        self._log(\"*\")\n        return ProtocolWrapper.connectionMade(self)\n\n    def dataReceived(self, data):\n        self._log(\"C %d: %r\" % (self._number, self._mungeData(data)))\n        return ProtocolWrapper.dataReceived(self, data)\n\n    def connectionLost(self, reason):\n        self._log(\"C %d: %r\" % (self._number, reason))\n        return ProtocolWrapper.connectionLost(self, reason)\n\n    # ITransport\n    def write(self, data):\n        self._log(\"S %d: %r\" % (self._number, self._mungeData(data)))\n        return ProtocolWrapper.write(self, data)\n\n    def writeSequence(self, iovec):\n        self._log(\"SV %d: %r\" % (self._number, [self._mungeData(d) for d in iovec]))\n        return ProtocolWrapper.writeSequence(self, iovec)\n\n    def loseConnection(self):\n        self._log(\"S %d: *\" % (self._number,))\n        return ProtocolWrapper.loseConnection(self)\n\n\nclass TrafficLoggingFactory(WrappingFactory):\n    protocol = TrafficLoggingProtocol\n\n    _counter = 0\n\n    def __init__(self, wrappedFactory, logfilePrefix, lengthLimit=None):\n        self.logfilePrefix = logfilePrefix\n        self.lengthLimit = lengthLimit\n        WrappingFactory.__init__(self, wrappedFactory)\n\n    def open(self, name):\n        return open(name, \"w\")\n\n    def buildProtocol(self, addr):\n        self._counter += 1\n        logfile = self.open(self.logfilePrefix + \"-\" + str(self._counter))\n        return self.protocol(\n            self,\n            self.wrappedFactory.buildProtocol(addr),\n            logfile,\n            self.lengthLimit,\n            self._counter,\n        )\n\n    def resetCounter(self):\n        \"\"\"\n        Reset the value of the counter used to identify connections.\n        \"\"\"\n        self._counter = 0\n\n\nclass TimeoutMixin:\n    \"\"\"\n    Mixin for protocols which wish to timeout connections.\n\n    Protocols that mix this in have a single timeout, set using L{setTimeout}.\n    When the timeout is hit, L{timeoutConnection} is called, which, by\n    default, closes the connection.\n\n    @cvar timeOut: The number of seconds after which to timeout the connection.\n    \"\"\"\n\n    timeOut: Optional[int] = None\n\n    __timeoutCall = None\n\n    def callLater(self, period, func):\n        \"\"\"\n        Wrapper around\n        L{reactor.callLater<twisted.internet.interfaces.IReactorTime.callLater>}\n        for test purpose.\n        \"\"\"\n        from twisted.internet import reactor\n\n        return reactor.callLater(period, func)\n\n    def resetTimeout(self):\n        \"\"\"\n        Reset the timeout count down.\n\n        If the connection has already timed out, then do nothing.  If the\n        timeout has been cancelled (probably using C{setTimeout(None)}), also\n        do nothing.\n\n        It's often a good idea to call this when the protocol has received\n        some meaningful input from the other end of the connection.  \"I've got\n        some data, they're still there, reset the timeout\".\n        \"\"\"\n        if self.__timeoutCall is not None and self.timeOut is not None:\n            self.__timeoutCall.reset(self.timeOut)\n\n    def setTimeout(self, period):\n        \"\"\"\n        Change the timeout period\n\n        @type period: C{int} or L{None}\n        @param period: The period, in seconds, to change the timeout to, or\n        L{None} to disable the timeout.\n        \"\"\"\n        prev = self.timeOut\n        self.timeOut = period\n\n        if self.__timeoutCall is not None:\n            if period is None:\n                try:\n                    self.__timeoutCall.cancel()\n                except (error.AlreadyCancelled, error.AlreadyCalled):\n                    # Do nothing if the call was already consumed.\n                    pass\n                self.__timeoutCall = None\n            else:\n                self.__timeoutCall.reset(period)\n        elif period is not None:\n            self.__timeoutCall = self.callLater(period, self.__timedOut)\n\n        return prev\n\n    def __timedOut(self):\n        self.__timeoutCall = None\n        self.timeoutConnection()\n\n    def timeoutConnection(self):\n        \"\"\"\n        Called when the connection times out.\n\n        Override to define behavior other than dropping the connection.\n        \"\"\"\n        self.transport.loseConnection()\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
{"messages": [{"role": "system", "content": "You are an AI agent expert in writing unit tests. Your task is to write unit tests for the given code files of the repository. Make sure the tests can be executed without lint or compile errors."}, {"role": "user", "content": "### Task Information\nBased on the source code, write/rewrite tests to cover the source code.\nRepository: twisted\nTest File Path: twisted\\test_reflect\\test_reflect.py\nProject Programming Language: Python\nTesting Framework: pytest\n### Source File Content\n### Source File Content:\n# -*- test-case-name: twisted.test.test_reflect -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nStandardized versions of various cool and/or strange things that you can do\nwith Python's reflection capabilities.\n\"\"\"\n\n\nimport os\nimport pickle\nimport re\nimport sys\nimport traceback\nimport types\nimport weakref\nfrom collections import deque\nfrom io import IOBase, StringIO\nfrom typing import Type, Union\n\nfrom twisted.python.compat import nativeString\nfrom twisted.python.deprecate import _fullyQualifiedName as fullyQualifiedName\n\nRegexType = type(re.compile(\"\"))\n\n\ndef prefixedMethodNames(classObj, prefix):\n    \"\"\"\n    Given a class object C{classObj}, returns a list of method names that match\n    the string C{prefix}.\n\n    @param classObj: A class object from which to collect method names.\n\n    @param prefix: A native string giving a prefix.  Each method with a name\n        which begins with this prefix will be returned.\n    @type prefix: L{str}\n\n    @return: A list of the names of matching methods of C{classObj} (and base\n        classes of C{classObj}).\n    @rtype: L{list} of L{str}\n    \"\"\"\n    dct = {}\n    addMethodNamesToDict(classObj, dct, prefix)\n    return list(dct.keys())\n\n\ndef addMethodNamesToDict(classObj, dict, prefix, baseClass=None):\n    \"\"\"\n    This goes through C{classObj} (and its bases) and puts method names\n    starting with 'prefix' in 'dict' with a value of 1. if baseClass isn't\n    None, methods will only be added if classObj is-a baseClass\n\n    If the class in question has the methods 'prefix_methodname' and\n    'prefix_methodname2', the resulting dict should look something like:\n    {\"methodname\": 1, \"methodname2\": 1}.\n\n    @param classObj: A class object from which to collect method names.\n\n    @param dict: A L{dict} which will be updated with the results of the\n        accumulation.  Items are added to this dictionary, with method names as\n        keys and C{1} as values.\n    @type dict: L{dict}\n\n    @param prefix: A native string giving a prefix.  Each method of C{classObj}\n        (and base classes of C{classObj}) with a name which begins with this\n        prefix will be returned.\n    @type prefix: L{str}\n\n    @param baseClass: A class object at which to stop searching upwards for new\n        methods.  To collect all method names, do not pass a value for this\n        parameter.\n\n    @return: L{None}\n    \"\"\"\n    for base in classObj.__bases__:\n        addMethodNamesToDict(base, dict, prefix, baseClass)\n\n    if baseClass is None or baseClass in classObj.__bases__:\n        for name, method in classObj.__dict__.items():\n            optName = name[len(prefix) :]\n            if (\n                (type(method) is types.FunctionType)\n                and (name[: len(prefix)] == prefix)\n                and (len(optName))\n            ):\n                dict[optName] = 1\n\n\ndef prefixedMethods(obj, prefix=\"\"):\n    \"\"\"\n    Given an object C{obj}, returns a list of method objects that match the\n    string C{prefix}.\n\n    @param obj: An arbitrary object from which to collect methods.\n\n    @param prefix: A native string giving a prefix.  Each method of C{obj} with\n        a name which begins with this prefix will be returned.\n    @type prefix: L{str}\n\n    @return: A list of the matching method objects.\n    @rtype: L{list}\n    \"\"\"\n    dct = {}\n    accumulateMethods(obj, dct, prefix)\n    return list(dct.values())\n\n\ndef accumulateMethods(obj, dict, prefix=\"\", curClass=None):\n    \"\"\"\n    Given an object C{obj}, add all methods that begin with C{prefix}.\n\n    @param obj: An arbitrary object to collect methods from.\n\n    @param dict: A L{dict} which will be updated with the results of the\n        accumulation.  Items are added to this dictionary, with method names as\n        keys and corresponding instance method objects as values.\n    @type dict: L{dict}\n\n    @param prefix: A native string giving a prefix.  Each method of C{obj} with\n        a name which begins with this prefix will be returned.\n    @type prefix: L{str}\n\n    @param curClass: The class in the inheritance hierarchy at which to start\n        collecting methods.  Collection proceeds up.  To collect all methods\n        from C{obj}, do not pass a value for this parameter.\n\n    @return: L{None}\n    \"\"\"\n    if not curClass:\n        curClass = obj.__class__\n    for base in curClass.__bases__:\n        # The implementation of the object class is different on PyPy vs.\n        # CPython.  This has the side effect of making accumulateMethods()\n        # pick up object methods from all new-style classes -\n        # such as __getattribute__, etc.\n        # If we ignore 'object' when accumulating methods, we can get\n        # consistent behavior on Pypy and CPython.\n        if base is not object:\n            accumulateMethods(obj, dict, prefix, base)\n\n    for name, method in curClass.__dict__.items():\n        optName = name[len(prefix) :]\n        if (\n            (type(method) is types.FunctionType)\n            and (name[: len(prefix)] == prefix)\n            and (len(optName))\n        ):\n            dict[optName] = getattr(obj, name)\n\n\ndef namedModule(name):\n    \"\"\"\n    Return a module given its name.\n    \"\"\"\n    topLevel = __import__(name)\n    packages = name.split(\".\")[1:]\n    m = topLevel\n    for p in packages:\n        m = getattr(m, p)\n    return m\n\n\ndef namedObject(name):\n    \"\"\"\n    Get a fully named module-global object.\n    \"\"\"\n    classSplit = name.split(\".\")\n    module = namedModule(\".\".join(classSplit[:-1]))\n    return getattr(module, classSplit[-1])\n\n\nnamedClass = namedObject  # backwards compat\n\n\ndef requireModule(name, default=None):\n    \"\"\"\n    Try to import a module given its name, returning C{default} value if\n    C{ImportError} is raised during import.\n\n    @param name: Module name as it would have been passed to C{import}.\n    @type name: C{str}.\n\n    @param default: Value returned in case C{ImportError} is raised while\n        importing the module.\n\n    @return: Module or default value.\n    \"\"\"\n    try:\n        return namedModule(name)\n    except ImportError:\n        return default\n\n\nclass _NoModuleFound(Exception):\n    \"\"\"\n    No module was found because none exists.\n    \"\"\"\n\n\nclass InvalidName(ValueError):\n    \"\"\"\n    The given name is not a dot-separated list of Python objects.\n    \"\"\"\n\n\nclass ModuleNotFound(InvalidName):\n    \"\"\"\n    The module associated with the given name doesn't exist and it can't be\n    imported.\n    \"\"\"\n\n\nclass ObjectNotFound(InvalidName):\n    \"\"\"\n    The object associated with the given name doesn't exist and it can't be\n    imported.\n    \"\"\"\n\n\ndef _importAndCheckStack(importName):\n    \"\"\"\n    Import the given name as a module, then walk the stack to determine whether\n    the failure was the module not existing, or some code in the module (for\n    example a dependent import) failing.  This can be helpful to determine\n    whether any actual application code was run.  For example, to distiguish\n    administrative error (entering the wrong module name), from programmer\n    error (writing buggy code in a module that fails to import).\n\n    @param importName: The name of the module to import.\n    @type importName: C{str}\n    @raise Exception: if something bad happens.  This can be any type of\n        exception, since nobody knows what loading some arbitrary code might\n        do.\n    @raise _NoModuleFound: if no module was found.\n    \"\"\"\n    try:\n        return __import__(importName)\n    except ImportError:\n        excType, excValue, excTraceback = sys.exc_info()\n        while excTraceback:\n            execName = excTraceback.tb_frame.f_globals[\"__name__\"]\n            if execName == importName:\n                raise excValue.with_traceback(excTraceback)\n            excTraceback = excTraceback.tb_next\n        raise _NoModuleFound()\n\n\ndef namedAny(name):\n    \"\"\"\n    Retrieve a Python object by its fully qualified name from the global Python\n    module namespace.  The first part of the name, that describes a module,\n    will be discovered and imported.  Each subsequent part of the name is\n    treated as the name of an attribute of the object specified by all of the\n    name which came before it.  For example, the fully-qualified name of this\n    object is 'twisted.python.reflect.namedAny'.\n\n    @type name: L{str}\n    @param name: The name of the object to return.\n\n    @raise InvalidName: If the name is an empty string, starts or ends with\n        a '.', or is otherwise syntactically incorrect.\n\n    @raise ModuleNotFound: If the name is syntactically correct but the\n        module it specifies cannot be imported because it does not appear to\n        exist.\n\n    @raise ObjectNotFound: If the name is syntactically correct, includes at\n        least one '.', but the module it specifies cannot be imported because\n        it does not appear to exist.\n\n    @raise AttributeError: If an attribute of an object along the way cannot be\n        accessed, or a module along the way is not found.\n\n    @return: the Python object identified by 'name'.\n    \"\"\"\n    if not name:\n        raise InvalidName(\"Empty module name\")\n\n    names = name.split(\".\")\n\n    # if the name starts or ends with a '.' or contains '..', the __import__\n    # will raise an 'Empty module name' error. This will provide a better error\n    # message.\n    if \"\" in names:\n        raise InvalidName(\n            \"name must be a string giving a '.'-separated list of Python \"\n            \"identifiers, not %r\" % (name,)\n        )\n\n    topLevelPackage = None\n    moduleNames = names[:]\n    while not topLevelPackage:\n        if moduleNames:\n            trialname = \".\".join(moduleNames)\n            try:\n                topLevelPackage = _importAndCheckStack(trialname)\n            except _NoModuleFound:\n                moduleNames.pop()\n        else:\n            if len(names) == 1:\n                raise ModuleNotFound(f\"No module named {name!r}\")\n            else:\n                raise ObjectNotFound(f\"{name!r} does not name an object\")\n\n    obj = topLevelPackage\n    for n in names[1:]:\n        obj = getattr(obj, n)\n\n    return obj\n\n\ndef filenameToModuleName(fn):\n    \"\"\"\n    Convert a name in the filesystem to the name of the Python module it is.\n\n    This is aggressive about getting a module name back from a file; it will\n    always return a string.  Aggressive means 'sometimes wrong'; it won't look\n    at the Python path or try to do any error checking: don't use this method\n    unless you already know that the filename you're talking about is a Python\n    module.\n\n    @param fn: A filesystem path to a module or package; C{bytes} on Python 2,\n        C{bytes} or C{unicode} on Python 3.\n\n    @return: A hopefully importable module name.\n    @rtype: C{str}\n    \"\"\"\n    if isinstance(fn, bytes):\n        initPy = b\"__init__.py\"\n    else:\n        initPy = \"__init__.py\"\n    fullName = os.path.abspath(fn)\n    base = os.path.basename(fn)\n    if not base:\n        # this happens when fn ends with a path separator, just skit it\n        base = os.path.basename(fn[:-1])\n    modName = nativeString(os.path.splitext(base)[0])\n    while 1:\n        fullName = os.path.dirname(fullName)\n        if os.path.exists(os.path.join(fullName, initPy)):\n            modName = \"{}.{}\".format(\n                nativeString(os.path.basename(fullName)),\n                nativeString(modName),\n            )\n        else:\n            break\n    return modName\n\n\ndef qual(clazz: Type[object]) -> str:\n    \"\"\"\n    Return full import path of a class.\n    \"\"\"\n    return clazz.__module__ + \".\" + clazz.__name__\n\n\ndef _determineClass(x):\n    try:\n        return x.__class__\n    except BaseException:\n        return type(x)\n\n\ndef _determineClassName(x):\n    c = _determineClass(x)\n    try:\n        return c.__name__\n    except BaseException:\n        try:\n            return str(c)\n        except BaseException:\n            return \"<BROKEN CLASS AT 0x%x>\" % id(c)\n\n\ndef _safeFormat(formatter: Union[types.FunctionType, Type[str]], o: object) -> str:\n    \"\"\"\n    Helper function for L{safe_repr} and L{safe_str}.\n\n    Called when C{repr} or C{str} fail. Returns a string containing info about\n    C{o} and the latest exception.\n\n    @param formatter: C{str} or C{repr}.\n    @type formatter: C{type}\n    @param o: Any object.\n\n    @rtype: C{str}\n    @return: A string containing information about C{o} and the raised\n        exception.\n    \"\"\"\n    io = StringIO()\n    traceback.print_exc(file=io)\n    className = _determineClassName(o)\n    tbValue = io.getvalue()\n    return \"<{} instance at 0x{:x} with {} error:\\n {}>\".format(\n        className,\n        id(o),\n        formatter.__name__,\n        tbValue,\n    )\n\n\ndef safe_repr(o):\n    \"\"\"\n    Returns a string representation of an object, or a string containing a\n    traceback, if that object's __repr__ raised an exception.\n\n    @param o: Any object.\n\n    @rtype: C{str}\n    \"\"\"\n    try:\n        return repr(o)\n    except BaseException:\n        return _safeFormat(repr, o)\n\n\ndef safe_str(o: object) -> str:\n    \"\"\"\n    Returns a string representation of an object, or a string containing a\n    traceback, if that object's __str__ raised an exception.\n\n    @param o: Any object.\n    \"\"\"\n    if isinstance(o, bytes):\n        # If o is bytes and seems to holds a utf-8 encoded string,\n        # convert it to str.\n        try:\n            return o.decode(\"utf-8\")\n        except BaseException:\n            pass\n    try:\n        return str(o)\n    except BaseException:\n        return _safeFormat(str, o)\n\n\nclass QueueMethod:\n    \"\"\"\n    I represent a method that doesn't exist yet.\n    \"\"\"\n\n    def __init__(self, name, calls):\n        self.name = name\n        self.calls = calls\n\n    def __call__(self, *args):\n        self.calls.append((self.name, args))\n\n\ndef fullFuncName(func):\n    qualName = str(pickle.whichmodule(func, func.__name__)) + \".\" + func.__name__\n    if namedObject(qualName) is not func:\n        raise Exception(f\"Couldn't find {func} as {qualName}.\")\n    return qualName\n\n\ndef getClass(obj):\n    \"\"\"\n    Return the class or type of object 'obj'.\n    \"\"\"\n    return type(obj)\n\n\ndef accumulateClassDict(classObj, attr, adict, baseClass=None):\n    \"\"\"\n    Accumulate all attributes of a given name in a class hierarchy into a single dictionary.\n\n    Assuming all class attributes of this name are dictionaries.\n    If any of the dictionaries being accumulated have the same key, the\n    one highest in the class hierarchy wins.\n    (XXX: If \\\"highest\\\" means \\\"closest to the starting class\\\".)\n\n    Ex::\n\n      class Soy:\n        properties = {\\\"taste\\\": \\\"bland\\\"}\n\n      class Plant:\n        properties = {\\\"colour\\\": \\\"green\\\"}\n\n      class Seaweed(Plant):\n        pass\n\n      class Lunch(Soy, Seaweed):\n        properties = {\\\"vegan\\\": 1 }\n\n      dct = {}\n\n      accumulateClassDict(Lunch, \\\"properties\\\", dct)\n\n      print(dct)\n\n    {\\\"taste\\\": \\\"bland\\\", \\\"colour\\\": \\\"green\\\", \\\"vegan\\\": 1}\n    \"\"\"\n    for base in classObj.__bases__:\n        accumulateClassDict(base, attr, adict)\n    if baseClass is None or baseClass in classObj.__bases__:\n        adict.update(classObj.__dict__.get(attr, {}))\n\n\ndef accumulateClassList(classObj, attr, listObj, baseClass=None):\n    \"\"\"\n    Accumulate all attributes of a given name in a class hierarchy into a single list.\n\n    Assuming all class attributes of this name are lists.\n    \"\"\"\n    for base in classObj.__bases__:\n        accumulateClassList(base, attr, listObj)\n    if baseClass is None or baseClass in classObj.__bases__:\n        listObj.extend(classObj.__dict__.get(attr, []))\n\n\ndef isSame(a, b):\n    return a is b\n\n\ndef isLike(a, b):\n    return a == b\n\n\ndef modgrep(goal):\n    return objgrep(sys.modules, goal, isLike, \"sys.modules\")\n\n\ndef isOfType(start, goal):\n    return type(start) is goal\n\n\ndef findInstances(start, t):\n    return objgrep(start, t, isOfType)\n\n\ndef objgrep(\n    start,\n    goal,\n    eq=isLike,\n    path=\"\",\n    paths=None,\n    seen=None,\n    showUnknowns=0,\n    maxDepth=None,\n):\n    \"\"\"\n    L{objgrep} finds paths between C{start} and C{goal}.\n\n    Starting at the python object C{start}, we will loop over every reachable\n    reference, tring to find the python object C{goal} (i.e. every object\n    C{candidate} for whom C{eq(candidate, goal)} is truthy), and return a\n    L{list} of L{str}, where each L{str} is Python syntax for a path between\n    C{start} and C{goal}.\n\n    Since this can be slightly difficult to visualize, here's an example::\n\n        >>> class Holder:\n        ...     def __init__(self, x):\n        ...         self.x = x\n        ...\n        >>> start = Holder({\"irrelevant\": \"ignore\",\n        ...                 \"relevant\": [7, 1, 3, 5, 7]})\n        >>> for path in objgrep(start, 7):\n        ...     print(\"start\" + path)\n        start.x['relevant'][0]\n        start.x['relevant'][4]\n\n    This can be useful, for example, when debugging stateful graphs of objects\n    attached to a socket, trying to figure out where a particular connection is\n    attached.\n\n    @param start: The object to start looking at.\n\n    @param goal: The object to search for.\n\n    @param eq: A 2-argument predicate which takes an object found by traversing\n        references starting at C{start}, as well as C{goal}, and returns a\n        boolean.\n\n    @param path: The prefix of the path to include in every return value; empty\n        by default.\n\n    @param paths: The result object to append values to; a list of strings.\n\n    @param seen: A dictionary mapping ints (object IDs) to objects already\n        seen.\n\n    @param showUnknowns: if true, print a message to C{stdout} when\n        encountering objects that C{objgrep} does not know how to traverse.\n\n    @param maxDepth: The maximum number of object references to attempt\n        traversing before giving up.  If an integer, limit to that many links,\n        if C{None}, unlimited.\n\n    @return: A list of strings representing python object paths starting at\n        C{start} and terminating at C{goal}.\n    \"\"\"\n    if paths is None:\n        paths = []\n    if seen is None:\n        seen = {}\n    if eq(start, goal):\n        paths.append(path)\n    if id(start) in seen:\n        if seen[id(start)] is start:\n            return\n    if maxDepth is not None:\n        if maxDepth == 0:\n            return\n        maxDepth -= 1\n    seen[id(start)] = start\n    # Make an alias for those arguments which are passed recursively to\n    # objgrep for container objects.\n    args = (paths, seen, showUnknowns, maxDepth)\n    if isinstance(start, dict):\n        for k, v in start.items():\n            objgrep(k, goal, eq, path + \"{\" + repr(v) + \"}\", *args)\n            objgrep(v, goal, eq, path + \"[\" + repr(k) + \"]\", *args)\n    elif isinstance(start, (list, tuple, deque)):\n        for idx, _elem in enumerate(start):\n            objgrep(start[idx], goal, eq, path + \"[\" + str(idx) + \"]\", *args)\n    elif isinstance(start, types.MethodType):\n        objgrep(start.__self__, goal, eq, path + \".__self__\", *args)\n        objgrep(start.__func__, goal, eq, path + \".__func__\", *args)\n        objgrep(start.__self__.__class__, goal, eq, path + \".__self__.__class__\", *args)\n    elif hasattr(start, \"__dict__\"):\n        for k, v in start.__dict__.items():\n            objgrep(v, goal, eq, path + \".\" + k, *args)\n    elif isinstance(start, weakref.ReferenceType):\n        objgrep(start(), goal, eq, path + \"()\", *args)\n    elif isinstance(\n        start,\n        (\n            str,\n            int,\n            types.FunctionType,\n            types.BuiltinMethodType,\n            RegexType,\n            float,\n            type(None),\n            IOBase,\n        ),\n    ) or type(start).__name__ in (\n        \"wrapper_descriptor\",\n        \"method_descriptor\",\n        \"member_descriptor\",\n        \"getset_descriptor\",\n    ):\n        pass\n    elif showUnknowns:\n        print(\"unknown type\", type(start), start)\n    return paths\n\n\n__all__ = [\n    \"InvalidName\",\n    \"ModuleNotFound\",\n    \"ObjectNotFound\",\n    \"QueueMethod\",\n    \"namedModule\",\n    \"namedObject\",\n    \"namedClass\",\n    \"namedAny\",\n    \"requireModule\",\n    \"safe_repr\",\n    \"safe_str\",\n    \"prefixedMethodNames\",\n    \"addMethodNamesToDict\",\n    \"prefixedMethods\",\n    \"accumulateMethods\",\n    \"fullFuncName\",\n    \"qual\",\n    \"getClass\",\n    \"accumulateClassDict\",\n    \"accumulateClassList\",\n    \"isSame\",\n    \"isLike\",\n    \"modgrep\",\n    \"isOfType\",\n    \"findInstances\",\n    \"objgrep\",\n    \"filenameToModuleName\",\n    \"fullyQualifiedName\",\n]\n\n\n# This is to be removed when fixing #6986\n__all__.remove(\"objgrep\")\n\n### Source File Dependency Files Content\n### Dependency File: compat.py\n# -*- test-case-name: twisted.test.test_compat -*-\n#\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\n\"\"\"\nCompatibility module to provide backwards compatibility for useful Python\nfeatures.\n\nThis is mainly for use of internal Twisted code. We encourage you to use\nthe latest version of Python directly from your code, if possible.\n\n@var unicode: The type of Unicode strings, C{unicode} on Python 2 and C{str}\n    on Python 3.\n\n@var NativeStringIO: An in-memory file-like object that operates on the native\n    string type (bytes in Python 2, unicode in Python 3).\n\n@var urllib_parse: a URL-parsing module (urlparse on Python 2, urllib.parse on\n    Python 3)\n\"\"\"\n\n\nimport inspect\nimport os\nimport platform\nimport socket\nimport urllib.parse as urllib_parse\nfrom collections.abc import Sequence\nfrom functools import reduce\nfrom html import escape\nfrom http import cookiejar as cookielib\nfrom io import IOBase, StringIO as NativeStringIO, TextIOBase\nfrom sys import intern\nfrom types import FrameType, MethodType as _MethodType\nfrom typing import Any, AnyStr, cast\nfrom urllib.parse import quote as urlquote, unquote as urlunquote\n\nfrom incremental import Version\n\nfrom twisted.python.deprecate import deprecated, deprecatedModuleAttribute\n\nif platform.python_implementation() == \"PyPy\":\n    _PYPY = True\nelse:\n    _PYPY = False\n\nFileType = IOBase\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for io.IOBase\",\n    __name__,\n    \"FileType\",\n)\n\nfrozenset = frozenset\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for frozenset builtin type\",\n    __name__,\n    \"frozenset\",\n)\n\nInstanceType = object\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Old-style classes don't exist in Python 3\",\n    __name__,\n    \"InstanceType\",\n)\n\nizip = zip\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for zip() builtin\",\n    __name__,\n    \"izip\",\n)\n\nlong = int\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for int builtin type\",\n    __name__,\n    \"long\",\n)\n\nrange = range\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for range() builtin\",\n    __name__,\n    \"range\",\n)\n\nraw_input = input\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for input() builtin\",\n    __name__,\n    \"raw_input\",\n)\n\nset = set\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for set builtin type\",\n    __name__,\n    \"set\",\n)\n\nStringType = str\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for str builtin type\",\n    __name__,\n    \"StringType\",\n)\n\nunichr = chr\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for chr() builtin\",\n    __name__,\n    \"unichr\",\n)\n\nunicode = str\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for str builtin type\",\n    __name__,\n    \"unicode\",\n)\n\nxrange = range\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Obsolete alias for range() builtin\",\n    __name__,\n    \"xrange\",\n)\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"d.items()\")\ndef iteritems(d):\n    \"\"\"\n    Return an iterable of the items of C{d}.\n\n    @type d: L{dict}\n    @rtype: iterable\n    \"\"\"\n    return d.items()\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"d.values()\")\ndef itervalues(d):\n    \"\"\"\n    Return an iterable of the values of C{d}.\n\n    @type d: L{dict}\n    @rtype: iterable\n    \"\"\"\n    return d.values()\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"list(d.items())\")\ndef items(d):\n    \"\"\"\n    Return a list of the items of C{d}.\n\n    @type d: L{dict}\n    @rtype: L{list}\n    \"\"\"\n    return list(d.items())\n\n\ndef currentframe(n: int = 0) -> FrameType:\n    \"\"\"\n    In Python 3, L{inspect.currentframe} does not take a stack-level argument.\n    Restore that functionality from Python 2 so we don't have to re-implement\n    the C{f_back}-walking loop in places where it's called.\n\n    @param n: The number of stack levels above the caller to walk.\n\n    @return: a frame, n levels up the stack from the caller.\n    \"\"\"\n    f = inspect.currentframe()\n    for x in range(n + 1):\n        assert f is not None\n        f = f.f_back\n    assert f is not None\n    return f\n\n\ndef execfile(filename, globals, locals=None):\n    \"\"\"\n    Execute a Python script in the given namespaces.\n\n    Similar to the execfile builtin, but a namespace is mandatory, partly\n    because that's a sensible thing to require, and because otherwise we'd\n    have to do some frame hacking.\n\n    This is a compatibility implementation for Python 3 porting, to avoid the\n    use of the deprecated builtin C{execfile} function.\n    \"\"\"\n    if locals is None:\n        locals = globals\n    with open(filename, \"rb\") as fin:\n        source = fin.read()\n    code = compile(source, filename, \"exec\")\n    exec(code, globals, locals)\n\n\n# type note: Can't find a Comparable type, despite\n# https://github.com/python/typing/issues/59\ndef cmp(a: object, b: object) -> int:\n    \"\"\"\n    Compare two objects.\n\n    Returns a negative number if C{a < b}, zero if they are equal, and a\n    positive number if C{a > b}.\n    \"\"\"\n    if a < b:  # type: ignore[operator]\n        return -1\n    elif a == b:\n        return 0\n    else:\n        return 1\n\n\ndef comparable(klass):\n    \"\"\"\n    Class decorator that ensures support for the special C{__cmp__} method.\n\n    C{__eq__}, C{__lt__}, etc. methods are added to the class, relying on\n    C{__cmp__} to implement their comparisons.\n    \"\"\"\n\n    def __eq__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c == 0\n\n    def __ne__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c != 0\n\n    def __lt__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c < 0\n\n    def __le__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c <= 0\n\n    def __gt__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c > 0\n\n    def __ge__(self: Any, other: object) -> bool:\n        c = cast(bool, self.__cmp__(other))\n        if c is NotImplemented:\n            return c\n        return c >= 0\n\n    klass.__lt__ = __lt__\n    klass.__gt__ = __gt__\n    klass.__le__ = __le__\n    klass.__ge__ = __ge__\n    klass.__eq__ = __eq__\n    klass.__ne__ = __ne__\n    return klass\n\n\ndef ioType(fileIshObject, default=str):\n    \"\"\"\n    Determine the type which will be returned from the given file object's\n    read() and accepted by its write() method as an argument.\n\n    In other words, determine whether the given file is 'opened in text mode'.\n\n    @param fileIshObject: Any object, but ideally one which resembles a file.\n    @type fileIshObject: L{object}\n\n    @param default: A default value to return when the type of C{fileIshObject}\n        cannot be determined.\n    @type default: L{type}\n\n    @return: There are 3 possible return values:\n\n            1. L{str}, if the file is unambiguously opened in text mode.\n\n            2. L{bytes}, if the file is unambiguously opened in binary mode.\n\n            3. The C{default} parameter, if the given type is not understood.\n\n    @rtype: L{type}\n    \"\"\"\n    if isinstance(fileIshObject, TextIOBase):\n        # If it's for text I/O, then it's for text I/O.\n        return str\n    if isinstance(fileIshObject, IOBase):\n        # If it's for I/O but it's _not_ for text I/O, it's for bytes I/O.\n        return bytes\n    encoding = getattr(fileIshObject, \"encoding\", None)\n    import codecs\n\n    if isinstance(fileIshObject, (codecs.StreamReader, codecs.StreamWriter)):\n        # On StreamReaderWriter, the 'encoding' attribute has special meaning;\n        # it is unambiguously text.\n        if encoding:\n            return str\n        else:\n            return bytes\n    return default\n\n\ndef nativeString(s: AnyStr) -> str:\n    \"\"\"\n    Convert C{bytes} or C{str} to C{str} type, using ASCII encoding if\n    conversion is necessary.\n\n    @raise UnicodeError: The input string is not ASCII encodable/decodable.\n    @raise TypeError: The input is neither C{bytes} nor C{str}.\n    \"\"\"\n    if not isinstance(s, (bytes, str)):\n        raise TypeError(\"%r is neither bytes nor str\" % s)\n    if isinstance(s, bytes):\n        return s.decode(\"ascii\")\n    else:\n        # Ensure we're limited to ASCII subset:\n        s.encode(\"ascii\")\n    return s\n\n\ndef _matchingString(constantString, inputString):\n    \"\"\"\n    Some functions, such as C{os.path.join}, operate on string arguments which\n    may be bytes or text, and wish to return a value of the same type.  In\n    those cases you may wish to have a string constant (in the case of\n    C{os.path.join}, that constant would be C{os.path.sep}) involved in the\n    parsing or processing, that must be of a matching type in order to use\n    string operations on it.  L{_matchingString} will take a constant string\n    (either L{bytes} or L{str}) and convert it to the same type as the\n    input string.  C{constantString} should contain only characters from ASCII;\n    to ensure this, it will be encoded or decoded regardless.\n\n    @param constantString: A string literal used in processing.\n    @type constantString: L{str} or L{bytes}\n\n    @param inputString: A byte string or text string provided by the user.\n    @type inputString: L{str} or L{bytes}\n\n    @return: C{constantString} converted into the same type as C{inputString}\n    @rtype: the type of C{inputString}\n    \"\"\"\n    if isinstance(constantString, bytes):\n        otherType = constantString.decode(\"ascii\")\n    else:\n        otherType = constantString.encode(\"ascii\")\n    if type(constantString) == type(inputString):\n        return constantString\n    else:\n        return otherType\n\n\n@deprecated(\n    Version(\"Twisted\", 21, 2, 0),\n    replacement=\"raise exception.with_traceback(traceback)\",\n)\ndef reraise(exception, traceback):\n    \"\"\"\n    Re-raise an exception, with an optional traceback.\n\n    Re-raised exceptions will be mutated, with their C{__traceback__} attribute\n    being set.\n\n    @param exception: The exception instance.\n    @param traceback: The traceback to use, or L{None} indicating a new\n    traceback.\n    \"\"\"\n    raise exception.with_traceback(traceback)\n\n\ndef iterbytes(originalBytes):\n    \"\"\"\n    Return an iterable wrapper for a C{bytes} object that provides the behavior\n    of iterating over C{bytes} on Python 2.\n\n    In particular, the results of iteration are the individual bytes (rather\n    than integers as on Python 3).\n\n    @param originalBytes: A C{bytes} object that will be wrapped.\n    \"\"\"\n    for i in range(len(originalBytes)):\n        yield originalBytes[i : i + 1]\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"b'%d'\")\ndef intToBytes(i: int) -> bytes:\n    \"\"\"\n    Convert the given integer into C{bytes}, as ASCII-encoded Arab numeral.\n\n    @param i: The C{int} to convert to C{bytes}.\n    @rtype: C{bytes}\n    \"\"\"\n    return b\"%d\" % (i,)\n\n\ndef lazyByteSlice(object, offset=0, size=None):\n    \"\"\"\n    Return a memory view of the given bytes-like object.\n\n    If an offset is given, the view starts at that offset. If a size is\n    given, the view will only be of that length.\n\n    @param object: C{bytes} to be sliced.\n\n    @param offset: C{int}, starting index of view.\n\n    @param size: Optional, if an C{int} is given limit the length of the view\n        to this size.\n    \"\"\"\n    view = memoryview(object)\n    if size is None:\n        return view[offset:]\n    else:\n        return view[offset : (offset + size)]\n\n\ndef networkString(s: str) -> bytes:\n    \"\"\"\n    Convert a string to L{bytes} using ASCII encoding.\n\n    This is useful for sending text-like bytes that are constructed using\n    string interpolation.  For example::\n\n        networkString(\"Hello %d\" % (n,))\n\n    @param s: A string to convert to bytes.\n    @type s: L{str}\n\n    @raise UnicodeError: The input string is not ASCII encodable.\n    @raise TypeError: The input is not L{str}.\n\n    @rtype: L{bytes}\n    \"\"\"\n    if not isinstance(s, str):\n        raise TypeError(\"Can only convert strings to bytes\")\n    return s.encode(\"ascii\")\n\n\n@deprecated(Version(\"Twisted\", 21, 2, 0), replacement=\"os.environb\")\ndef bytesEnviron():\n    \"\"\"\n    Return a L{dict} of L{os.environ} where all text-strings are encoded into\n    L{bytes}.\n\n    This function is POSIX only; environment variables are always text strings\n    on Windows.\n    \"\"\"\n    encodekey = os.environ.encodekey\n    encodevalue = os.environ.encodevalue\n\n    return {encodekey(x): encodevalue(y) for x, y in os.environ.items()}\n\n\ndef _constructMethod(cls, name, self):\n    \"\"\"\n    Construct a bound method.\n\n    @param cls: The class that the method should be bound to.\n    @type cls: L{type}\n\n    @param name: The name of the method.\n    @type name: native L{str}\n\n    @param self: The object that the method is bound to.\n    @type self: any object\n\n    @return: a bound method\n    @rtype: L{_MethodType}\n    \"\"\"\n    func = cls.__dict__[name]\n    return _MethodType(func, self)\n\n\ndef _pypy3BlockingHack():\n    \"\"\"\n    Work around U{https://foss.heptapod.net/pypy/pypy/-/issues/3051}\n    by replacing C{socket.fromfd} with a more conservative version.\n    \"\"\"\n    try:\n        from fcntl import F_GETFL, F_SETFL, fcntl\n    except ImportError:\n        return\n    if not _PYPY:\n        return\n\n    def fromFDWithoutModifyingFlags(fd, family, type, proto=None):\n        passproto = [proto] * (proto is not None)\n        flags = fcntl(fd, F_GETFL)\n        try:\n            return realFromFD(fd, family, type, *passproto)\n        finally:\n            fcntl(fd, F_SETFL, flags)\n\n    realFromFD = socket.fromfd\n    if realFromFD.__name__ == fromFDWithoutModifyingFlags.__name__:\n        return\n    socket.fromfd = fromFDWithoutModifyingFlags\n\n\n_pypy3BlockingHack()\n\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use functools.reduce() directly\",\n    __name__,\n    \"reduce\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use io.StringIO directly\",\n    __name__,\n    \"NativeStringIO\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Import urllib.parse directly\",\n    __name__,\n    \"urllib_parse\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0), \"Use html.escape directly\", __name__, \"escape\"\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use urllib.parse.quote() directly\",\n    __name__,\n    \"urlquote\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use urllib.parse.unquote() directly\",\n    __name__,\n    \"urlunquote\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use http.cookiejar directly\",\n    __name__,\n    \"cookielib\",\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0), \"Use sys.intern() directly\", __name__, \"intern\"\n)\n\ndeprecatedModuleAttribute(\n    Version(\"Twisted\", 21, 2, 0),\n    \"Use collections.abc.Sequence directly\",\n    __name__,\n    \"Sequence\",\n)\n\n\n__all__ = [\n    \"reraise\",\n    \"execfile\",\n    \"frozenset\",\n    \"reduce\",\n    \"set\",\n    \"cmp\",\n    \"comparable\",\n    \"nativeString\",\n    \"NativeStringIO\",\n    \"networkString\",\n    \"unicode\",\n    \"iterbytes\",\n    \"intToBytes\",\n    \"lazyByteSlice\",\n    \"StringType\",\n    \"InstanceType\",\n    \"FileType\",\n    \"items\",\n    \"iteritems\",\n    \"itervalues\",\n    \"range\",\n    \"xrange\",\n    \"urllib_parse\",\n    \"bytesEnviron\",\n    \"escape\",\n    \"urlquote\",\n    \"urlunquote\",\n    \"cookielib\",\n    \"intern\",\n    \"unichr\",\n    \"raw_input\",\n    \"Sequence\",\n]\n\n\n### Dependency File: deprecate.py\n# -*- test-case-name: twisted.python.test.test_deprecate -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nDeprecation framework for Twisted.\n\nTo mark a method, function, or class as being deprecated do this::\n\n    from incremental import Version\n    from twisted.python.deprecate import deprecated\n\n    @deprecated(Version(\"Twisted\", 22, 10, 0))\n    def badAPI(self, first, second):\n        '''\n        Docstring for badAPI.\n        '''\n        ...\n\n    @deprecated(Version(\"Twisted\", 22, 10, 0))\n    class BadClass:\n        '''\n        Docstring for BadClass.\n        '''\n\nThe newly-decorated badAPI will issue a warning when called, and BadClass will\nissue a warning when instantiated. Both will also have  a deprecation notice\nappended to their docstring.\n\nTo deprecate properties you can use::\n\n    from incremental import Version\n    from twisted.python.deprecate import deprecatedProperty\n\n    class OtherwiseUndeprecatedClass:\n\n        @deprecatedProperty(Version(\"Twisted\", 22, 10, 0))\n        def badProperty(self):\n            '''\n            Docstring for badProperty.\n            '''\n\n        @badProperty.setter\n        def badProperty(self, value):\n            '''\n            Setter sill also raise the deprecation warning.\n            '''\n\n\nWhile it's best to avoid this as it adds performance overhead to *any* usage of\nthe module, to mark module-level attributes as being deprecated you can use::\n\n    badAttribute = \"someValue\"\n\n    ...\n\n    deprecatedModuleAttribute(\n        Version(\"Twisted\", 22, 10, 0),\n        \"Use goodAttribute instead.\",\n        \"your.full.module.name\",\n        \"badAttribute\")\n\nThe deprecated attributes will issue a warning whenever they are accessed. If\nthe attributes being deprecated are in the same module as the\nL{deprecatedModuleAttribute} call is being made from, the C{__name__} global\ncan be used as the C{moduleName} parameter.\n\n\nTo mark an optional, keyword parameter of a function or method as deprecated\nwithout deprecating the function itself, you can use::\n\n    @deprecatedKeywordParameter(Version(\"Twisted\", 22, 10, 0), \"baz\")\n    def someFunction(foo, bar=0, baz=None):\n        ...\n\nSee also L{incremental.Version}.\n\n@type DEPRECATION_WARNING_FORMAT: C{str}\n@var DEPRECATION_WARNING_FORMAT: The default deprecation warning string format\n    to use when one is not provided by the user.\n\"\"\"\nfrom __future__ import annotations\n\n__all__ = [\n    \"deprecated\",\n    \"deprecatedProperty\",\n    \"getDeprecationWarningString\",\n    \"getWarningMethod\",\n    \"setWarningMethod\",\n    \"deprecatedModuleAttribute\",\n    \"deprecatedKeywordParameter\",\n]\n\n\nimport inspect\nimport sys\nfrom dis import findlinestarts\nfrom functools import wraps\nfrom types import ModuleType\nfrom typing import Any, Callable, Dict, Optional, TypeVar, cast\nfrom warnings import warn, warn_explicit\n\nfrom incremental import Version, getVersionString\nfrom typing_extensions import ParamSpec\n\n_P = ParamSpec(\"_P\")\n_R = TypeVar(\"_R\")\n\nDEPRECATION_WARNING_FORMAT = \"%(fqpn)s was deprecated in %(version)s\"\n\n# Notionally, part of twisted.python.reflect, but defining it there causes a\n# cyclic dependency between this module and that module.  Define it here,\n# instead, and let reflect import it to re-expose to the public.\n\n\ndef _fullyQualifiedName(obj):\n    \"\"\"\n    Return the fully qualified name of a module, class, method or function.\n    Classes and functions need to be module level ones to be correctly\n    qualified.\n\n    @rtype: C{str}.\n    \"\"\"\n    try:\n        name = obj.__qualname__\n    except AttributeError:\n        name = obj.__name__\n\n    if inspect.isclass(obj) or inspect.isfunction(obj):\n        moduleName = obj.__module__\n        return f\"{moduleName}.{name}\"\n    elif inspect.ismethod(obj):\n        return f\"{obj.__module__}.{obj.__qualname__}\"\n    return name\n\n\n# Try to keep it looking like something in twisted.python.reflect.\n_fullyQualifiedName.__module__ = \"twisted.python.reflect\"\n_fullyQualifiedName.__name__ = \"fullyQualifiedName\"\n_fullyQualifiedName.__qualname__ = \"fullyQualifiedName\"\n\n\ndef _getReplacementString(replacement):\n    \"\"\"\n    Surround a replacement for a deprecated API with some polite text exhorting\n    the user to consider it as an alternative.\n\n    @type replacement: C{str} or callable\n\n    @return: a string like \"please use twisted.python.modules.getModule\n        instead\".\n    \"\"\"\n    if callable(replacement):\n        replacement = _fullyQualifiedName(replacement)\n    return f\"please use {replacement} instead\"\n\n\ndef _getDeprecationDocstring(version, replacement=None):\n    \"\"\"\n    Generate an addition to a deprecated object's docstring that explains its\n    deprecation.\n\n    @param version: the version it was deprecated.\n    @type version: L{incremental.Version}\n\n    @param replacement: The replacement, if specified.\n    @type replacement: C{str} or callable\n\n    @return: a string like \"Deprecated in Twisted 27.2.0; please use\n        twisted.timestream.tachyon.flux instead.\"\n    \"\"\"\n    doc = f\"Deprecated in {getVersionString(version)}\"\n    if replacement:\n        doc = f\"{doc}; {_getReplacementString(replacement)}\"\n    return doc + \".\"\n\n\ndef _getDeprecationWarningString(fqpn, version, format=None, replacement=None):\n    \"\"\"\n    Return a string indicating that the Python name was deprecated in the given\n    version.\n\n    @param fqpn: Fully qualified Python name of the thing being deprecated\n    @type fqpn: C{str}\n\n    @param version: Version that C{fqpn} was deprecated in.\n    @type version: L{incremental.Version}\n\n    @param format: A user-provided format to interpolate warning values into, or\n        L{DEPRECATION_WARNING_FORMAT\n        <twisted.python.deprecate.DEPRECATION_WARNING_FORMAT>} if L{None} is\n        given.\n    @type format: C{str}\n\n    @param replacement: what should be used in place of C{fqpn}. Either pass in\n        a string, which will be inserted into the warning message, or a\n        callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n\n    @return: A textual description of the deprecation\n    @rtype: C{str}\n    \"\"\"\n    if format is None:\n        format = DEPRECATION_WARNING_FORMAT\n    warningString = format % {\"fqpn\": fqpn, \"version\": getVersionString(version)}\n    if replacement:\n        warningString = \"{}; {}\".format(\n            warningString, _getReplacementString(replacement)\n        )\n    return warningString\n\n\ndef getDeprecationWarningString(callableThing, version, format=None, replacement=None):\n    \"\"\"\n    Return a string indicating that the callable was deprecated in the given\n    version.\n\n    @type callableThing: C{callable}\n    @param callableThing: Callable object to be deprecated\n\n    @type version: L{incremental.Version}\n    @param version: Version that C{callableThing} was deprecated in.\n\n    @type format: C{str}\n    @param format: A user-provided format to interpolate warning values into,\n        or L{DEPRECATION_WARNING_FORMAT\n        <twisted.python.deprecate.DEPRECATION_WARNING_FORMAT>} if L{None} is\n        given\n\n    @param replacement: what should be used in place of the callable. Either\n        pass in a string, which will be inserted into the warning message,\n        or a callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n\n    @return: A string describing the deprecation.\n    @rtype: C{str}\n    \"\"\"\n    return _getDeprecationWarningString(\n        _fullyQualifiedName(callableThing), version, format, replacement\n    )\n\n\ndef _appendToDocstring(thingWithDoc, textToAppend):\n    \"\"\"\n    Append the given text to the docstring of C{thingWithDoc}.\n\n    If C{thingWithDoc} has no docstring, then the text just replaces the\n    docstring. If it has a single-line docstring then it appends a blank line\n    and the message text. If it has a multi-line docstring, then in appends a\n    blank line a the message text, and also does the indentation correctly.\n    \"\"\"\n    if thingWithDoc.__doc__:\n        docstringLines = thingWithDoc.__doc__.splitlines()\n    else:\n        docstringLines = []\n\n    if len(docstringLines) == 0:\n        docstringLines.append(textToAppend)\n    elif len(docstringLines) == 1:\n        docstringLines.extend([\"\", textToAppend, \"\"])\n    else:\n        trailer = docstringLines[-1]\n        spaces = \"\"\n        if not trailer.strip():\n            # Deal with differences between Python 3.13 and older versions.\n            spaces = docstringLines.pop()\n        docstringLines.extend([\"\", spaces + textToAppend, spaces])\n        docstringLines = [l.lstrip(\" \") for l in docstringLines]\n    thingWithDoc.__doc__ = \"\\n\".join(docstringLines)\n\n\ndef deprecated(\n    version: Version, replacement: str | Callable[..., object] | None = None\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:\n    \"\"\"\n    Return a decorator that marks callables as deprecated. To deprecate a\n    property, see L{deprecatedProperty}.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the callable will be marked as\n        having been deprecated.  The decorated function will be annotated\n        with this version, having it set as its C{deprecatedVersion}\n        attribute.\n\n    @param replacement: what should be used in place of the callable. Either\n        pass in a string, which will be inserted into the warning message,\n        or a callable, which will be expanded to its full import path.\n    @type replacement: C{str} or callable\n    \"\"\"\n\n    def deprecationDecorator(function: Callable[_P, _R]) -> Callable[_P, _R]:\n        \"\"\"\n        Decorator that marks C{function} as deprecated.\n        \"\"\"\n        warningString = getDeprecationWarningString(\n            function, version, None, replacement\n        )\n\n        @wraps(function)\n        def deprecatedFunction(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n            warn(warningString, DeprecationWarning, stacklevel=2)\n            return function(*args, **kwargs)\n\n        _appendToDocstring(\n            deprecatedFunction, _getDeprecationDocstring(version, replacement)\n        )\n        deprecatedFunction.deprecatedVersion = version  # type: ignore[attr-defined]\n        return deprecatedFunction\n\n    return deprecationDecorator\n\n\ndef deprecatedProperty(\n    version: Version, replacement: str | Callable[..., object] | None = None\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:\n    \"\"\"\n    Return a decorator that marks a property as deprecated. To deprecate a\n    regular callable or class, see L{deprecated}.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the callable will be marked as\n        having been deprecated.  The decorated function will be annotated\n        with this version, having it set as its C{deprecatedVersion}\n        attribute.\n\n    @param replacement: what should be used in place of the callable.\n        Either pass in a string, which will be inserted into the warning\n        message, or a callable, which will be expanded to its full import\n        path.\n    @type replacement: C{str} or callable\n\n    @return: A new property with deprecated setter and getter.\n    @rtype: C{property}\n\n    @since: 16.1.0\n    \"\"\"\n\n    class _DeprecatedProperty(property):\n        \"\"\"\n        Extension of the build-in property to allow deprecated setters.\n        \"\"\"\n\n        def _deprecatedWrapper(self, function):\n            @wraps(function)\n            def deprecatedFunction(*args, **kwargs):\n                warn(\n                    self.warningString,  # type: ignore[attr-defined]\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n                return function(*args, **kwargs)\n\n            return deprecatedFunction\n\n        def setter(self, function):\n            return property.setter(self, self._deprecatedWrapper(function))\n\n    def deprecationDecorator(function):\n        warningString = getDeprecationWarningString(\n            function, version, None, replacement\n        )\n\n        @wraps(function)\n        def deprecatedFunction(*args, **kwargs):\n            warn(warningString, DeprecationWarning, stacklevel=2)\n            return function(*args, **kwargs)\n\n        _appendToDocstring(\n            deprecatedFunction, _getDeprecationDocstring(version, replacement)\n        )\n        deprecatedFunction.deprecatedVersion = version  # type: ignore[attr-defined]\n\n        result = _DeprecatedProperty(deprecatedFunction)\n        result.warningString = warningString  # type: ignore[attr-defined]\n        return result\n\n    return deprecationDecorator\n\n\ndef getWarningMethod():\n    \"\"\"\n    Return the warning method currently used to record deprecation warnings.\n    \"\"\"\n    return warn\n\n\ndef setWarningMethod(newMethod):\n    \"\"\"\n    Set the warning method to use to record deprecation warnings.\n\n    The callable should take message, category and stacklevel. The return\n    value is ignored.\n    \"\"\"\n    global warn\n    warn = newMethod\n\n\nclass _InternalState:\n    \"\"\"\n    An L{_InternalState} is a helper object for a L{_ModuleProxy}, so that it\n    can easily access its own attributes, bypassing its logic for delegating to\n    another object that it's proxying for.\n\n    @ivar proxy: a L{_ModuleProxy}\n    \"\"\"\n\n    def __init__(self, proxy):\n        object.__setattr__(self, \"proxy\", proxy)\n\n    def __getattribute__(self, name):\n        return object.__getattribute__(object.__getattribute__(self, \"proxy\"), name)\n\n    def __setattr__(self, name, value):\n        return object.__setattr__(object.__getattribute__(self, \"proxy\"), name, value)\n\n\nclass _ModuleProxy:\n    \"\"\"\n    Python module wrapper to hook module-level attribute access.\n\n    Access to deprecated attributes first checks\n    L{_ModuleProxy._deprecatedAttributes}, if the attribute does not appear\n    there then access falls through to L{_ModuleProxy._module}, the wrapped\n    module object.\n\n    @ivar _module: Module on which to hook attribute access.\n    @type _module: C{module}\n\n    @ivar _deprecatedAttributes: Mapping of attribute names to objects that\n        retrieve the module attribute's original value.\n    @type _deprecatedAttributes: C{dict} mapping C{str} to\n        L{_DeprecatedAttribute}\n\n    @ivar _lastWasPath: Heuristic guess as to whether warnings about this\n        package should be ignored for the next call.  If the last attribute\n        access of this module was a C{getattr} of C{__path__}, we will assume\n        that it was the import system doing it and we won't emit a warning for\n        the next access, even if it is to a deprecated attribute.  The CPython\n        import system always tries to access C{__path__}, then the attribute\n        itself, then the attribute itself again, in both successful and failed\n        cases.\n    @type _lastWasPath: C{bool}\n    \"\"\"\n\n    def __init__(self, module):\n        state = _InternalState(self)\n        state._module = module\n        state._deprecatedAttributes = {}\n        state._lastWasPath = False\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Get a string containing the type of the module proxy and a\n        representation of the wrapped module object.\n        \"\"\"\n        state = _InternalState(self)\n        return f\"<{type(self).__name__} module={state._module!r}>\"\n\n    def __setattr__(self, name, value):\n        \"\"\"\n        Set an attribute on the wrapped module object.\n        \"\"\"\n        state = _InternalState(self)\n        state._lastWasPath = False\n        setattr(state._module, name, value)\n\n    def __getattribute__(self, name):\n        \"\"\"\n        Get an attribute from the module object, possibly emitting a warning.\n\n        If the specified name has been deprecated, then a warning is issued.\n        (Unless certain obscure conditions are met; see\n        L{_ModuleProxy._lastWasPath} for more information about what might quash\n        such a warning.)\n        \"\"\"\n        state = _InternalState(self)\n        if state._lastWasPath:\n            deprecatedAttribute = None\n        else:\n            deprecatedAttribute = state._deprecatedAttributes.get(name)\n\n        if deprecatedAttribute is not None:\n            # If we have a _DeprecatedAttribute object from the earlier lookup,\n            # allow it to issue the warning.\n            value = deprecatedAttribute.get()\n        else:\n            # Otherwise, just retrieve the underlying value directly; it's not\n            # deprecated, there's no warning to issue.\n            value = getattr(state._module, name)\n        if name == \"__path__\":\n            state._lastWasPath = True\n        else:\n            state._lastWasPath = False\n        return value\n\n\nclass _DeprecatedAttribute:\n    \"\"\"\n    Wrapper for deprecated attributes.\n\n    This is intended to be used by L{_ModuleProxy}. Calling\n    L{_DeprecatedAttribute.get} will issue a warning and retrieve the\n    underlying attribute's value.\n\n    @type module: C{module}\n    @ivar module: The original module instance containing this attribute\n\n    @type fqpn: C{str}\n    @ivar fqpn: Fully qualified Python name for the deprecated attribute\n\n    @type version: L{incremental.Version}\n    @ivar version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @ivar message: Deprecation message\n    \"\"\"\n\n    def __init__(self, module, name, version, message):\n        \"\"\"\n        Initialise a deprecated name wrapper.\n        \"\"\"\n        self.module = module\n        self.__name__ = name\n        self.fqpn = module.__name__ + \".\" + name\n        self.version = version\n        self.message = message\n\n    def get(self):\n        \"\"\"\n        Get the underlying attribute value and issue a deprecation warning.\n        \"\"\"\n        # This might fail if the deprecated thing is a module inside a package.\n        # In that case, don't emit the warning this time.  The import system\n        # will come back again when it's not an AttributeError and we can emit\n        # the warning then.\n        result = getattr(self.module, self.__name__)\n        message = _getDeprecationWarningString(\n            self.fqpn, self.version, DEPRECATION_WARNING_FORMAT + \": \" + self.message\n        )\n        warn(message, DeprecationWarning, stacklevel=3)\n        return result\n\n\ndef _deprecateAttribute(proxy, name, version, message):\n    \"\"\"\n    Mark a module-level attribute as being deprecated.\n\n    @type proxy: L{_ModuleProxy}\n    @param proxy: The module proxy instance proxying the deprecated attributes\n\n    @type name: C{str}\n    @param name: Attribute name\n\n    @type version: L{incremental.Version}\n    @param version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @param message: Deprecation message\n    \"\"\"\n    _module = object.__getattribute__(proxy, \"_module\")\n    attr = _DeprecatedAttribute(_module, name, version, message)\n    # Add a deprecated attribute marker for this module's attribute. When this\n    # attribute is accessed via _ModuleProxy a warning is emitted.\n    _deprecatedAttributes = object.__getattribute__(proxy, \"_deprecatedAttributes\")\n    _deprecatedAttributes[name] = attr\n\n\ndef deprecatedModuleAttribute(version, message, moduleName, name):\n    \"\"\"\n    Declare a module-level attribute as being deprecated.\n\n    @type version: L{incremental.Version}\n    @param version: Version that the attribute was deprecated in\n\n    @type message: C{str}\n    @param message: Deprecation message\n\n    @type moduleName: C{str}\n    @param moduleName: Fully-qualified Python name of the module containing\n        the deprecated attribute; if called from the same module as the\n        attributes are being deprecated in, using the C{__name__} global can\n        be helpful\n\n    @type name: C{str}\n    @param name: Attribute name to deprecate\n    \"\"\"\n    module = sys.modules[moduleName]\n    if not isinstance(module, _ModuleProxy):\n        module = cast(ModuleType, _ModuleProxy(module))\n        sys.modules[moduleName] = module\n\n    _deprecateAttribute(module, name, version, message)\n\n\ndef warnAboutFunction(offender, warningString):\n    \"\"\"\n    Issue a warning string, identifying C{offender} as the responsible code.\n\n    This function is used to deprecate some behavior of a function.  It differs\n    from L{warnings.warn} in that it is not limited to deprecating the behavior\n    of a function currently on the call stack.\n\n    @param offender: The function that is being deprecated.\n\n    @param warningString: The string that should be emitted by this warning.\n    @type warningString: C{str}\n\n    @since: 11.0\n    \"\"\"\n    # inspect.getmodule() is attractive, but somewhat\n    # broken in Python < 2.6.  See Python bug 4845.\n    # In Python 3.13 line numbers returned by findlinestarts\n    # can be None for bytecode that does not map to source\n    # lines.\n    offenderModule = sys.modules[offender.__module__]\n    warn_explicit(\n        warningString,\n        category=DeprecationWarning,\n        filename=inspect.getabsfile(offenderModule),\n        lineno=max(\n            lineNumber\n            for _, lineNumber in findlinestarts(offender.__code__)\n            if lineNumber is not None\n        ),\n        module=offenderModule.__name__,\n        registry=offender.__globals__.setdefault(\"__warningregistry__\", {}),\n        module_globals=None,\n    )\n\n\ndef _passedArgSpec(argspec, positional, keyword):\n    \"\"\"\n    Take an I{inspect.ArgSpec}, a tuple of positional arguments, and a dict of\n    keyword arguments, and return a mapping of arguments that were actually\n    passed to their passed values.\n\n    @param argspec: The argument specification for the function to inspect.\n    @type argspec: I{inspect.ArgSpec}\n\n    @param positional: The positional arguments that were passed.\n    @type positional: L{tuple}\n\n    @param keyword: The keyword arguments that were passed.\n    @type keyword: L{dict}\n\n    @return: A dictionary mapping argument names (those declared in C{argspec})\n        to values that were passed explicitly by the user.\n    @rtype: L{dict} mapping L{str} to L{object}\n    \"\"\"\n    result: Dict[str, object] = {}\n    unpassed = len(argspec.args) - len(positional)\n    if argspec.keywords is not None:\n        kwargs = result[argspec.keywords] = {}\n    if unpassed < 0:\n        if argspec.varargs is None:\n            raise TypeError(\"Too many arguments.\")\n        else:\n            result[argspec.varargs] = positional[len(argspec.args) :]\n    for name, value in zip(argspec.args, positional):\n        result[name] = value\n    for name, value in keyword.items():\n        if name in argspec.args:\n            if name in result:\n                raise TypeError(\"Already passed.\")\n            result[name] = value\n        elif argspec.keywords is not None:\n            kwargs[name] = value\n        else:\n            raise TypeError(\"no such param\")\n    return result\n\n\ndef _passedSignature(signature, positional, keyword):\n    \"\"\"\n    Take an L{inspect.Signature}, a tuple of positional arguments, and a dict of\n    keyword arguments, and return a mapping of arguments that were actually\n    passed to their passed values.\n\n    @param signature: The signature of the function to inspect.\n    @type signature: L{inspect.Signature}\n\n    @param positional: The positional arguments that were passed.\n    @type positional: L{tuple}\n\n    @param keyword: The keyword arguments that were passed.\n    @type keyword: L{dict}\n\n    @return: A dictionary mapping argument names (those declared in\n        C{signature}) to values that were passed explicitly by the user.\n    @rtype: L{dict} mapping L{str} to L{object}\n    \"\"\"\n    result = {}\n    kwargs = None\n    numPositional = 0\n    for n, (name, param) in enumerate(signature.parameters.items()):\n        if param.kind == inspect.Parameter.VAR_POSITIONAL:\n            # Varargs, for example: *args\n            result[name] = positional[n:]\n            numPositional = len(result[name]) + 1\n        elif param.kind == inspect.Parameter.VAR_KEYWORD:\n            # Variable keyword args, for example: **my_kwargs\n            kwargs = result[name] = {}\n        elif param.kind in (\n            inspect.Parameter.POSITIONAL_OR_KEYWORD,\n            inspect.Parameter.POSITIONAL_ONLY,\n        ):\n            if n < len(positional):\n                result[name] = positional[n]\n                numPositional += 1\n        elif param.kind == inspect.Parameter.KEYWORD_ONLY:\n            if name not in keyword:\n                if param.default == inspect.Parameter.empty:\n                    raise TypeError(f\"missing keyword arg {name}\")\n                else:\n                    result[name] = param.default\n        else:\n            raise TypeError(f\"'{name}' parameter is invalid kind: {param.kind}\")\n\n    if len(positional) > numPositional:\n        raise TypeError(\"Too many arguments.\")\n    for name, value in keyword.items():\n        if name in signature.parameters.keys():\n            if name in result:\n                raise TypeError(\"Already passed.\")\n            result[name] = value\n        elif kwargs is not None:\n            kwargs[name] = value\n        else:\n            raise TypeError(\"no such param\")\n    return result\n\n\ndef _mutuallyExclusiveArguments(argumentPairs):\n    \"\"\"\n    Decorator which causes its decoratee to raise a L{TypeError} if two of the\n    given arguments are passed at the same time.\n\n    @param argumentPairs: pairs of argument identifiers, each pair indicating\n        an argument that may not be passed in conjunction with another.\n    @type argumentPairs: sequence of 2-sequences of L{str}\n\n    @return: A decorator, used like so::\n\n            @_mutuallyExclusiveArguments([[\"tweedledum\", \"tweedledee\"]])\n            def function(tweedledum=1, tweedledee=2):\n                \"Don't pass tweedledum and tweedledee at the same time.\"\n\n    @rtype: 1-argument callable taking a callable and returning a callable.\n    \"\"\"\n\n    def wrapper(wrappee):\n        spec = inspect.signature(wrappee)\n        _passed = _passedSignature\n\n        @wraps(wrappee)\n        def wrapped(*args, **kwargs):\n            arguments = _passed(spec, args, kwargs)\n            for this, that in argumentPairs:\n                if this in arguments and that in arguments:\n                    raise TypeError(\n                        (\"The %r and %r arguments to %s \" \"are mutually exclusive.\")\n                        % (this, that, _fullyQualifiedName(wrappee))\n                    )\n            return wrappee(*args, **kwargs)\n\n        return wrapped\n\n    return wrapper\n\n\n_Tc = TypeVar(\"_Tc\", bound=Callable[..., Any])\n\n\ndef deprecatedKeywordParameter(\n    version: Version, name: str, replacement: Optional[str] = None\n) -> Callable[[_Tc], _Tc]:\n    \"\"\"\n    Return a decorator that marks a keyword parameter of a callable\n    as deprecated. A warning will be emitted if a caller supplies\n    a value for the parameter, whether the caller uses a keyword or\n    positional syntax.\n\n    @type version: L{incremental.Version}\n    @param version: The version in which the parameter will be marked as\n        having been deprecated.\n\n    @type name: L{str}\n    @param name: The name of the deprecated parameter.\n\n    @type replacement: L{str}\n    @param replacement: Optional text indicating what should be used in\n        place of the deprecated parameter.\n\n    @since: Twisted 21.2.0\n    \"\"\"\n\n    def wrapper(wrappee: _Tc) -> _Tc:\n        warningString = _getDeprecationWarningString(\n            f\"The {name!r} parameter to {_fullyQualifiedName(wrappee)}\",\n            version,\n            replacement=replacement,\n        )\n\n        doc = \"The {!r} parameter was deprecated in {}\".format(\n            name,\n            getVersionString(version),\n        )\n        if replacement:\n            doc = doc + \"; \" + _getReplacementString(replacement)\n        doc += \".\"\n\n        params = inspect.signature(wrappee).parameters\n        if (\n            name in params\n            and params[name].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        ):\n            parameterIndex = list(params).index(name)\n\n            def checkDeprecatedParameter(*args, **kwargs):\n                if len(args) > parameterIndex or name in kwargs:\n                    warn(warningString, DeprecationWarning, stacklevel=2)\n                return wrappee(*args, **kwargs)\n\n        else:\n\n            def checkDeprecatedParameter(*args, **kwargs):\n                if name in kwargs:\n                    warn(warningString, DeprecationWarning, stacklevel=2)\n                return wrappee(*args, **kwargs)\n\n        decorated = cast(_Tc, wraps(wrappee)(checkDeprecatedParameter))\n        _appendToDocstring(decorated, doc)\n        return decorated\n\n    return wrapper\n\nOutput the complete test file, code only, no explanations.\n```Python\n<complete test code>\n```\n### Time\nCurrent time: 2025-03-10 12:42:34"}]}
