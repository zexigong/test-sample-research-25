messages:
- content: You are an AI agent expert in writing unit tests. Your task is to write
    unit tests for the given code files of the repository. Make sure the tests can
    be executed without lint or compile errors.
  role: system
- content: "### Task Information\nBased on the source code, write/rewrite tests to\
    \ cover the source code.\nRepository: pyinstaller\nTest File Path: pyinstaller\\\
    test_building_utils\\test_building_utils.py\nProject Programming Language: Python\n\
    Testing Framework: pytest\n### Source File Content\n### Source File Content:\n\
    #-----------------------------------------------------------------------------\n\
    # Copyright (c) 2005-2023, PyInstaller Development Team.\n#\n# Distributed under\
    \ the terms of the GNU General Public License (version 2\n# or later) with exception\
    \ for distributing the bootloader.\n#\n# The full license is in the file COPYING.txt,\
    \ distributed with this software.\n#\n# SPDX-License-Identifier: (GPL-2.0-or-later\
    \ WITH Bootloader-exception)\n#-----------------------------------------------------------------------------\n\
    \nimport fnmatch\nimport glob\nimport hashlib\nimport io\nimport marshal\nimport\
    \ os\nimport pathlib\nimport platform\nimport shutil\nimport struct\nimport subprocess\n\
    import sys\nimport zipfile\n\nfrom PyInstaller import compat\nfrom PyInstaller\
    \ import log as logging\nfrom PyInstaller.compat import EXTENSION_SUFFIXES, is_darwin,\
    \ is_win, is_linux\nfrom PyInstaller.config import CONF\nfrom PyInstaller.exceptions\
    \ import InvalidSrcDestTupleError\nfrom PyInstaller.utils import misc\n\nif is_win:\n\
    \    from PyInstaller.utils.win32 import versioninfo\n\nif is_darwin:\n    import\
    \ PyInstaller.utils.osx as osxutils\n\nlogger = logging.getLogger(__name__)\n\n\
    # -- Helpers for checking guts.\n#\n# NOTE: by _GUTS it is meant intermediate\
    \ files and data structures that PyInstaller creates for bundling files and\n\
    # creating final executable.\n\n\ndef _check_guts_eq(attr_name, old_value, new_value,\
    \ last_build):\n    \"\"\"\n    Rebuild is required if values differ.\n    \"\"\
    \"\n    if old_value != new_value:\n        logger.info(\"Building because %s\
    \ changed\", attr_name)\n        return True\n    return False\n\n\ndef _check_guts_toc_mtime(attr_name,\
    \ old_toc, new_toc, last_build):\n    \"\"\"\n    Rebuild is required if mtimes\
    \ of files listed in old TOC are newer than last_build.\n\n    Use this for calculated/analysed\
    \ values read from cache.\n    \"\"\"\n    for dest_name, src_name, typecode in\
    \ old_toc:\n        if misc.mtime(src_name) > last_build:\n            logger.info(\"\
    Building because %s changed\", src_name)\n            return True\n    return\
    \ False\n\n\ndef _check_guts_toc(attr_name, old_toc, new_toc, last_build):\n \
    \   \"\"\"\n    Rebuild is required if either TOC content changed or mtimes of\
    \ files listed in old TOC are newer than last_build.\n\n    Use this for input\
    \ parameters.\n    \"\"\"\n    return _check_guts_eq(attr_name, old_toc, new_toc,\
    \ last_build) or \\\n        _check_guts_toc_mtime(attr_name, old_toc, new_toc,\
    \ last_build)\n\n\ndef add_suffix_to_extension(dest_name, src_name, typecode):\n\
    \    \"\"\"\n    Take a TOC entry (dest_name, src_name, typecode) and adjust the\
    \ dest_name for EXTENSION to include the full library\n    suffix.\n    \"\"\"\
    \n    # No-op for non-extension\n    if typecode != 'EXTENSION':\n        return\
    \ dest_name, src_name, typecode\n\n    # If dest_name completely fits into end\
    \ of the src_name, it has already been processed.\n    if src_name.endswith(dest_name):\n\
    \        return dest_name, src_name, typecode\n\n    # Change the dotted name\
    \ into a relative path. This places C extensions in the Python-standard location.\n\
    \    dest_name = dest_name.replace('.', os.sep)\n    # In some rare cases extension\
    \ might already contain a suffix. Skip it in this case.\n    if os.path.splitext(dest_name)[1]\
    \ not in EXTENSION_SUFFIXES:\n        # Determine the base name of the file.\n\
    \        base_name = os.path.basename(dest_name)\n        assert '.' not in base_name\n\
    \        # Use this file's existing extension. For extensions such as ``libzmq.cp36-win_amd64.pyd``,\
    \ we cannot use\n        # ``os.path.splitext``, which would give only the ```.pyd``\
    \ part of the extension.\n        dest_name = dest_name + os.path.basename(src_name)[len(base_name):]\n\
    \n    return dest_name, src_name, typecode\n\n\ndef process_collected_binary(\n\
    \    src_name,\n    dest_name,\n    use_strip=False,\n    use_upx=False,\n   \
    \ upx_exclude=None,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n\
    \    strict_arch_validation=False\n):\n    \"\"\"\n    Process the collected binary\
    \ using strip or UPX (or both), and apply any platform-specific processing. On\
    \ macOS,\n    this rewrites the library paths in the headers, and (re-)signs the\
    \ binary. On-disk cache is used to avoid processing\n    the same binary with\
    \ same options over and over.\n\n    In addition to given arguments, this function\
    \ also uses CONF['cachedir'] and CONF['upx_dir'].\n    \"\"\"\n    from PyInstaller.config\
    \ import CONF\n\n    # We need to use cache in the following scenarios:\n    #\
    \  * extra binary processing due to use of `strip` or `upx`\n    #  * building\
    \ on macOS, where we need to rewrite library paths in binaries' headers and (re-)sign\
    \ the binaries.\n    if not use_strip and not use_upx and not is_darwin:\n   \
    \     return src_name\n\n    # Match against provided UPX exclude patterns.\n\
    \    upx_exclude = upx_exclude or []\n    if use_upx:\n        src_path = pathlib.PurePath(src_name)\n\
    \        for upx_exclude_entry in upx_exclude:\n            # pathlib.PurePath.match()\
    \ matches from right to left, and supports * wildcard, but does not support the\n\
    \            # \"**\" syntax for directory recursion. Case sensitivity follows\
    \ the OS default.\n            if src_path.match(upx_exclude_entry):\n       \
    \         logger.info(\"Disabling UPX for %s due to match in exclude pattern:\
    \ %s\", src_name, upx_exclude_entry)\n                use_upx = False\n      \
    \          break\n\n    # Additional automatic disablement rules for UPX and strip.\n\
    \n    # On Windows, avoid using UPX with binaries that have control flow guard\
    \ (CFG) enabled.\n    if use_upx and is_win and versioninfo.pefile_check_control_flow_guard(src_name):\n\
    \        logger.info('Disabling UPX for %s due to CFG!', src_name)\n        use_upx\
    \ = False\n\n    # Avoid using UPX with Qt plugins, as it strips the data required\
    \ by the Qt plugin loader.\n    if use_upx and misc.is_file_qt_plugin(src_name):\n\
    \        logger.info('Disabling UPX for %s due to it being a Qt plugin!', src_name)\n\
    \        use_upx = False\n\n    # On linux, if a binary has an accompanying HMAC\
    \ or CHK file, avoid modifying it in any way.\n    if (use_upx or use_strip) and\
    \ is_linux:\n        src_path = pathlib.Path(src_name)\n        hmac_path = src_path.with_name(f\"\
    .{src_path.name}.hmac\")\n        chk_path = src_path.with_suffix(\".chk\")\n\
    \        if hmac_path.is_file():\n            logger.info('Disabling UPX and/or\
    \ strip for %s due to accompanying .hmac file!', src_name)\n            use_upx\
    \ = use_strip = False\n        elif chk_path.is_file():\n            logger.info('Disabling\
    \ UPX and/or strip for %s due to accompanying .chk file!', src_name)\n       \
    \     use_upx = use_strip = False\n        del src_path, hmac_path, chk_path\n\
    \n    # Exit early if no processing is required after above rules are applied.\n\
    \    if not use_strip and not use_upx and not is_darwin:\n        return src_name\n\
    \n    # Prepare cache directory path. Cache is tied to python major/minor version,\
    \ but also to various processing options.\n    pyver = f'py{sys.version_info[0]}{sys.version_info[1]}'\n\
    \    arch = platform.architecture()[0]\n    cache_dir = os.path.join(\n      \
    \  CONF['cachedir'],\n        f'bincache{use_strip:d}{use_upx:d}{pyver}{arch}',\n\
    \    )\n    if target_arch:\n        cache_dir = os.path.join(cache_dir, target_arch)\n\
    \    if is_darwin:\n        # Separate by codesign identity\n        if codesign_identity:\n\
    \            # Compute hex digest of codesign identity string to prevent issues\
    \ with invalid characters.\n            csi_hash = hashlib.sha256(codesign_identity.encode('utf-8'))\n\
    \            cache_dir = os.path.join(cache_dir, csi_hash.hexdigest())\n     \
    \   else:\n            cache_dir = os.path.join(cache_dir, 'adhoc')  # ad-hoc\
    \ signing\n        # Separate by entitlements\n        if entitlements_file:\n\
    \            # Compute hex digest of entitlements file contents\n            with\
    \ open(entitlements_file, 'rb') as fp:\n                ef_hash = hashlib.sha256(fp.read())\n\
    \            cache_dir = os.path.join(cache_dir, ef_hash.hexdigest())\n      \
    \  else:\n            cache_dir = os.path.join(cache_dir, 'no-entitlements')\n\
    \    os.makedirs(cache_dir, exist_ok=True)\n\n    # Load cache index, if available\n\
    \    cache_index_file = os.path.join(cache_dir, \"index.dat\")\n    try:\n   \
    \     cache_index = misc.load_py_data_struct(cache_index_file)\n    except FileNotFoundError:\n\
    \        cache_index = {}\n    except Exception:\n        # Tell the user they\
    \ may want to fix their cache... However, do not delete it for them; if it keeps\
    \ getting\n        # corrupted, we will never find out.\n        logger.warning(\"\
    PyInstaller bincache may be corrupted; use pyinstaller --clean to fix it.\")\n\
    \        raise\n\n    # Look up the file in cache; use case-normalized destination\
    \ name as identifier.\n    cached_id = os.path.normcase(dest_name)\n    cached_name\
    \ = os.path.join(cache_dir, dest_name)\n    src_digest = _compute_file_digest(src_name)\n\
    \n    if cached_id in cache_index:\n        # If digest matches to the cached\
    \ digest, return the cached file...\n        if src_digest == cache_index[cached_id]:\n\
    \            return cached_name\n\n        # ... otherwise remove it.\n      \
    \  os.remove(cached_name)\n\n    # Ensure parent path exists\n    os.makedirs(os.path.dirname(cached_name),\
    \ exist_ok=True)\n\n    # Use `shutil.copyfile` to copy the file with default\
    \ permissions bits, then manually set executable\n    # bits. This way, we avoid\
    \ copying permission bits and metadata from the original file, which might be\
    \ too\n    # restrictive for further processing (read-only permissions, immutable\
    \ flag on FreeBSD, and so on).\n    shutil.copyfile(src_name, cached_name)\n \
    \   os.chmod(cached_name, 0o755)\n\n    # Apply strip\n    if use_strip:\n   \
    \     strip_options = []\n        if is_darwin:\n            # The default strip\
    \ behavior breaks some shared libraries under macOS.\n            strip_options\
    \ = [\"-S\"]  # -S = strip only debug symbols.\n\n        cmd = [\"strip\", *strip_options,\
    \ cached_name]\n        logger.info(\"Executing: %s\", \" \".join(cmd))\n    \
    \    try:\n            p = subprocess.run(\n                cmd,\n           \
    \     stdin=subprocess.DEVNULL,\n                stdout=subprocess.PIPE,\n   \
    \             stderr=subprocess.STDOUT,\n                check=True,\n       \
    \         errors='ignore',\n                encoding='utf-8',\n            )\n\
    \            logger.debug(\"Output from strip command:\\n%s\", p.stdout)\n   \
    \     except subprocess.CalledProcessError as e:\n            logger.warning(\"\
    Failed to run strip on %r!\", cached_name, exc_info=True)\n            logger.warning(\"\
    Output from strip command:\\n%s\", e.stdout)\n        except Exception:\n    \
    \        logger.warning(\"Failed to run strip on %r!\", cached_name, exc_info=True)\n\
    \n    # Apply UPX\n    if use_upx:\n        upx_exe = 'upx'\n        upx_dir =\
    \ CONF['upx_dir']\n        if upx_dir:\n            upx_exe = os.path.join(upx_dir,\
    \ upx_exe)\n\n        upx_options = [\n            # Do not compress icons, so\
    \ that they can still be accessed externally.\n            '--compress-icons=0',\n\
    \            # Use LZMA compression.\n            '--lzma',\n            # Quiet\
    \ mode.\n            '-q',\n        ]\n        if is_win:\n            # Binaries\
    \ built with Visual Studio 7.1 require --strip-loadconf or they will not compress.\n\
    \            upx_options.append('--strip-loadconf')\n\n        cmd = [upx_exe,\
    \ *upx_options, cached_name]\n        logger.info(\"Executing: %s\", \" \".join(cmd))\n\
    \        try:\n            p = subprocess.run(\n                cmd,\n       \
    \         stdin=subprocess.DEVNULL,\n                stdout=subprocess.PIPE,\n\
    \                stderr=subprocess.STDOUT,\n                check=True,\n    \
    \            errors='ignore',\n                encoding='utf-8',\n           \
    \ )\n            logger.debug(\"Output from upx command:\\n%s\", p.stdout)\n \
    \       except subprocess.CalledProcessError as e:\n            logger.warning(\"\
    Failed to upx strip on %r!\", cached_name, exc_info=True)\n            logger.warning(\"\
    Output from upx command:\\n%s\", e.stdout)\n        except Exception:\n      \
    \      logger.warning(\"Failed to run upx on %r!\", cached_name, exc_info=True)\n\
    \n    # On macOS, we need to modify the given binary's paths to the dependent\
    \ libraries, in order to ensure they are\n    # relocatable and always refer to\
    \ location within the frozen application. Specifically, we make all dependent\n\
    \    # library paths relative to @rpath, and set @rpath to point to the top-level\
    \ application directory, relative to\n    # the binary's location (i.e., @loader_path).\n\
    \    #\n    # While modifying the headers invalidates existing signatures, we\
    \ avoid removing them in order to speed things up\n    # (and to avoid potential\
    \ bugs in the codesign utility, like the one reported on macOS 10.13 in #6167).\n\
    \    # The forced re-signing at the end should take care of the invalidated signatures.\n\
    \    if is_darwin:\n        try:\n            osxutils.binary_to_target_arch(cached_name,\
    \ target_arch, display_name=src_name)\n            #osxutils.remove_signature_from_binary(cached_name)\
    \  # Disabled as per comment above.\n            target_rpath = str(\n       \
    \         pathlib.PurePath('@loader_path', *['..' for level in pathlib.PurePath(dest_name).parent.parts])\n\
    \            )\n            osxutils.set_dylib_dependency_paths(cached_name, target_rpath)\n\
    \            osxutils.sign_binary(cached_name, codesign_identity, entitlements_file)\n\
    \        except osxutils.InvalidBinaryError:\n            # Raised by osxutils.binary_to_target_arch\
    \ when the given file is not a valid macOS binary (for example,\n            #\
    \ a linux .so file; see issue #6327). The error prevents any further processing,\
    \ so just ignore it.\n            pass\n        except osxutils.IncompatibleBinaryArchError:\n\
    \            # Raised by osxutils.binary_to_target_arch when the given file does\
    \ not contain (all) required arch slices.\n            # Depending on the strict\
    \ validation mode, re-raise or swallow the error.\n            #\n           \
    \ # Strict validation should be enabled only for binaries where the architecture\
    \ *must* match the target one,\n            # i.e., the extension modules. Everything\
    \ else is pretty much a gray area, for example:\n            #  * a universal2\
    \ extension may have its x86_64 and arm64 slices linked against distinct single-arch/thin\n\
    \            #    shared libraries\n            #  * a collected executable that\
    \ is launched by python code via a subprocess can be x86_64-only, even though\n\
    \            #    the actual python code is running on M1 in native arm64 mode.\n\
    \            if strict_arch_validation:\n                raise\n            logger.debug(\"\
    File %s failed optional architecture validation - collecting as-is!\", src_name)\n\
    \        except Exception as e:\n            raise SystemError(f\"Failed to process\
    \ binary {cached_name!r}!\") from e\n\n    # Update cache index\n    cache_index[cached_id]\
    \ = src_digest\n    misc.save_py_data_struct(cache_index_file, cache_index)\n\n\
    \    return cached_name\n\n\ndef _compute_file_digest(filename):\n    hasher =\
    \ hashlib.sha1()\n    with open(filename, \"rb\") as fp:\n        for chunk in\
    \ iter(lambda: fp.read(16 * 1024), b\"\"):\n            hasher.update(chunk)\n\
    \    return bytearray(hasher.digest())\n\n\ndef _check_path_overlap(path):\n \
    \   \"\"\"\n    Check that path does not overlap with WORKPATH or SPECPATH (i.e.,\
    \ WORKPATH and SPECPATH may not start with path,\n    which could be caused by\
    \ a faulty hand-edited specfile).\n\n    Raise SystemExit if there is overlap,\
    \ return True otherwise\n    \"\"\"\n    from PyInstaller.config import CONF\n\
    \    specerr = 0\n    if CONF['workpath'].startswith(path):\n        logger.error('Specfile\
    \ error: The output path \"%s\" contains WORKPATH (%s)', path, CONF['workpath'])\n\
    \        specerr += 1\n    if CONF['specpath'].startswith(path):\n        logger.error('Specfile\
    \ error: The output path \"%s\" contains SPECPATH (%s)', path, CONF['specpath'])\n\
    \        specerr += 1\n    if specerr:\n        raise SystemExit(\n          \
    \  'Error: Please edit/recreate the specfile (%s) and set a different output name\
    \ (e.g. \"dist\").' %\n            CONF['spec']\n        )\n    return True\n\n\
    \ndef _make_clean_directory(path):\n    \"\"\"\n    Create a clean directory from\
    \ the given directory name.\n    \"\"\"\n    if _check_path_overlap(path):\n \
    \       if os.path.isdir(path) or os.path.isfile(path):\n            try:\n  \
    \              os.remove(path)\n            except OSError:\n                _rmtree(path)\n\
    \n        os.makedirs(path, exist_ok=True)\n\n\ndef _rmtree(path):\n    \"\"\"\
    \n    Remove directory and all its contents, but only after user confirmation,\
    \ or if the -y option is set.\n    \"\"\"\n    from PyInstaller.config import\
    \ CONF\n    if CONF['noconfirm']:\n        choice = 'y'\n    elif sys.stdout.isatty():\n\
    \        choice = input(\n            'WARNING: The output directory \"%s\" and\
    \ ALL ITS CONTENTS will be REMOVED! Continue? (y/N)' % path\n        )\n    else:\n\
    \        raise SystemExit(\n            'Error: The output directory \"%s\" is\
    \ not empty. Please remove all its contents or use the -y option (remove'\n  \
    \          ' output directory without confirmation).' % path\n        )\n    if\
    \ choice.strip().lower() == 'y':\n        if not CONF['noconfirm']:\n        \
    \    print(\"On your own risk, you can use the option `--noconfirm` to get rid\
    \ of this question.\")\n        logger.info('Removing dir %s', path)\n       \
    \ shutil.rmtree(path)\n    else:\n        raise SystemExit('User aborted')\n\n\
    \n# TODO Refactor to prohibit empty target directories. As the docstring below\
    \ documents, this function currently permits\n# the second item of each 2-tuple\
    \ in \"hook.datas\" to be the empty string, in which case the target directory\
    \ defaults to\n# the source directory's basename. However, this functionality\
    \ is very fragile and hence bad. Instead:\n#\n# * An exception should be raised\
    \ if such item is empty.\n# * All hooks currently passing the empty string for\
    \ such item (e.g.,\n#   \"hooks/hook-babel.py\", \"hooks/hook-matplotlib.py\"\
    ) should be refactored\n#   to instead pass such basename.\ndef format_binaries_and_datas(binaries_or_datas,\
    \ workingdir=None):\n    \"\"\"\n    Convert the passed list of hook-style 2-tuples\
    \ into a returned set of `TOC`-style 2-tuples.\n\n    Elements of the passed list\
    \ are 2-tuples `(source_dir_or_glob, target_dir)`.\n    Elements of the returned\
    \ set are 2-tuples `(target_file, source_file)`.\n    For backwards compatibility,\
    \ the order of elements in the former tuples are the reverse of the order of elements\
    \ in\n    the latter tuples!\n\n    Parameters\n    ----------\n    binaries_or_datas\
    \ : list\n        List of hook-style 2-tuples (e.g., the top-level `binaries`\
    \ and `datas` attributes defined by hooks) whose:\n        * The first element\
    \ is either:\n          * A glob matching only the absolute or relative paths\
    \ of source non-Python data files.\n          * The absolute or relative path\
    \ of a source directory containing only source non-Python data files.\n      \
    \  * The second element is the relative path of the target directory into which\
    \ these source files will be\n          recursively copied.\n\n        If the\
    \ optional `workingdir` parameter is passed, source paths may be either absolute\
    \ or relative; else, source\n        paths _must_ be absolute.\n    workingdir\
    \ : str\n        Optional absolute path of the directory to which all relative\
    \ source paths in the `binaries_or_datas`\n        parameter will be prepended\
    \ by (and hence converted into absolute paths) _or_ `None` if these paths are\
    \ to be\n        preserved as relative. Defaults to `None`.\n\n    Returns\n \
    \   ----------\n    set\n        Set of `TOC`-style 2-tuples whose:\n        *\
    \ First element is the absolute or relative path of a target file.\n        *\
    \ Second element is the absolute or relative path of the corresponding source\
    \ file to be copied to this target\n          file.\n    \"\"\"\n    toc_datas\
    \ = set()\n\n    for src_root_path_or_glob, trg_root_dir in binaries_or_datas:\n\
    \        # Disallow empty source path. Those are typically result of errors, and\
    \ result in implicit collection of the\n        # whole current working directory,\
    \ which is never a good idea.\n        if not src_root_path_or_glob:\n       \
    \     raise InvalidSrcDestTupleError(\n                (src_root_path_or_glob,\
    \ trg_root_dir),\n                \"Empty SRC is not allowed when adding binary\
    \ and data files, as it would result in collection of the \"\n               \
    \ \"whole current working directory.\"\n            )\n        if not trg_root_dir:\n\
    \            raise InvalidSrcDestTupleError(\n                (src_root_path_or_glob,\
    \ trg_root_dir),\n                \"Empty DEST_DIR is not allowed - to collect\
    \ files into application's top-level directory, use \"\n                f\"{os.curdir!r}.\"\
    \n            )\n        # Disallow absolute target paths, as well as target paths\
    \ that would end up pointing outside of the\n        # application's top-level\
    \ directory.\n        if os.path.isabs(trg_root_dir):\n            raise InvalidSrcDestTupleError((src_root_path_or_glob,\
    \ trg_root_dir), \"DEST_DIR must be a relative path!\")\n        if os.path.normpath(trg_root_dir).startswith('..'):\n\
    \            raise InvalidSrcDestTupleError(\n                (src_root_path_or_glob,\
    \ trg_root_dir),\n                \"DEST_DIR must not point outside of application's\
    \ top-level directory!\",\n            )\n\n        # Convert relative to absolute\
    \ paths if required.\n        if workingdir and not os.path.isabs(src_root_path_or_glob):\n\
    \            src_root_path_or_glob = os.path.join(workingdir, src_root_path_or_glob)\n\
    \n        # Normalize paths.\n        src_root_path_or_glob = os.path.normpath(src_root_path_or_glob)\n\
    \        if os.path.isfile(src_root_path_or_glob):\n            src_root_paths\
    \ = [src_root_path_or_glob]\n        else:\n            # List of the absolute\
    \ paths of all source paths matching the current glob.\n            src_root_paths\
    \ = glob.glob(src_root_path_or_glob)\n\n        if not src_root_paths:\n     \
    \       raise SystemExit(f'Unable to find {src_root_path_or_glob!r} when adding\
    \ binary and data files.')\n\n        for src_root_path in src_root_paths:\n \
    \           if os.path.isfile(src_root_path):\n                # Normalizing the\
    \ result to remove redundant relative paths (e.g., removing \"./\" from \"trg/./file\"\
    ).\n                toc_datas.add((\n                    os.path.normpath(os.path.join(trg_root_dir,\
    \ os.path.basename(src_root_path))),\n                    os.path.normpath(src_root_path),\n\
    \                ))\n            elif os.path.isdir(src_root_path):\n        \
    \        for src_dir, src_subdir_basenames, src_file_basenames in os.walk(src_root_path):\n\
    \                    # Ensure the current source directory is a subdirectory of\
    \ the passed top-level source directory.\n                    # Since os.walk()\
    \ does *NOT* follow symlinks by default, this should be the case. (But let's make\n\
    \                    # sure.)\n                    assert src_dir.startswith(src_root_path)\n\
    \n                    # Relative path of the current target directory, obtained\
    \ by:\n                    #\n                    # * Stripping the top-level\
    \ source directory from the current source directory (e.g., removing\n       \
    \             #   \"/top\" from \"/top/dir\").\n                    # * Normalizing\
    \ the result to remove redundant relative paths (e.g., removing \"./\" from\n\
    \                    #   \"trg/./file\").\n                    trg_dir = os.path.normpath(os.path.join(trg_root_dir,\
    \ os.path.relpath(src_dir, src_root_path)))\n\n                    for src_file_basename\
    \ in src_file_basenames:\n                        src_file = os.path.join(src_dir,\
    \ src_file_basename)\n                        if os.path.isfile(src_file):\n \
    \                           # Normalize the result to remove redundant relative\
    \ paths (e.g., removing \"./\" from\n                            # \"trg/./file\"\
    ).\n                            toc_datas.add((\n                            \
    \    os.path.normpath(os.path.join(trg_dir, src_file_basename)), os.path.normpath(src_file)\n\
    \                            ))\n\n    return toc_datas\n\n\ndef get_code_object(modname,\
    \ filename, optimize):\n    \"\"\"\n    Get the code-object for a module.\n\n\
    \    This is a simplifed non-performant version which circumvents __pycache__.\n\
    \    \"\"\"\n\n    if filename in ('-', None):\n        # This is a NamespacePackage,\
    \ modulegraph marks them by using the filename '-'. (But wants to use None, so\n\
    \        # check for None, too, to be forward-compatible.)\n        logger.debug('Compiling\
    \ namespace package %s', modname)\n        txt = '#\\n'\n        code_object =\
    \ compile(txt, filename, 'exec', optimize=optimize)\n    else:\n        _, ext\
    \ = os.path.splitext(filename)\n        ext = ext.lower()\n\n        if ext ==\
    \ '.pyc':\n            # The module is available in binary-only form. Read the\
    \ contents of .pyc file using helper function, which\n            # supports reading\
    \ from either stand-alone or archive-embedded .pyc files.\n            logger.debug('Reading\
    \ code object from .pyc file %s', filename)\n            pyc_data = _read_pyc_data(filename)\n\
    \            code_object = marshal.loads(pyc_data[16:])\n        else:\n     \
    \       # Assume this is a source .py file, but allow an arbitrary extension (other\
    \ than .pyc, which is taken in\n            # the above branch). This allows entry-point\
    \ scripts to have an arbitrary (or no) extension, as tested by\n            #\
    \ the `test_arbitrary_ext` in `test_basic.py`.\n            logger.debug('Compiling\
    \ python script/module file %s', filename)\n\n            with open(filename,\
    \ 'rb') as f:\n                source = f.read()\n\n            # If entry-point\
    \ script has no suffix, append .py when compiling the source. In POSIX builds,\
    \ the executable\n            # has no suffix either; this causes issues with\
    \ `traceback` module, as it tries to read the executable file\n            # when\
    \ trying to look up the code for the entry-point script (when current working\
    \ directory contains the\n            # executable).\n            _, ext = os.path.splitext(filename)\n\
    \            if not ext:\n                logger.debug(\"Appending .py to compiled\
    \ entry-point name...\")\n                filename += '.py'\n\n            try:\n\
    \                code_object = compile(source, filename, 'exec', optimize=optimize)\n\
    \            except SyntaxError:\n                logger.warning(\"Sytnax error\
    \ while compiling %s\", filename)\n                raise\n\n    return code_object\n\
    \n\ndef strip_paths_in_code(co, new_filename=None):\n    # Paths to remove from\
    \ filenames embedded in code objects\n    replace_paths = sys.path + CONF['pathex']\n\
    \    # Make sure paths end with os.sep and the longest paths are first\n    replace_paths\
    \ = sorted((os.path.join(f, '') for f in replace_paths), key=len, reverse=True)\n\
    \n    if new_filename is None:\n        original_filename = os.path.normpath(co.co_filename)\n\
    \        for f in replace_paths:\n            if original_filename.startswith(f):\n\
    \                new_filename = original_filename[len(f):]\n                break\n\
    \n        else:\n            return co\n\n    code_func = type(co)\n\n    consts\
    \ = tuple(\n        strip_paths_in_code(const_co, new_filename) if isinstance(const_co,\
    \ code_func) else const_co\n        for const_co in co.co_consts\n    )\n\n  \
    \  return co.replace(co_consts=consts, co_filename=new_filename)\n\n\ndef _should_include_system_binary(binary_tuple,\
    \ exceptions):\n    \"\"\"\n    Return True if the given binary_tuple describes\
    \ a system binary that should be included.\n\n    Exclude all system library binaries\
    \ other than those with \"lib-dynload\" in the destination or \"python\" in the\n\
    \    source, except for those matching the patterns in the exceptions list. Intended\
    \ to be used from the Analysis\n    exclude_system_libraries method.\n    \"\"\
    \"\n    dest = binary_tuple[0]\n    if dest.startswith('lib-dynload'):\n     \
    \   return True\n    src = binary_tuple[1]\n    if fnmatch.fnmatch(src, '*python*'):\n\
    \        return True\n    if not src.startswith('/lib') and not src.startswith('/usr/lib'):\n\
    \        return True\n    for exception in exceptions:\n        if fnmatch.fnmatch(dest,\
    \ exception):\n            return True\n    return False\n\n\ndef compile_pymodule(name,\
    \ src_path, workpath, optimize, code_cache=None):\n    \"\"\"\n    Given the name\
    \ and source file for a pure-python module, compile the module in the specified\
    \ working directory,\n    and return the name of resulting .pyc file. The paths\
    \ in the resulting .pyc module are anonymized by having their\n    absolute prefix\
    \ removed.\n\n    If a .pyc file with matching name already exists in the target\
    \ working directory, it is re-used (provided it has\n    compatible bytecode magic\
    \ in the header, and that its modification time is newer than that of the source\
    \ file).\n\n    If the specified module is available in binary-only form, the\
    \ input .pyc file is copied to the target working\n    directory and post-processed.\
    \ If the specified module is available in source form, it is compiled only if\n\
    \    corresponding code object is not available in the optional code-object cache;\
    \ otherwise, it is copied from cache\n    and post-processed. When compiling the\
    \ module, the specified byte-code optimization level is used.\n\n    It is up\
    \ to caller to ensure that the optional code-object cache contains only code-objects\
    \ of target optimization\n    level, and that if the specified working directory\
    \ already contains .pyc files, that they were created with target\n    optimization\
    \ level.\n    \"\"\"\n\n    # Construct the target .pyc filename in the workpath\n\
    \    split_name = name.split(\".\")\n    if \"__init__\" in src_path:\n      \
    \  # __init__ module; use \"__init__\" as module name, and construct parent path\
    \ using all components of the\n        # fully-qualified name\n        parent_dirs\
    \ = split_name\n        mod_basename = \"__init__\"\n    else:\n        # Regular\
    \ module; use last component of the fully-qualified name as module name, and the\
    \ rest as the parent\n        # path.\n        parent_dirs = split_name[:-1]\n\
    \        mod_basename = split_name[-1]\n    pyc_path = os.path.join(workpath,\
    \ *parent_dirs, mod_basename + '.pyc')\n\n    # Check if optional cache contains\
    \ module entry\n    code_object = code_cache.get(name, None) if code_cache else\
    \ None\n\n    if code_object is None:\n        _, ext = os.path.splitext(src_path)\n\
    \        ext = ext.lower()\n\n        if ext == '.py':\n            # Source py\
    \ file; read source and compile it.\n            with open(src_path, 'rb') as\
    \ f:\n                src_data = f.read()\n            code_object = compile(src_data,\
    \ src_path, 'exec', optimize=optimize)\n        elif ext == '.pyc':\n        \
    \    # The module is available in binary-only form. Read the contents of .pyc\
    \ file using helper function, which\n            # supports reading from either\
    \ stand-alone or archive-embedded .pyc files.\n            pyc_data = _read_pyc_data(src_path)\n\
    \            # Unmarshal code object; this is necessary if we want to strip paths\
    \ from it\n            code_object = marshal.loads(pyc_data[16:])\n        else:\n\
    \            raise ValueError(f\"Invalid python module file {src_path}; unhandled\
    \ extension {ext}!\")\n\n    # Strip code paths from the code object\n    code_object\
    \ = strip_paths_in_code(code_object)\n\n    # Write complete .pyc module to in-memory\
    \ stream. Then, check if .pyc file already exists, compare contents, and\n   \
    \ # (re)write it only if different. This avoids unnecessary (re)writing of the\
    \ file, and in turn also avoids\n    # unnecessary cache invalidation for targets\
    \ that make use of the .pyc file (e.g., PKG, COLLECT).\n    with io.BytesIO()\
    \ as pyc_stream:\n        pyc_stream.write(compat.BYTECODE_MAGIC)\n        pyc_stream.write(struct.pack('<I',\
    \ 0b01))  # PEP-552: hash-based pyc, check_source=False\n        pyc_stream.write(b'\\\
    00' * 8)  # Zero the source hash\n        marshal.dump(code_object, pyc_stream)\n\
    \        pyc_data = pyc_stream.getvalue()\n\n    if os.path.isfile(pyc_path):\n\
    \        with open(pyc_path, 'rb') as fh:\n            existing_pyc_data = fh.read()\n\
    \        if pyc_data == existing_pyc_data:\n            return pyc_path  # Return\
    \ path to (existing) file.\n\n    # Ensure the existence of parent directories\
    \ for the target pyc path\n    os.makedirs(os.path.dirname(pyc_path), exist_ok=True)\n\
    \n    # Write\n    with open(pyc_path, 'wb') as fh:\n        fh.write(pyc_data)\n\
    \n    # Return output path\n    return pyc_path\n\n\ndef _read_pyc_data(filename):\n\
    \    \"\"\"\n    Helper for reading data from .pyc files. Supports both stand-alone\
    \ and archive-embedded .pyc files. Used by\n    `compile_pymodule` and `get_code_object`\
    \ helper functions.\n    \"\"\"\n    src_file = pathlib.Path(filename)\n\n   \
    \ if src_file.is_file():\n        # Stand-alone .pyc file.\n        pyc_data =\
    \ src_file.read_bytes()\n    else:\n        # Check if .pyc file is stored in\
    \ a .zip archive, as is the case for stdlib modules in embeddable\n        # python\
    \ on Windows.\n        parent_zip_file = misc.path_to_parent_archive(src_file)\n\
    \        if parent_zip_file is not None and zipfile.is_zipfile(parent_zip_file):\n\
    \            with zipfile.ZipFile(parent_zip_file, 'r') as zip_archive:\n    \
    \            # NOTE: zip entry names must be in POSIX format, even on Windows!\n\
    \                zip_entry_name = str(src_file.relative_to(parent_zip_file).as_posix())\n\
    \                pyc_data = zip_archive.read(zip_entry_name)\n        else:\n\
    \            raise FileNotFoundError(f\"Cannot find .pyc file {filename!r}!\"\
    )\n\n        # Verify the python version\n        if pyc_data[:4] != compat.BYTECODE_MAGIC:\n\
    \            raise ValueError(f\"The .pyc module {filename} was compiled for incompatible\
    \ version of python!\")\n\n    return pyc_data\n\n\ndef postprocess_binaries_toc_pywin32(binaries):\n\
    \    \"\"\"\n    Process the given `binaries` TOC list to apply work around for\
    \ `pywin32` package, fixing the target directory\n    for collected extensions.\n\
    \    \"\"\"\n    # Ensure that all files collected from `win32`  or `pythonwin`\
    \ into top-level directory are put back into\n    # their corresponding directories.\
    \ They end up in top-level directory because `pywin32.pth` adds both\n    # directories\
    \ to the `sys.path`, so they end up visible as top-level directories. But these\
    \ extensions\n    # might in fact be linked against each other, so we should preserve\
    \ the directory layout for consistency\n    # between modulegraph-discovered extensions\
    \ and linked binaries discovered by link-time dependency analysis.\n    # Within\
    \ the same framework, also consider `pywin32_system32`, just in case.\n    PYWIN32_SUBDIRS\
    \ = {'win32', 'pythonwin', 'pywin32_system32'}\n\n    processed_binaries = []\n\
    \    for dest_name, src_name, typecode in binaries:\n        dest_path = pathlib.PurePath(dest_name)\n\
    \        src_path = pathlib.PurePath(src_name)\n\n        if dest_path.parent\
    \ == pathlib.PurePath('.') and src_path.parent.name.lower() in PYWIN32_SUBDIRS:\n\
    \            dest_path = pathlib.PurePath(src_path.parent.name) / dest_path\n\
    \            dest_name = str(dest_path)\n\n        processed_binaries.append((dest_name,\
    \ src_name, typecode))\n\n    return processed_binaries\n\n\ndef postprocess_binaries_toc_pywin32_anaconda(binaries):\n\
    \    \"\"\"\n    Process the given `binaries` TOC list to apply work around for\
    \ Anaconda `pywin32` package, fixing the location\n    of collected `pywintypes3X.dll`\
    \ and `pythoncom3X.dll`.\n    \"\"\"\n    # The Anaconda-provided `pywin32` package\
    \ installs three copies of `pywintypes3X.dll` and `pythoncom3X.dll`,\n    # located\
    \ in the following directories (relative to the environment):\n    # - Library/bin\n\
    \    # - Lib/site-packages/pywin32_system32\n    # - Lib/site-packages/win32\n\
    \    #\n    # This turns our dependency scanner and directory layout preservation\
    \ mechanism into a lottery based on what\n    # `pywin32` modules are imported\
    \ and in what order. To keep things simple, we deal with this insanity by\n  \
    \  # post-processing the `binaries` list, modifying the destination of offending\
    \ copies, and let the final TOC\n    # list normalization deal with potential\
    \ duplicates.\n    DLL_CANDIDATES = {\n        f\"pywintypes{sys.version_info[0]}{sys.version_info[1]}.dll\"\
    ,\n        f\"pythoncom{sys.version_info[0]}{sys.version_info[1]}.dll\",\n   \
    \ }\n\n    DUPLICATE_DIRS = {\n        pathlib.PurePath('.'),\n        pathlib.PurePath('win32'),\n\
    \    }\n\n    processed_binaries = []\n    for dest_name, src_name, typecode in\
    \ binaries:\n        # Check if we need to divert - based on the destination base\
    \ name and destination parent directory.\n        dest_path = pathlib.PurePath(dest_name)\n\
    \        if dest_path.name.lower() in DLL_CANDIDATES and dest_path.parent in DUPLICATE_DIRS:\n\
    \            dest_path = pathlib.PurePath(\"pywin32_system32\") / dest_path.name\n\
    \            dest_name = str(dest_path)\n\n        processed_binaries.append((dest_name,\
    \ src_name, typecode))\n\n    return processed_binaries\n\n\ndef create_base_library_zip(filename,\
    \ modules_toc, code_cache=None):\n    \"\"\"\n    Create a zip archive with python\
    \ modules that are needed during python interpreter initialization.\n    \"\"\"\
    \n    with zipfile.ZipFile(filename, 'w') as zf:\n        for name, src_path,\
    \ typecode in modules_toc:\n            # Obtain code object from cache, or compile\
    \ it.\n            code = None if code_cache is None else code_cache.get(name,\
    \ None)\n            if code is None:\n                optim_level = {'PYMODULE':\
    \ 0, 'PYMODULE-1': 1, 'PYMODULE-2': 2}[typecode]\n                code = get_code_object(name,\
    \ src_path, optimize=optim_level)\n            # Determine destination name\n\
    \            dest_name = name.replace('.', os.sep)\n            # Special case:\
    \ packages have an implied `__init__` filename that needs to be added.\n     \
    \       basename, ext = os.path.splitext(os.path.basename(src_path))\n       \
    \     if basename == '__init__':\n                dest_name += os.sep + '__init__'\n\
    \            dest_name += '.pyc'  # Always .pyc, regardless of optimization level.\n\
    \            # Write the .pyc module\n            with io.BytesIO() as fc:\n \
    \               fc.write(compat.BYTECODE_MAGIC)\n                fc.write(struct.pack('<I',\
    \ 0b01))  # PEP-552: hash-based pyc, check_source=False\n                fc.write(b'\\\
    00' * 8)  # Match behavior of `building.utils.compile_pymodule`\n            \
    \    code = strip_paths_in_code(code)  # Strip paths\n                marshal.dump(code,\
    \ fc)\n                # Use a ZipInfo to set timestamp for deterministic build.\n\
    \                info = zipfile.ZipInfo(dest_name)\n                zf.writestr(info,\
    \ fc.getvalue())\n\n### Source File Dependency Files Content\n### Dependency File:\
    \ compat.py\n# ----------------------------------------------------------------------------\n\
    # Copyright (c) 2005-2023, PyInstaller Development Team.\n#\n# Distributed under\
    \ the terms of the GNU General Public License (version 2\n# or later) with exception\
    \ for distributing the bootloader.\n#\n# The full license is in the file COPYING.txt,\
    \ distributed with this software.\n#\n# SPDX-License-Identifier: (GPL-2.0-or-later\
    \ WITH Bootloader-exception)\n# ----------------------------------------------------------------------------\n\
    \"\"\"\nVarious classes and functions to provide some backwards-compatibility\
    \ with previous versions of Python onward.\n\"\"\"\nfrom __future__ import annotations\n\
    \nimport errno\n\nimport importlib.machinery\nimport importlib.util\nimport os\n\
    import platform\nimport site\nimport subprocess\nimport sys\nimport sysconfig\n\
    import shutil\nimport types\n\nfrom PyInstaller._shared_with_waf import _pyi_machine\n\
    from PyInstaller.exceptions import ExecCommandFailed\n\n# setup.py sets this environment\
    \ variable to avoid errors due to unmet run-time dependencies. The PyInstaller.compat\n\
    # module is imported by setup.py to build wheels, and some dependencies that are\
    \ otherwise required at run-time\n# (importlib-metadata on python < 3.10, pywin32-ctypes\
    \ on Windows) might not be present while building wheels,\n# nor are they required\
    \ during that phase.\n_setup_py_mode = os.environ.get('_PYINSTALLER_SETUP_PY',\
    \ '0') != '0'\n\n# PyInstaller requires importlib.metadata from python >= 3.10\
    \ stdlib, or equivalent importlib-metadata >= 4.6.\nif _setup_py_mode:\n    importlib_metadata\
    \ = None\nelse:\n    if sys.version_info >= (3, 10):\n        import importlib.metadata\
    \ as importlib_metadata\n    else:\n        try:\n            import importlib_metadata\n\
    \        except ImportError as e:\n            from PyInstaller.exceptions import\
    \ ImportlibMetadataError\n            raise ImportlibMetadataError() from e\n\n\
    \        import packaging.version  # For importlib_metadata version check\n\n\
    \        # Validate the version\n        if packaging.version.parse(importlib_metadata.version(\"\
    importlib-metadata\")) < packaging.version.parse(\"4.6\"):\n            from PyInstaller.exceptions\
    \ import ImportlibMetadataError\n            raise ImportlibMetadataError()\n\n\
    # Strict collect mode, which raises error when trying to collect duplicate files\
    \ into PKG/CArchive or COLLECT.\nstrict_collect_mode = os.environ.get(\"PYINSTALLER_STRICT_COLLECT_MODE\"\
    , \"0\") != \"0\"\n\n# Copied from https://docs.python.org/3/library/platform.html#cross-platform.\n\
    is_64bits: bool = sys.maxsize > 2**32\n\n# Distinguish specific code for various\
    \ Python versions. Variables 'is_pyXY' mean that Python X.Y and up is supported.\n\
    # Keep even unsupported versions here to keep 3rd-party hooks working.\nis_py35\
    \ = sys.version_info >= (3, 5)\nis_py36 = sys.version_info >= (3, 6)\nis_py37\
    \ = sys.version_info >= (3, 7)\nis_py38 = sys.version_info >= (3, 8)\nis_py39\
    \ = sys.version_info >= (3, 9)\nis_py310 = sys.version_info >= (3, 10)\nis_py311\
    \ = sys.version_info >= (3, 11)\nis_py312 = sys.version_info >= (3, 12)\nis_py313\
    \ = sys.version_info >= (3, 13)\n\nis_win = sys.platform.startswith('win')\nis_win_10\
    \ = is_win and (platform.win32_ver()[0] == '10')\nis_win_11 = is_win and (platform.win32_ver()[0]\
    \ == '11')\nis_win_wine = False  # Running under Wine; determined later on.\n\
    is_cygwin = sys.platform == 'cygwin'\nis_darwin = sys.platform == 'darwin'  #\
    \ macOS\n\n# Unix platforms\nis_linux = sys.platform.startswith('linux')\nis_solar\
    \ = sys.platform.startswith('sun')  # Solaris\nis_aix = sys.platform.startswith('aix')\n\
    is_freebsd = sys.platform.startswith('freebsd')\nis_openbsd = sys.platform.startswith('openbsd')\n\
    is_hpux = sys.platform.startswith('hp-ux')\n\n# Some code parts are similar to\
    \ several unix platforms (e.g. Linux, Solaris, AIX).\n# macOS is not considered\
    \ as unix since there are many platform-specific details for Mac in PyInstaller.\n\
    is_unix = is_linux or is_solar or is_aix or is_freebsd or is_hpux or is_openbsd\n\
    \n# Linux distributions such as Alpine or OpenWRT use musl as their libc implementation\
    \ and resultantly need specially\n# compiled bootloaders. On musl systems, ldd\
    \ with no arguments prints 'musl' and its version.\nis_musl = is_linux and \"\
    musl\" in subprocess.run([\"ldd\"], capture_output=True, encoding=\"utf-8\").stderr\n\
    \n# macOS version\n_macos_ver = tuple(int(x) for x in platform.mac_ver()[0].split('.'))\
    \ if is_darwin else None\n\n# macOS 11 (Big Sur): if python is not compiled with\
    \ Big Sur support, it ends up in compatibility mode by default, which\n# is indicated\
    \ by platform.mac_ver() returning '10.16'. The lack of proper Big Sur support\
    \ breaks find_library()\n# function from ctypes.util module, as starting with\
    \ Big Sur, shared libraries are not visible on disk anymore. Support\n# for the\
    \ new library search mechanism was added in python 3.9 when compiled with Big\
    \ Sur support. In such cases,\n# platform.mac_ver() reports version as '11.x'.\
    \ The behavior can be further modified via SYSTEM_VERSION_COMPAT\n# environment\
    \ variable; which allows explicitly enabling or disabling the compatibility mode.\
    \ However, note that\n# disabling the compatibility mode and using python that\
    \ does not properly support Big Sur still leaves find_library()\n# broken (which\
    \ is a scenario that we ignore at the moment).\n# The same logic applies to macOS\
    \ 12 (Monterey).\nis_macos_11_compat = bool(_macos_ver) and _macos_ver[0:2] ==\
    \ (10, 16)  # Big Sur or newer in compat mode\nis_macos_11_native = bool(_macos_ver)\
    \ and _macos_ver[0:2] >= (11, 0)  # Big Sur or newer in native mode\nis_macos_11\
    \ = is_macos_11_compat or is_macos_11_native  # Big Sur or newer\n\n# Check if\
    \ python >= 3.13 was built with Py_GIL_DISABLED / free-threading (PEP703).\n#\n\
    # This affects the shared library name, which has the \"t\" ABI suffix, as per:\n\
    # https://github.com/python/steering-council/issues/221#issuecomment-1841593283\n\
    #\n# It also affects the layout of PyConfig structure used by bootloader; consequently\n\
    #  a) we need to inform bootloader what kind of build it is dealing with\n#  b)\
    \ we must not mix up shared libraries, in case multiple builds are present on\
    \ the system. Thus, strictly enforce the\n#     \"t\" ABI suffix in the PYDYLIB_NAMES,\
    \ if applicable.\nis_nogil = bool(sysconfig.get_config_var('Py_GIL_DISABLED'))\n\
    \n_py_suffix = \"t\" if is_nogil else \"\"\n\n# On different platforms is different\
    \ file for dynamic python library.\n_py_major, _py_minor = sys.version_info[:2]\n\
    if is_win or is_cygwin:\n    PYDYLIB_NAMES = {\n        f'python{_py_major}{_py_minor}{_py_suffix}.dll',\n\
    \        f'libpython{_py_major}{_py_minor}{_py_suffix}.dll',\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.dll',\n\
    \    }  # For MSYS2 environment\nelif is_darwin:\n    # The suffix in .framework\
    \ library name is capitalized, e.g., PythonT for freethreading-enabled build.\n\
    \    # The `libpython%d.%d%s.dylib` is there primarily for Anaconda installations,\
    \ but it also serves as a fallback in\n    # .framework builds, where `/Library/Frameworks/Python.framework/Versions/3.X/lib/libpython3.13.dylib`\
    \ is a symbolic\n    # link that points to `../Python`.\n    PYDYLIB_NAMES = {\n\
    \        f'Python{_py_suffix.upper()}',\n        f'.Python{_py_suffix.upper()}',\n\
    \        f'Python{_py_major}{_py_suffix.upper()}',\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.dylib',\n\
    \    }\nelif is_aix:\n    # Shared libs on AIX may be archives with shared object\
    \ members, hence the \".a\" suffix. However, starting with\n    # python 2.7.11\
    \ libpython?.?.so and Python3 libpython?.?m.so files are produced.\n    PYDYLIB_NAMES\
    \ = {\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.a',\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so',\n\
    \    }\nelif is_freebsd:\n    PYDYLIB_NAMES = {\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so.1',\n\
    \        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so.1.0',\n    }\nelif\
    \ is_openbsd:\n    PYDYLIB_NAMES = {\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so.0.0',\n\
    \    }\nelif is_hpux:\n    PYDYLIB_NAMES = {\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so',\n\
    \    }\nelif is_unix:\n    # Other *nix platforms.\n    # Python 2 .so library\
    \ on Linux is: libpython2.7.so.1.0\n    # Python 3 .so library on Linux is: libpython3.3.so.1.0\n\
    \    PYDYLIB_NAMES = {\n        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so.1.0',\n\
    \        f'libpython{_py_major}.{_py_minor}{_py_suffix}.so',\n    }\nelse:\n \
    \   raise SystemExit('Your platform is not yet supported. Please define constant\
    \ PYDYLIB_NAMES for your platform.')\n\ndel _py_major, _py_minor, _py_suffix\n\
    \n# In a virtual environment created by virtualenv (github.com/pypa/virtualenv)\
    \ there exists sys.real_prefix with the path\n# to the base Python installation\
    \ from which the virtual environment was created. This is true regardless of the\
    \ version\n# of Python used to execute the virtualenv command.\n#\n# In a virtual\
    \ environment created by the venv module available in the Python standard lib,\
    \ there exists sys.base_prefix\n# with the path to the base implementation. This\
    \ does not exist in a virtual environment created by virtualenv.\n#\n# The following\
    \ code creates compat.is_venv and is.virtualenv that are True when running a virtual\
    \ environment, and also\n# compat.base_prefix with the path to the base Python\
    \ installation.\n\nbase_prefix: str = os.path.abspath(getattr(sys, 'real_prefix',\
    \ getattr(sys, 'base_prefix', sys.prefix)))\n# Ensure `base_prefix` is not containing\
    \ any relative parts.\nis_venv = is_virtualenv = base_prefix != os.path.abspath(sys.prefix)\n\
    \n# Conda environments sometimes have different paths or apply patches to packages\
    \ that can affect how a hook or package\n# should access resources. Method for\
    \ determining conda taken from https://stackoverflow.com/questions/47610844#47610844\n\
    is_conda = os.path.isdir(os.path.join(base_prefix, 'conda-meta'))\n\n# Similar\
    \ to ``is_conda`` but is ``False`` using another ``venv``-like manager on top.\
    \ In this case, no packages\n# encountered will be conda packages meaning that\
    \ the default non-conda behaviour is generally desired from PyInstaller.\nis_pure_conda\
    \ = os.path.isdir(os.path.join(sys.prefix, 'conda-meta'))\n\n# Full path to python\
    \ interpreter.\npython_executable = getattr(sys, '_base_executable', sys.executable)\n\
    \n# Is this Python from Microsoft App Store (Windows only)? Python from Microsoft\
    \ App Store has executable pointing at\n# empty shims.\nis_ms_app_store = is_win\
    \ and os.path.getsize(python_executable) == 0\n\nif is_ms_app_store:\n    # Locate\
    \ the actual executable inside base_prefix.\n    python_executable = os.path.join(base_prefix,\
    \ os.path.basename(python_executable))\n    if not os.path.exists(python_executable):\n\
    \        raise SystemExit(\n            'PyInstaller cannot locate real python\
    \ executable belonging to Python from Microsoft App Store!'\n        )\n\n# Bytecode\
    \ magic value\nBYTECODE_MAGIC = importlib.util.MAGIC_NUMBER\n\n# List of suffixes\
    \ for Python C extension modules.\nEXTENSION_SUFFIXES = importlib.machinery.EXTENSION_SUFFIXES\n\
    ALL_SUFFIXES = importlib.machinery.all_suffixes()\n\n# On Windows we require pywin32-ctypes.\n\
    # -> all pyinstaller modules should use win32api from PyInstaller.compat to\n\
    #    ensure that it can work on MSYS2 (which requires pywin32-ctypes)\nif is_win:\n\
    \    if _setup_py_mode:\n        pywintypes = None\n        win32api = None\n\
    \    else:\n        try:\n            # Hide the `cffi` package from win32-ctypes\
    \ by temporarily blocking its import. This ensures that `ctypes`\n           \
    \ # backend is always used, even if `cffi` is available. The `cffi` backend uses\
    \ `pycparser`, which is\n            # incompatible with -OO mode (2nd optimization\
    \ level) due to its removal of docstrings.\n            # See https://github.com/pyinstaller/pyinstaller/issues/6345\n\
    \            # On the off chance that `cffi` has already been imported, store\
    \ the `sys.modules` entry so we can restore\n            # it after importing\
    \ `pywin32-ctypes` modules.\n            orig_cffi = sys.modules.get('cffi')\n\
    \            sys.modules['cffi'] = None\n\n            from win32ctypes.pywin32\
    \ import pywintypes  # noqa: F401, E402\n            from win32ctypes.pywin32\
    \ import win32api  # noqa: F401, E402\n        except ImportError as e:\n    \
    \        raise SystemExit(\n                'Could not import `pywintypes` or\
    \ `win32api` from `win32ctypes.pywin32`.\\n'\n                'Please make sure\
    \ that `pywin32-ctypes` is installed and importable, for example:\\n\\n'\n   \
    \             'pip install pywin32-ctypes\\n'\n            ) from e\n        finally:\n\
    \            # Unblock `cffi`.\n            if orig_cffi is not None:\n      \
    \          sys.modules['cffi'] = orig_cffi\n            else:\n              \
    \  del sys.modules['cffi']\n            del orig_cffi\n\n# macOS's platform.architecture()\
    \ can be buggy, so we do this manually here. Based off the python documentation:\n\
    # https://docs.python.org/3/library/platform.html#platform.architecture\nif is_darwin:\n\
    \    architecture = '64bit' if sys.maxsize > 2**32 else '32bit'\nelse:\n    architecture\
    \ = platform.architecture()[0]\n\n# Cygwin needs special handling, because platform.system()\
    \ contains identifiers such as MSYS_NT-10.0-19042 and\n# CYGWIN_NT-10.0-19042\
    \ that do not fit PyInstaller's OS naming scheme. Explicitly set `system` to 'Cygwin'.\n\
    system = 'Cygwin' if is_cygwin else platform.system()\n\n# Machine suffix for\
    \ bootloader.\nif is_win:\n    # On Windows ARM64 using an x64 Python environment,\
    \ platform.machine() returns ARM64 but\n    # we really want the bootloader that\
    \ matches the Python environment instead of the OS.\n    machine = _pyi_machine(os.environ.get(\"\
    PROCESSOR_ARCHITECTURE\", platform.machine()), platform.system())\nelse:\n   \
    \ machine = _pyi_machine(platform.machine(), platform.system())\n\n\n# Wine detection\
    \ and support\ndef is_wine_dll(filename: str | os.PathLike):\n    \"\"\"\n   \
    \ Check if the given PE file is a Wine DLL (PE-converted built-in, or fake/placeholder\
    \ one).\n\n    Returns True if the given file is a Wine DLL, False if not (or\
    \ if file cannot be analyzed or does not exist).\n    \"\"\"\n    _WINE_SIGNATURES\
    \ = (\n        b'Wine builtin DLL',  # PE-converted Wine DLL\n        b'Wine placeholder\
    \ DLL',  # Fake/placeholder Wine DLL\n    )\n    _MAX_LEN = max([len(sig) for\
    \ sig in _WINE_SIGNATURES])\n\n    # Wine places their DLL signature in the padding\
    \ area between the IMAGE_DOS_HEADER and IMAGE_NT_HEADERS. So we need\n    # to\
    \ compare the bytes that come right after IMAGE_DOS_HEADER, i.e., after initial\
    \ 64 bytes. We can read the file\n    # directly and avoid using the pefile library\
    \ to avoid performance penalty associated with full header parsing.\n    try:\n\
    \        with open(filename, 'rb') as fp:\n            fp.seek(64)\n         \
    \   signature = fp.read(_MAX_LEN)\n        return signature.startswith(_WINE_SIGNATURES)\n\
    \    except Exception:\n        pass\n    return False\n\n\nif is_win:\n    try:\n\
    \        import ctypes.util  # noqa: E402\n        is_win_wine = is_wine_dll(ctypes.util.find_library('kernel32'))\n\
    \    except Exception:\n        pass\n\n# Set and get environment variables does\
    \ not handle unicode strings correctly on Windows.\n\n# Acting on os.environ instead\
    \ of using getenv()/setenv()/unsetenv(), as suggested in\n# <http://docs.python.org/library/os.html#os.environ>:\
    \ \"Calling putenv() directly does not change os.environ, so it is\n# better to\
    \ modify os.environ.\" (Same for unsetenv.)\n\n\ndef getenv(name: str, default:\
    \ str | None = None):\n    \"\"\"\n    Returns unicode string containing value\
    \ of environment variable 'name'.\n    \"\"\"\n    return os.environ.get(name,\
    \ default)\n\n\ndef setenv(name: str, value: str):\n    \"\"\"\n    Accepts unicode\
    \ string and set it as environment variable 'name' containing value 'value'.\n\
    \    \"\"\"\n    os.environ[name] = value\n\n\ndef unsetenv(name: str):\n    \"\
    \"\"\n    Delete the environment variable 'name'.\n    \"\"\"\n    # Some platforms\
    \ (e.g., AIX) do not support `os.unsetenv()` and thus `del os.environ[name]` has\
    \ no effect on the\n    # real environment. For this case, we set the value to\
    \ the empty string.\n    os.environ[name] = \"\"\n    del os.environ[name]\n\n\
    \n# Exec commands in subprocesses.\n\n\ndef exec_command(\n    *cmdargs: str,\
    \ encoding: str | None = None, raise_enoent: bool | None = None, **kwargs: int\
    \ | bool | list | None\n):\n    \"\"\"\n    Run the command specified by the passed\
    \ positional arguments, optionally configured by the passed keyword arguments.\n\
    \n    .. DANGER::\n       **Ignore this function's return value** -- unless this\
    \ command's standard output contains _only_ pathnames, in\n       which case this\
    \ function returns the correct filesystem-encoded string expected by PyInstaller.\
    \ In all other\n       cases, this function's return value is _not_ safely usable.\n\
    \n       For backward compatibility, this function's return value non-portably\
    \ depends on the current Python version and\n       passed keyword arguments:\n\
    \n       * Under Python 3.x, this value is a **decoded `str` string**. However,\
    \ even this value is _not_ necessarily\n         safely usable:\n         * If\
    \ the `encoding` parameter is passed, this value is guaranteed to be safely usable.\n\
    \         * Else, this value _cannot_ be safely used for any purpose (e.g., string\
    \ manipulation or parsing), except to be\n           passed directly to another\
    \ non-Python command. Why? Because this value has been decoded with the encoding\n\
    \           specified by `sys.getfilesystemencoding()`, the encoding used by `os.fsencode()`\
    \ and `os.fsdecode()` to\n           convert from platform-agnostic to platform-specific\
    \ pathnames. This is _not_ necessarily the encoding with\n           which this\
    \ command's standard output was encoded. Cue edge-case decoding exceptions.\n\n\
    \    Parameters\n    ----------\n    cmdargs :\n        Variadic list whose:\n\
    \        1. Mandatory first element is the absolute path, relative path, or basename\
    \ in the current `${PATH}` of the\n           command to run.\n        2. Optional\
    \ remaining elements are arguments to pass to this command.\n    encoding : str,\
    \ optional\n        Optional keyword argument specifying the encoding with which\
    \ to decode this command's standard output under\n        Python 3. As this function's\
    \ return value should be ignored, this argument should _never_ be passed.\n  \
    \  raise_enoent : boolean, optional\n        Optional keyword argument to simply\
    \ raise the exception if the executing the command fails since to the command\n\
    \        is not found. This is useful to checking id a command exists.\n\n   \
    \ All remaining keyword arguments are passed as is to the `subprocess.Popen()`\
    \ constructor.\n\n    Returns\n    ----------\n    str\n        Ignore this value.\
    \ See discussion above.\n    \"\"\"\n\n    proc = subprocess.Popen(cmdargs, stdout=subprocess.PIPE,\
    \ **kwargs)\n    try:\n        out = proc.communicate(timeout=60)[0]\n    except\
    \ OSError as e:\n        if raise_enoent and e.errno == errno.ENOENT:\n      \
    \      raise\n        print('--' * 20, file=sys.stderr)\n        print(\"Error\
    \ running '%s':\" % \" \".join(cmdargs), file=sys.stderr)\n        print(e, file=sys.stderr)\n\
    \        print('--' * 20, file=sys.stderr)\n        raise ExecCommandFailed(\"\
    Error: Executing command failed!\") from e\n    except subprocess.TimeoutExpired:\n\
    \        proc.kill()\n        raise\n\n    # stdout/stderr are returned as a byte\
    \ array NOT as string, so we need to convert that to proper encoding.\n    try:\n\
    \        if encoding:\n            out = out.decode(encoding)\n        else:\n\
    \            # If no encoding is given, assume we are reading filenames from stdout\
    \ only because it is the common case.\n            out = os.fsdecode(out)\n  \
    \  except UnicodeDecodeError as e:\n        # The sub-process used a different\
    \ encoding; provide more information to ease debugging.\n        print('--' *\
    \ 20, file=sys.stderr)\n        print(str(e), file=sys.stderr)\n        print('These\
    \ are the bytes around the offending byte:', file=sys.stderr)\n        print('--'\
    \ * 20, file=sys.stderr)\n        raise\n    return out\n\n\ndef exec_command_rc(*cmdargs:\
    \ str, **kwargs: float | bool | list | None):\n    \"\"\"\n    Return the exit\
    \ code of the command specified by the passed positional arguments, optionally\
    \ configured by the\n    passed keyword arguments.\n\n    Parameters\n    ----------\n\
    \    cmdargs : list\n        Variadic list whose:\n        1. Mandatory first\
    \ element is the absolute path, relative path, or basename in the current `${PATH}`\
    \ of the\n           command to run.\n        2. Optional remaining elements are\
    \ arguments to pass to this command.\n\n    All keyword arguments are passed as\
    \ is to the `subprocess.call()` function.\n\n    Returns\n    ----------\n   \
    \ int\n        This command's exit code as an unsigned byte in the range `[0,\
    \ 255]`, where 0 signifies success and all other\n        values signal a failure.\n\
    \    \"\"\"\n\n    # 'encoding' keyword is not supported for 'subprocess.call';\
    \ remove it from kwargs.\n    if 'encoding' in kwargs:\n        kwargs.pop('encoding')\n\
    \    return subprocess.call(cmdargs, **kwargs)\n\n\ndef exec_command_all(*cmdargs:\
    \ str, encoding: str | None = None, **kwargs: int | bool | list | None):\n   \
    \ \"\"\"\n    Run the command specified by the passed positional arguments, optionally\
    \ configured by the passed keyword arguments.\n\n    .. DANGER::\n       **Ignore\
    \ this function's return value.** If this command's standard output consists solely\
    \ of pathnames, consider\n       calling `exec_command()`\n\n    Parameters\n\
    \    ----------\n    cmdargs : str\n        Variadic list whose:\n        1. Mandatory\
    \ first element is the absolute path, relative path, or basename in the current\
    \ `${PATH}` of the\n           command to run.\n        2. Optional remaining\
    \ elements are arguments to pass to this command.\n    encoding : str, optional\n\
    \        Optional keyword argument specifying the encoding with which to decode\
    \ this command's standard output. As this\n        function's return value should\
    \ be ignored, this argument should _never_ be passed.\n\n    All remaining keyword\
    \ arguments are passed as is to the `subprocess.Popen()` constructor.\n\n    Returns\n\
    \    ----------\n    (int, str, str)\n        Ignore this 3-element tuple `(exit_code,\
    \ stdout, stderr)`. See the `exec_command()` function for discussion.\n    \"\"\
    \"\n    proc = subprocess.Popen(\n        cmdargs,\n        bufsize=-1,  # Default\
    \ OS buffer size.\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n\
    \        **kwargs\n    )\n    # Waits for subprocess to complete.\n    try:\n\
    \        out, err = proc.communicate(timeout=60)\n    except subprocess.TimeoutExpired:\n\
    \        proc.kill()\n        raise\n    # stdout/stderr are returned as a byte\
    \ array NOT as string. Thus we need to convert that to proper encoding.\n    try:\n\
    \        if encoding:\n            out = out.decode(encoding)\n            err\
    \ = err.decode(encoding)\n        else:\n            # If no encoding is given,\
    \ assume we're reading filenames from stdout only because it's the common case.\n\
    \            out = os.fsdecode(out)\n            err = os.fsdecode(err)\n    except\
    \ UnicodeDecodeError as e:\n        # The sub-process used a different encoding,\
    \ provide more information to ease debugging.\n        print('--' * 20, file=sys.stderr)\n\
    \        print(str(e), file=sys.stderr)\n        print('These are the bytes around\
    \ the offending byte:', file=sys.stderr)\n        print('--' * 20, file=sys.stderr)\n\
    \        raise\n\n    return proc.returncode, out, err\n\n\ndef __wrap_python(args,\
    \ kwargs):\n    cmdargs = [sys.executable]\n\n    # macOS supports universal binaries\
    \ (binary for multiple architectures. We need to ensure that subprocess\n    #\
    \ binaries are running for the same architecture as python executable. It is necessary\
    \ to run binaries with 'arch'\n    # command.\n    if is_darwin:\n        if architecture\
    \ == '64bit':\n            if platform.machine() == 'arm64':\n               \
    \ py_prefix = ['arch', '-arm64']  # Apple M1\n            else:\n            \
    \    py_prefix = ['arch', '-x86_64']  # Intel\n        elif architecture == '32bit':\n\
    \            py_prefix = ['arch', '-i386']\n        else:\n            py_prefix\
    \ = []\n        # Since macOS 10.11, the environment variable DYLD_LIBRARY_PATH\
    \ is no more inherited by child processes, so we\n        # proactively propagate\
    \ the current value using the `-e` option of the `arch` command.\n        if 'DYLD_LIBRARY_PATH'\
    \ in os.environ:\n            path = os.environ['DYLD_LIBRARY_PATH']\n       \
    \     py_prefix += ['-e', 'DYLD_LIBRARY_PATH=%s' % path]\n        cmdargs = py_prefix\
    \ + cmdargs\n\n    if not __debug__:\n        cmdargs.append('-O')\n\n    cmdargs.extend(args)\n\
    \n    env = kwargs.get('env')\n    if env is None:\n        env = dict(**os.environ)\n\
    \n    # Ensure python 3 subprocess writes 'str' as utf-8\n    env['PYTHONIOENCODING']\
    \ = 'UTF-8'\n    # ... and ensure we read output as utf-8\n    kwargs['encoding']\
    \ = 'UTF-8'\n\n    return cmdargs, kwargs\n\n\ndef exec_python(*args: str, **kwargs:\
    \ str | None):\n    \"\"\"\n    Wrap running python script in a subprocess.\n\n\
    \    Return stdout of the invoked command.\n    \"\"\"\n    cmdargs, kwargs =\
    \ __wrap_python(args, kwargs)\n    return exec_command(*cmdargs, **kwargs)\n\n\
    \ndef exec_python_rc(*args: str, **kwargs: str | None):\n    \"\"\"\n    Wrap\
    \ running python script in a subprocess.\n\n    Return exit code of the invoked\
    \ command.\n    \"\"\"\n    cmdargs, kwargs = __wrap_python(args, kwargs)\n  \
    \  return exec_command_rc(*cmdargs, **kwargs)\n\n\n# Path handling.\n\n\n# Site-packages\
    \ functions - use native function if available.\ndef getsitepackages(prefixes:\
    \ list | None = None):\n    \"\"\"\n    Returns a list containing all global site-packages\
    \ directories.\n\n    For each directory present in ``prefixes`` (or the global\
    \ ``PREFIXES``), this function finds its `site-packages`\n    subdirectory depending\
    \ on the system environment, and returns a list of full paths.\n    \"\"\"\n \
    \   # This implementation was copied from the ``site`` module, python 3.7.3.\n\
    \    sitepackages = []\n    seen = set()\n\n    if prefixes is None:\n       \
    \ prefixes = [sys.prefix, sys.exec_prefix]\n\n    for prefix in prefixes:\n  \
    \      if not prefix or prefix in seen:\n            continue\n        seen.add(prefix)\n\
    \n        if os.sep == '/':\n            sitepackages.append(os.path.join(prefix,\
    \ \"lib\", \"python%d.%d\" % sys.version_info[:2], \"site-packages\"))\n     \
    \   else:\n            sitepackages.append(prefix)\n            sitepackages.append(os.path.join(prefix,\
    \ \"lib\", \"site-packages\"))\n    return sitepackages\n\n\n# Backported for\
    \ virtualenv. Module 'site' in virtualenv might not have this attribute.\ngetsitepackages\
    \ = getattr(site, 'getsitepackages', getsitepackages)\n\n\n# Wrapper to load a\
    \ module from a Python source file. This function loads import hooks when processing\
    \ them.\ndef importlib_load_source(name: str, pathname: str):\n    # Import module\
    \ from a file.\n    mod_loader = importlib.machinery.SourceFileLoader(name, pathname)\n\
    \    mod = types.ModuleType(mod_loader.name)\n    mod.__file__ = mod_loader.get_filename()\
    \  # Some hooks require __file__ attribute in their namespace\n    mod_loader.exec_module(mod)\n\
    \    return mod\n\n\n# Patterns of module names that should be bundled into the\
    \ base_library.zip to be available during bootstrap.\n# These modules include\
    \ direct or indirect dependencies of encodings.* modules. The encodings modules\
    \ must be\n# recursively included to set the I/O encoding during python startup.\
    \ Similarly, this list should include\n# modules used by PyInstaller's bootstrap\
    \ scripts and modules (loader/pyi*.py)\n\nPY3_BASE_MODULES = {\n    '_collections_abc',\n\
    \    '_weakrefset',\n    'abc',\n    'codecs',\n    'collections',\n    'copyreg',\n\
    \    'encodings',\n    'enum',\n    'functools',\n    'genericpath',  # dependency\
    \ of os.path\n    'io',\n    'heapq',\n    'keyword',\n    'linecache',\n    'locale',\n\
    \    'ntpath',  # dependency of os.path\n    'operator',\n    'os',\n    'posixpath',\
    \  # dependency of os.path\n    're',\n    'reprlib',\n    'sre_compile',\n  \
    \  'sre_constants',\n    'sre_parse',\n    'stat',  # dependency of os.path\n\
    \    'traceback',  # for startup errors\n    'types',\n    'weakref',\n    'warnings',\n\
    }\n\nif not is_py310:\n    PY3_BASE_MODULES.add('_bootlocale')\n\n# Object types\
    \ of Pure Python modules in modulegraph dependency graph.\n# Pure Python modules\
    \ have code object (attribute co_code).\nPURE_PYTHON_MODULE_TYPES = {\n    'SourceModule',\n\
    \    'CompiledModule',\n    'Package',\n    'NamespacePackage',\n    # Deprecated.\n\
    \    # TODO Could these module types be removed?\n    'FlatPackage',\n    'ArchiveModule',\n\
    }\n# Object types of special Python modules (built-in, run-time, namespace package)\
    \ in modulegraph dependency graph that do\n# not have code object.\nSPECIAL_MODULE_TYPES\
    \ = {\n    # Omit AliasNode from here (and consequently from VALID_MODULE_TYPES),\
    \ in order to prevent PyiModuleGraph from\n    # running standard hooks for aliased\
    \ modules.\n    #'AliasNode',\n    'BuiltinModule',\n    'RuntimeModule',\n  \
    \  'RuntimePackage',\n\n    # PyInstaller handles scripts differently and not\
    \ as standard Python modules.\n    'Script',\n}\n# Object types of Binary Python\
    \ modules (extensions, etc) in modulegraph dependency graph.\nBINARY_MODULE_TYPES\
    \ = {\n    'Extension',\n    'ExtensionPackage',\n}\n# Object types of valid Python\
    \ modules in modulegraph dependency graph.\nVALID_MODULE_TYPES = PURE_PYTHON_MODULE_TYPES\
    \ | SPECIAL_MODULE_TYPES | BINARY_MODULE_TYPES\n# Object types of bad/missing/invalid\
    \ Python modules in modulegraph dependency graph.\n# TODO: should be 'Invalid'\
    \ module types also in the 'MISSING' set?\nBAD_MODULE_TYPES = {\n    'BadModule',\n\
    \    'ExcludedModule',\n    'InvalidSourceModule',\n    'InvalidCompiledModule',\n\
    \    'MissingModule',\n\n    # Runtime modules and packages are technically valid\
    \ rather than bad, but exist only in-memory rather than on-disk\n    # (typically\
    \ due to pre_safe_import_module() hooks), and hence cannot be physically frozen.\
    \ For simplicity, these\n    # nodes are categorized as bad rather than valid.\n\
    \    'RuntimeModule',\n    'RuntimePackage',\n}\nALL_MODULE_TYPES = VALID_MODULE_TYPES\
    \ | BAD_MODULE_TYPES\n# TODO: review this mapping to TOC, remove useless entries.\n\
    # Dictionary to map ModuleGraph node types to TOC typecodes.\nMODULE_TYPES_TO_TOC_DICT\
    \ = {\n    # Pure modules.\n    'AliasNode': 'PYMODULE',\n    'Script': 'PYSOURCE',\n\
    \    'SourceModule': 'PYMODULE',\n    'CompiledModule': 'PYMODULE',\n    'Package':\
    \ 'PYMODULE',\n    'FlatPackage': 'PYMODULE',\n    'ArchiveModule': 'PYMODULE',\n\
    \    # Binary modules.\n    'Extension': 'EXTENSION',\n    'ExtensionPackage':\
    \ 'EXTENSION',\n    # Special valid modules.\n    'BuiltinModule': 'BUILTIN',\n\
    \    'NamespacePackage': 'PYMODULE',\n    # Bad modules.\n    'BadModule': 'bad',\n\
    \    'ExcludedModule': 'excluded',\n    'InvalidSourceModule': 'invalid',\n  \
    \  'InvalidCompiledModule': 'invalid',\n    'MissingModule': 'missing',\n    'RuntimeModule':\
    \ 'runtime',\n    'RuntimePackage': 'runtime',\n    # Other.\n    'does not occur':\
    \ 'BINARY',\n}\n\n\ndef check_requirements():\n    \"\"\"\n    Verify that all\
    \ requirements to run PyInstaller are met.\n\n    Fail hard if any requirement\
    \ is not met.\n    \"\"\"\n    # Fail hard if Python does not have minimum required\
    \ version\n    if sys.version_info < (3, 8):\n        raise EnvironmentError('PyInstaller\
    \ requires Python 3.8 or newer.')\n\n    # There are some old packages which used\
    \ to be backports of libraries which are now part of the standard library.\n \
    \   # These backports are now unmaintained and contain only an older subset of\
    \ features leading to obscure errors like\n    # \"enum has not attribute IntFlag\"\
    \ if installed.\n    from importlib.metadata import distribution, PackageNotFoundError\n\
    \n    for name in [\"enum34\", \"typing\", \"pathlib\"]:\n        try:\n     \
    \       dist = distribution(name)\n        except PackageNotFoundError:\n    \
    \        continue\n        remove = \"conda remove\" if is_conda else f'\"{sys.executable}\"\
    \ -m pip uninstall {name}'\n        raise SystemExit(\n            f\"The '{name}'\
    \ package is an obsolete backport of a standard library package and is incompatible\
    \ with \"\n            f\"PyInstaller. Please remove this package (located in\
    \ {dist.locate_file('')}) using\\n    {remove}\\n\"\n            \"then try again.\"\
    \n        )\n\n    # Bail out if binutils is not installed.\n    if is_linux and\
    \ shutil.which(\"objdump\") is None:\n        raise SystemExit(\n            \"\
    On Linux, objdump is required. It is typically provided by the 'binutils' package\
    \ \"\n            \"installable via your Linux distribution's package manager.\"\
    \n        )\n\n\n### Dependency File: config.py\n#-----------------------------------------------------------------------------\n\
    # Copyright (c) 2005-2023, PyInstaller Development Team.\n#\n# Distributed under\
    \ the terms of the GNU General Public License (version 2\n# or later) with exception\
    \ for distributing the bootloader.\n#\n# The full license is in the file COPYING.txt,\
    \ distributed with this software.\n#\n# SPDX-License-Identifier: (GPL-2.0-or-later\
    \ WITH Bootloader-exception)\n#-----------------------------------------------------------------------------\n\
    \"\"\"\nThis module holds run-time PyInstaller configuration.\n\nVariable CONF\
    \ is a dict() with all configuration options that are necessary for the build\
    \ phase. Build phase is done by\npassing .spec file to exec() function. CONF variable\
    \ is the only way how to pass arguments to exec() and how to avoid\nusing 'global'\
    \ variables.\n\nNOTE: Having 'global' variables does not play well with the test\
    \ suite because it does not provide isolated environments\nfor tests. Some tests\
    \ might fail in this case.\n\nNOTE: The 'CONF' dict() is cleaned after building\
    \ phase to not interfere with any other possible test.\n\nTo pass any arguments\
    \ to build phase, just do:\n\n    from PyInstaller.config import CONF\n    CONF['my_var_name']\
    \ = my_value\n\nAnd to use this variable in the build phase:\n\n    from PyInstaller.config\
    \ import CONF\n    foo = CONF['my_var_name']\n\n\nThis is the list of known variables.\
    \ (Please update it if necessary.)\n\ncachedir\nhiddenimports\nnoconfirm\npathex\n\
    ui_admin\nui_access\nupx_available\nupx_dir\nworkpath\n\ntests_modgraph  - cached\
    \ PyiModuleGraph object to speed up tests\n\ncode_cache - dictionary associating\
    \ `Analysis.pure` list instances with code cache dictionaries. Used by PYZ writer.\n\
    \"\"\"\n\n# NOTE: Do not import other PyInstaller modules here. Just define constants\
    \ here.\n\nCONF = {\n    # Unit tests require this key to exist.\n    'pathex':\
    \ [],\n}\n\n\n### Dependency File: exceptions.py\n#-----------------------------------------------------------------------------\n\
    # Copyright (c) 2005-2023, PyInstaller Development Team.\n#\n# Distributed under\
    \ the terms of the GNU General Public License (version 2\n# or later) with exception\
    \ for distributing the bootloader.\n#\n# The full license is in the file COPYING.txt,\
    \ distributed with this software.\n#\n# SPDX-License-Identifier: (GPL-2.0-or-later\
    \ WITH Bootloader-exception)\n#-----------------------------------------------------------------------------\n\
    \nfrom PyInstaller import compat\n\n\nclass ExecCommandFailed(SystemExit):\n \
    \   pass\n\n\nclass HookError(Exception):\n    \"\"\"\n    Base class for hook\
    \ related errors.\n    \"\"\"\n    pass\n\n\nclass ImportErrorWhenRunningHook(HookError):\n\
    \    def __str__(self):\n        return (\n            \"Failed to import module\
    \ {0} required by hook for module {1}. Please check whether module {0} actually\
    \ \"\n            \"exists and whether the hook is compatible with your version\
    \ of {1}: You might want to read more about \"\n            \"hooks in the manual\
    \ and provide a pull-request to improve PyInstaller.\".format(self.args[0], self.args[1])\n\
    \        )\n\n\nclass RemovedCipherFeatureError(SystemExit):\n    def __init__(self,\
    \ message):\n        super().__init__(\n            f\"Bytecode encryption was\
    \ removed in PyInstaller v6.0. {message}\"\n            \" For the rationale and\
    \ alternatives see https://github.com/pyinstaller/pyinstaller/pull/6999\"\n  \
    \      )\n\n\nclass RemovedExternalManifestError(SystemExit):\n    def __init__(self,\
    \ message):\n        super().__init__(f\"Support for external executable manifest\
    \ was removed in PyInstaller v6.0. {message}\")\n\n\nclass RemovedWinSideBySideSupportError(SystemExit):\n\
    \    def __init__(self, message):\n        super().__init__(\n            f\"\
    Support for collecting and processing WinSxS assemblies was removed in PyInstaller\
    \ v6.0. {message}\"\n        )\n\n\n_MISSING_PYTHON_LIB_MSG = \\\n\"\"\"Python\
    \ library not found: {0}\n    This means your Python installation does not come\
    \ with proper shared library files.\n    This usually happens due to missing development\
    \ package, or unsuitable build parameters of the Python installation.\n\n    *\
    \ On Debian/Ubuntu, you need to install Python development packages:\n      *\
    \ apt-get install python3-dev\n      * apt-get install python-dev\n    * If you\
    \ are building Python by yourself, rebuild with `--enable-shared` (or, `--enable-framework`\
    \ on macOS).\n\"\"\"  # noqa: E122\n\n\nclass PythonLibraryNotFoundError(IOError):\n\
    \    def __init__(self):\n        super().__init__(_MISSING_PYTHON_LIB_MSG.format(\"\
    , \".join(compat.PYDYLIB_NAMES),))\n\n\nclass InvalidSrcDestTupleError(SystemExit):\n\
    \    def __init__(self, src_dest, message):\n        super().__init__(f\"Invalid\
    \ (SRC, DEST_DIR) tuple: {src_dest!r}. {message}\")\n\n\nclass ImportlibMetadataError(SystemExit):\n\
    \    def __init__(self):\n        super().__init__(\n            \"PyInstaller\
    \ requires importlib.metadata from python >= 3.10 stdlib or importlib_metadata\
    \ from \"\n            \"importlib-metadata >= 4.6\"\n        )\n\n\n### Dependency\
    \ File: log.py\n#-----------------------------------------------------------------------------\n\
    # Copyright (c) 2013-2023, PyInstaller Development Team.\n#\n# Distributed under\
    \ the terms of the GNU General Public License (version 2\n# or later) with exception\
    \ for distributing the bootloader.\n#\n# The full license is in the file COPYING.txt,\
    \ distributed with this software.\n#\n# SPDX-License-Identifier: (GPL-2.0-or-later\
    \ WITH Bootloader-exception)\n#-----------------------------------------------------------------------------\n\
    \"\"\"\nLogging module for PyInstaller.\n\"\"\"\n\n__all__ = ['getLogger', 'INFO',\
    \ 'WARN', 'DEBUG', 'TRACE', 'ERROR', 'FATAL', 'DEPRECATION']\n\nimport os\nimport\
    \ logging\nfrom logging import DEBUG, ERROR, FATAL, INFO, WARN, getLogger\n\n\
    TRACE = DEBUG - 5\nlogging.addLevelName(TRACE, 'TRACE')\nDEPRECATION = WARN +\
    \ 5\nlogging.addLevelName(DEPRECATION, 'DEPRECATION')\nLEVELS = {\n    'TRACE':\
    \ TRACE,\n    'DEBUG': DEBUG,\n    'INFO': INFO,\n    'WARN': WARN,\n    'DEPRECATION':\
    \ DEPRECATION,\n    'ERROR': ERROR,\n    'FATAL': FATAL,\n}\n\nFORMAT = '%(relativeCreated)d\
    \ %(levelname)s: %(message)s'\n_env_level = os.environ.get(\"PYI_LOG_LEVEL\",\
    \ \"INFO\")\ntry:\n    level = LEVELS[_env_level.upper()]\nexcept KeyError:\n\
    \    raise SystemExit(f\"Invalid PYI_LOG_LEVEL value '{_env_level}'. Should be\
    \ one of {list(LEVELS)}.\")\nlogging.basicConfig(format=FORMAT, level=level)\n\
    logger = getLogger('PyInstaller')\n\n\ndef __add_options(parser):\n    parser.add_argument(\n\
    \        '--log-level',\n        choices=LEVELS,\n        metavar=\"LEVEL\",\n\
    \        dest='loglevel',\n        help='Amount of detail in build-time console\
    \ messages. LEVEL may be one of %s (default: INFO). '\n        'Also settable\
    \ via and overrides the PYI_LOG_LEVEL environment variable.' % ', '.join(LEVELS),\n\
    \    )\n\n\ndef __process_options(parser, opts):\n    if opts.loglevel:\n    \
    \    try:\n            level = opts.loglevel.upper()\n            _level = LEVELS[level]\n\
    \        except KeyError:\n            parser.error('Unknown log level `%s`' %\
    \ opts.loglevel)\n        logger.setLevel(_level)\n        os.environ[\"PYI_LOG_LEVEL\"\
    ] = level\n\n\n### Dependency File: misc.py\n#-----------------------------------------------------------------------------\n\
    # Copyright (c) 2013-2023, PyInstaller Development Team.\n#\n# Distributed under\
    \ the terms of the GNU General Public License (version 2\n# or later) with exception\
    \ for distributing the bootloader.\n#\n# The full license is in the file COPYING.txt,\
    \ distributed with this software.\n#\n# SPDX-License-Identifier: (GPL-2.0-or-later\
    \ WITH Bootloader-exception)\n#-----------------------------------------------------------------------------\n\
    \"\"\"\nThis module contains miscellaneous functions that do not fit anywhere\
    \ else.\n\"\"\"\n\nimport glob\nimport os\nimport pprint\nimport codecs\nimport\
    \ re\nimport tokenize\nimport io\nimport pathlib\n\nfrom PyInstaller import log\
    \ as logging\nfrom PyInstaller.compat import is_win\n\nlogger = logging.getLogger(__name__)\n\
    \n\ndef dlls_in_subdirs(directory):\n    \"\"\"\n    Returns a list *.dll, *.so,\
    \ *.dylib in the given directory and its subdirectories.\n    \"\"\"\n    filelist\
    \ = []\n    for root, dirs, files in os.walk(directory):\n        filelist.extend(dlls_in_dir(root))\n\
    \    return filelist\n\n\ndef dlls_in_dir(directory):\n    \"\"\"\n    Returns\
    \ a list of *.dll, *.so, *.dylib in the given directory.\n    \"\"\"\n    return\
    \ files_in_dir(directory, [\"*.so\", \"*.dll\", \"*.dylib\"])\n\n\ndef files_in_dir(directory,\
    \ file_patterns=None):\n    \"\"\"\n    Returns a list of files in the given directory\
    \ that match the given pattern.\n    \"\"\"\n\n    file_patterns = file_patterns\
    \ or []\n\n    files = []\n    for file_pattern in file_patterns:\n        files.extend(glob.glob(os.path.join(directory,\
    \ file_pattern)))\n    return files\n\n\ndef get_path_to_toplevel_modules(filename):\n\
    \    \"\"\"\n    Return the path to top-level directory that contains Python modules.\n\
    \n    It will look in parent directories for __init__.py files. The first parent\
    \ directory without __init__.py is the\n    top-level directory.\n\n    Returned\
    \ directory might be used to extend the PYTHONPATH.\n    \"\"\"\n    curr_dir\
    \ = os.path.dirname(os.path.abspath(filename))\n    pattern = '__init__.py'\n\n\
    \    # Try max. 10 levels up.\n    try:\n        for i in range(10):\n       \
    \     files = set(os.listdir(curr_dir))\n            # 'curr_dir' is still not\
    \ top-level; go to parent dir.\n            if pattern in files:\n           \
    \     curr_dir = os.path.dirname(curr_dir)\n            # Top-level dir found;\
    \ return it.\n            else:\n                return curr_dir\n    except IOError:\n\
    \        pass\n    # No top-level directory found, or error was encountered.\n\
    \    return None\n\n\ndef mtime(fnm):\n    try:\n        # TODO: explain why this\
    \ does not use os.path.getmtime() ?\n        #       - It is probably not used\
    \ because it returns float and not int.\n        return os.stat(fnm)[8]\n    except\
    \ Exception:\n        return 0\n\n\ndef save_py_data_struct(filename, data):\n\
    \    \"\"\"\n    Save data into text file as Python data structure.\n    :param\
    \ filename:\n    :param data:\n    :return:\n    \"\"\"\n    dirname = os.path.dirname(filename)\n\
    \    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n    with open(filename,\
    \ 'w', encoding='utf-8') as f:\n        pprint.pprint(data, f)\n\n\ndef load_py_data_struct(filename):\n\
    \    \"\"\"\n    Load data saved as python code and interpret that code.\n   \
    \ :param filename:\n    :return:\n    \"\"\"\n    with open(filename, 'r', encoding='utf-8')\
    \ as f:\n        if is_win:\n            # import versioninfo so that VSVersionInfo\
    \ can parse correctly.\n            from PyInstaller.utils.win32 import versioninfo\
    \  # noqa: F401\n\n        return eval(f.read())\n\n\ndef absnormpath(apath):\n\
    \    return os.path.abspath(os.path.normpath(apath))\n\n\ndef module_parent_packages(full_modname):\n\
    \    \"\"\"\n    Return list of parent package names.\n        'aaa.bb.c.dddd'\
    \ ->  ['aaa', 'aaa.bb', 'aaa.bb.c']\n    :param full_modname: Full name of a module.\n\
    \    :return: List of parent module names.\n    \"\"\"\n    prefix = ''\n    parents\
    \ = []\n    # Ignore the last component in module name and get really just parent,\
    \ grandparent, great grandparent, etc.\n    for pkg in full_modname.split('.')[0:-1]:\n\
    \        # Ensure that first item does not start with dot '.'\n        prefix\
    \ += '.' + pkg if prefix else pkg\n        parents.append(prefix)\n    return\
    \ parents\n\n\ndef is_file_qt_plugin(filename):\n    \"\"\"\n    Check if the\
    \ given file is a Qt plugin file.\n    :param filename: Full path to file to check.\n\
    \    :return: True if given file is a Qt plugin file, False if not.\n    \"\"\"\
    \n\n    # Check the file contents; scan for QTMETADATA string. The scan is based\
    \ on the brute-force Windows codepath of\n    # findPatternUnloaded() from qtbase/src/corelib/plugin/qlibrary.cpp\
    \ in Qt5.\n    with open(filename, 'rb') as fp:\n        fp.seek(0, os.SEEK_END)\n\
    \        end_pos = fp.tell()\n\n        SEARCH_CHUNK_SIZE = 8192\n        QTMETADATA_MAGIC\
    \ = b'QTMETADATA '\n\n        magic_offset = -1\n        while end_pos >= len(QTMETADATA_MAGIC):\n\
    \            start_pos = max(end_pos - SEARCH_CHUNK_SIZE, 0)\n            chunk_size\
    \ = end_pos - start_pos\n            # Is the remaining chunk large enough to\
    \ hold the pattern?\n            if chunk_size < len(QTMETADATA_MAGIC):\n    \
    \            break\n            # Read and scan the chunk\n            fp.seek(start_pos,\
    \ os.SEEK_SET)\n            buf = fp.read(chunk_size)\n            pos = buf.rfind(QTMETADATA_MAGIC)\n\
    \            if pos != -1:\n                magic_offset = start_pos + pos\n \
    \               break\n            # Adjust search location for next chunk; ensure\
    \ proper overlap.\n            end_pos = start_pos + len(QTMETADATA_MAGIC) - 1\n\
    \        if magic_offset == -1:\n            return False\n\n        return True\n\
    \n\nBOM_MARKERS_TO_DECODERS = {\n    codecs.BOM_UTF32_LE: codecs.utf_32_le_decode,\n\
    \    codecs.BOM_UTF32_BE: codecs.utf_32_be_decode,\n    codecs.BOM_UTF32: codecs.utf_32_decode,\n\
    \    codecs.BOM_UTF16_LE: codecs.utf_16_le_decode,\n    codecs.BOM_UTF16_BE: codecs.utf_16_be_decode,\n\
    \    codecs.BOM_UTF16: codecs.utf_16_decode,\n    codecs.BOM_UTF8: codecs.utf_8_decode,\n\
    }\nBOM_RE = re.compile(rb\"\\A(%s)?(.*)\" % b\"|\".join(map(re.escape, BOM_MARKERS_TO_DECODERS)),\
    \ re.DOTALL)\n\n\ndef decode(raw: bytes):\n    \"\"\"\n    Decode bytes to string,\
    \ respecting and removing any byte-order marks if present, or respecting but not\
    \ removing any\n    PEP263 encoding comments (# encoding: cp1252).\n    \"\"\"\
    \n    bom, raw = BOM_RE.match(raw).groups()\n    if bom:\n        return BOM_MARKERS_TO_DECODERS[bom](raw)[0]\n\
    \n    encoding, _ = tokenize.detect_encoding(io.BytesIO(raw).readline)\n    return\
    \ raw.decode(encoding)\n\n\ndef is_iterable(arg):\n    \"\"\"\n    Check if the\
    \ passed argument is an iterable.\"\n    \"\"\"\n    try:\n        iter(arg)\n\
    \    except TypeError:\n        return False\n    return True\n\n\ndef path_to_parent_archive(filename):\n\
    \    \"\"\"\n    Check if the given file path points to a file inside an existing\
    \ archive file. Returns first path from the set of\n    parent paths that points\
    \ to an existing file, or `None` if no such path exists (i.e., file is an actual\
    \ stand-alone\n    file).\n    \"\"\"\n    for parent in pathlib.Path(filename).parents:\n\
    \        if parent.is_file():\n            return parent\n    return None\n\n\
    Output the complete test file, code only, no explanations.\n### Time\nCurrent\
    \ time: 2025-03-15 16:07:34\n"
  role: user
